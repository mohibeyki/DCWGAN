{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COR-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1600481393982",
      "display_name": "Python 3.8.5 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZKq_k35W6_a"
      },
      "source": [
        "import argparse\n",
        "import copy\n",
        "import gc\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import h5py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or158iZXcTtF",
        "tags": [],
        "outputId": "5aa90264-7ae2-46f0-cd09-68d9ea34f0c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "experimentName = 'COR-GAN'\n",
        "\n",
        "parser.add_argument(\"--DATASETPATH\", type=str, default=os.path.expanduser('~/workspace/data/mimic-iii-processed/BINARY.h5'), help=\"Dataset file\")\n",
        "\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--n_epochs_ae\", type=int, default=100, help=\"number of epochs of pretraining the autoencoder\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=256, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--weight_decay\", type=float, default=0.0001, help=\"l2 regularization\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.9, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument('--n_critic', type=int, default=5, help='number of D iters per each G iter')\n",
        "parser.add_argument('--clamp', type=float, default=0.01)\n",
        "\n",
        "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
        "parser.add_argument(\"--multiplegpu\", type=bool, default=True, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--num_gpu\", type=int, default=1, help=\"Number of GPUs in case of multiple GPU\")\n",
        "\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval between samples\")\n",
        "parser.add_argument(\"--epoch_time_show\", type=bool, default=True, help=\"interval betwen image samples\")\n",
        "parser.add_argument(\"--epoch_save_model_freq\", type=int, default=100, help=\"number of epops per model save\")\n",
        "parser.add_argument(\"--minibatch_averaging\", type=bool, default=False, help=\"Minibatch averaging\")\n",
        "\n",
        "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/experiments/pytorch/model/{}'.format(experimentName)), help=\"Training status\")\n",
        "\n",
        "opt = parser.parse_args([])\n",
        "print(opt)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(DATASETPATH='/home/mohi/workspace/data/mimic-iii-processed/BINARY.h5', b1=0.9, b2=0.999, batch_size=256, clamp=0.01, cuda=True, epoch_save_model_freq=100, epoch_time_show=True, expPATH='/home/mohi/workspace/experiments/pytorch/model/COR-GAN', latent_dim=128, lr=0.001, minibatch_averaging=False, multiplegpu=True, n_cpu=32, n_critic=5, n_epochs=100, n_epochs_ae=100, num_gpu=1, sample_interval=100, weight_decay=0.0001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syZZGE3ixcZ",
        "tags": [],
        "outputId": "f1c2c765-60bc-4264-f16b-aed4c1a3ae4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################\n",
        "### Initialization ###\n",
        "######################\n",
        "\n",
        "# Create experiments DIR\n",
        "if not os.path.exists(opt.expPATH):\n",
        "    os.system('mkdir {0}'.format(opt.expPATH))\n",
        "\n",
        "# opt.seed = 1024 # fix seed\n",
        "opt.seed = random.randint(1, 10000)\n",
        "\n",
        "print('Random Seed: {}'.format(opt.seed))\n",
        "random.seed(opt.seed)\n",
        "torch.manual_seed(opt.seed)\n",
        "np.random.seed(opt.seed)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available() and not opt.cuda:\n",
        "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
        "print('using \\'{}\\' as the tensor processor'.format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed: 6460\n",
            "using 'cuda:0' as the tensor processor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYJtIeTEil-P"
      },
      "source": [
        "#################################\n",
        "### Reading Dataset from File ###\n",
        "#################################\n",
        "\n",
        "input_data = None\n",
        "with h5py.File(opt.DATASETPATH, 'r') as hf:\n",
        "    input_data = hf.get('dataset')[()]\n",
        "\n",
        "total_samples = input_data.shape[0]\n",
        "feature_size = input_data.shape[1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP96S8Kbcs0y"
      },
      "source": [
        "#####################\n",
        "### Dataset Model ###\n",
        "#####################\n",
        "\n",
        "class EHRDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.sample_size = dataset.shape[0]\n",
        "        self.feature_size = dataset.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkAxe6HS-KJ",
        "tags": [],
        "outputId": "f8a2d81a-a638-4c29-a8aa-8b165a132621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##########################\n",
        "### Dataset Processing ###\n",
        "##########################\n",
        "\n",
        "train_data = input_data[:int(0.8 * total_samples)]\n",
        "test_data = input_data[int(0.8 * total_samples):]\n",
        "print('total samples: {}, features: {}'.format(total_samples, feature_size))\n",
        "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total samples: 46520, features: 1071\n",
            "training data shape: (37216, 1071), testing data shape: (9304, 1071), dataset type: float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvS8xM1k8Teu"
      },
      "source": [
        "training_dataloader = DataLoader(\n",
        "    EHRDataset(dataset=train_data),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu\n",
        ")\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "    EHRDataset(dataset=test_data),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcvJBicPcyhv"
      },
      "source": [
        "def weightsInit(m):\n",
        "    \"\"\"\n",
        "    Custom weight initialization.\n",
        "    :param m: Input argument to extract layer type\n",
        "    :return: Initialized architecture\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSYLExToytb"
      },
      "source": [
        "########################\n",
        "### AutoEncoder Loss ###\n",
        "########################\n",
        "\n",
        "class AutoEncoderLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoderLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        epsilon = 1e-12\n",
        "        term = target * torch.log(input + epsilon) + (1. - target) * torch.log(1. - input + epsilon)\n",
        "        return torch.mean(-torch.sum(term, 1), 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3x99QhUfV6j"
      },
      "source": [
        "#########################\n",
        "### AutoEncoder Model ###\n",
        "#########################\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        n_channels_base = 4\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=n_channels_base, kernel_size=5, stride=2, padding=0, dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=n_channels_base, out_channels=2 * n_channels_base, kernel_size=5, stride=2, padding=0,\n",
        "                      dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(2 * n_channels_base),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=2 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=5, stride=3,\n",
        "                      padding=0, dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(4 * n_channels_base),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=4 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5, stride=3,\n",
        "                      padding=0, dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(8 * n_channels_base),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=8 * n_channels_base, out_channels=16 * n_channels_base, kernel_size=5, stride=3,\n",
        "                      padding=0, dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(16 * n_channels_base),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=16 * n_channels_base, out_channels=32 * n_channels_base, kernel_size=8, stride=1,\n",
        "                      padding=0, dilation=1,\n",
        "                      groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_channels=32 * n_channels_base, out_channels=16 * n_channels_base, kernel_size=5,\n",
        "                               stride=1, padding=0, dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=16 * n_channels_base, out_channels=8 * n_channels_base, kernel_size=5,\n",
        "                               stride=4, padding=0,\n",
        "                               dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(8 * n_channels_base),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=8 * n_channels_base, out_channels=4 * n_channels_base, kernel_size=7,\n",
        "                               stride=4,\n",
        "                               padding=0, dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(4 * n_channels_base),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=4 * n_channels_base, out_channels=2 * n_channels_base, kernel_size=7,\n",
        "                               stride=3,\n",
        "                               padding=0, dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(2 * n_channels_base),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=2 * n_channels_base, out_channels=n_channels_base, kernel_size=7, stride=2,\n",
        "                               padding=0, dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.BatchNorm1d(n_channels_base),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=n_channels_base, out_channels=1, kernel_size=3, stride=2,\n",
        "                               padding=0, dilation=1,\n",
        "                               groups=1, bias=True, padding_mode='zeros'),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x.view(-1, 1, x.shape[1]))\n",
        "        x = self.decoder(x)\n",
        "        return torch.squeeze(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "        x = self.decoder(x)\n",
        "        return torch.squeeze(x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0I5dbr5cGlQ"
      },
      "source": [
        "#############################\n",
        "### Generator Model ###\n",
        "#############################\n",
        "\n",
        "# Output should be 64 * 20\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        ngf = 4\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose1d(opt.latent_dim, ngf * 16, 4, 1, 0),\n",
        "            nn.BatchNorm1d(ngf * 16, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(ngf * 16, ngf * 8, 4, 2, 1),\n",
        "            nn.BatchNorm1d(ngf * 8, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(ngf * 8, ngf * 4, 4, 2, 1),\n",
        "            nn.BatchNorm1d(ngf * 4, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(ngf * 4, ngf * 2, 4, 2, 1),\n",
        "            nn.BatchNorm1d(ngf * 2, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(ngf * 2, ngf, 4, 2, 1),\n",
        "            nn.BatchNorm1d(ngf, eps=0.001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(ngf, 1, 4, 2, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, x.shape[1], 1)\n",
        "        out = self.main(x)\n",
        "        return torch.squeeze(out)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oIATq7r9ek"
      },
      "source": [
        "###########################\n",
        "### Discriminator Model ###\n",
        "###########################\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        ndf = 16\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv1d(1, ndf, 8, 4, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv1d(ndf, ndf * 2, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv1d(ndf * 2, ndf * 4, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv1d(ndf * 4, ndf * 8, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv1d(ndf * 8, 1, 3, 1, 0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv1(input.view(-1, 1, input.shape[1]))\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        return torch.squeeze(out, dim=2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inVoiMu9QS_",
        "tags": [],
        "outputId": "10fe0145-9f08-440c-ad8f-9c9ac966ba2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "############################\n",
        "### Model Initialization ###\n",
        "############################\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "Tensor = torch.FloatTensor\n",
        "\n",
        "one = torch.FloatTensor([1])\n",
        "mone = one * -1\n",
        "\n",
        "if opt.cuda:\n",
        "    autoencoder.cuda()\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    one = one.cuda()\n",
        "    mone = mone.cuda()\n",
        "    Tensor = torch.cuda.FloatTensor\n",
        "\n",
        "generator_params = [{'params': generator.parameters()}, {'params': autoencoder.decoder.parameters(), 'lr': 1e-4}]\n",
        "\n",
        "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)\n",
        "optimizer_G = torch.optim.Adam(generator_params, lr=opt.lr)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)\n",
        "\n",
        "generator.apply(weightsInit)\n",
        "discriminator.apply(weightsInit)\n",
        "autoencoder.apply(weightsInit)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv1d(4, 8, kernel_size=(5,), stride=(2,))\n",
              "    (3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv1d(8, 16, kernel_size=(5,), stride=(3,))\n",
              "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv1d(16, 32, kernel_size=(5,), stride=(3,))\n",
              "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv1d(32, 64, kernel_size=(5,), stride=(3,))\n",
              "    (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (14): Conv1d(64, 128, kernel_size=(8,), stride=(1,))\n",
              "    (15): Tanh()\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): ConvTranspose1d(128, 64, kernel_size=(5,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): ConvTranspose1d(64, 32, kernel_size=(5,), stride=(4,))\n",
              "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,))\n",
              "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU()\n",
              "    (8): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(3,))\n",
              "    (9): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): ConvTranspose1d(8, 4, kernel_size=(7,), stride=(2,))\n",
              "    (12): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU()\n",
              "    (14): ConvTranspose1d(4, 1, kernel_size=(3,), stride=(2,))\n",
              "    (15): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWlJt7_892vs",
        "tags": [],
        "outputId": "2c172b8d-e228-457f-d3e7-f074fe75dfb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#####################################\n",
        "###### AutoEncoder Training #########\n",
        "#####################################\n",
        "\n",
        "criterion = AutoEncoderLoss()\n",
        "\n",
        "if True:\n",
        "    for epoch in range(opt.n_epochs_ae):\n",
        "        autoencoder.train()\n",
        "        for batch in training_dataloader:\n",
        "            batch = Variable(batch.type(Tensor))\n",
        "            generated = autoencoder(batch)\n",
        "            loss_A = criterion(generated, batch)\n",
        "            optimizer_A.zero_grad()\n",
        "            loss_A.backward()\n",
        "            optimizer_A.step()\n",
        "\n",
        "        errors = 0\n",
        "        testing_loss = 0\n",
        "        autoencoder.eval()\n",
        "        for batch in testing_dataloader:\n",
        "            batch = Variable(batch.type(Tensor))\n",
        "            generated = autoencoder(batch)\n",
        "            res = generated.round()\n",
        "            diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
        "            bad_diffs = diff[diff > 0.5]\n",
        "            errors += len(bad_diffs)\n",
        "            testing_loss += criterion(generated, batch)\n",
        "\n",
        "        print(\"[Epoch {:3d}/{:3d} of autoencoder training] [Loss: {:10.2f}] [errors: {:6d}]\".format(epoch + 1, opt.n_epochs_ae, testing_loss, errors), flush=True)\n",
        "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
        "\n",
        "else:\n",
        "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))\n",
        "    autoencoder.eval()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch   1/100 of autoencoder training] [Loss:   20149.87] [errors: 399178]\n",
            "[Epoch   2/100 of autoencoder training] [Loss:   12605.12] [errors: 131308]\n",
            "[Epoch   3/100 of autoencoder training] [Loss:    5942.70] [errors: 131308]\n",
            "[Epoch   4/100 of autoencoder training] [Loss:    6250.25] [errors: 131308]\n",
            "[Epoch   5/100 of autoencoder training] [Loss:    5410.60] [errors: 131308]\n",
            "[Epoch   6/100 of autoencoder training] [Loss:    3544.35] [errors: 131308]\n",
            "[Epoch   7/100 of autoencoder training] [Loss:    3134.05] [errors: 131308]\n",
            "[Epoch   8/100 of autoencoder training] [Loss:    2042.22] [errors: 131308]\n",
            "[Epoch   9/100 of autoencoder training] [Loss:    2206.41] [errors: 131308]\n",
            "[Epoch  10/100 of autoencoder training] [Loss:    1409.50] [errors: 131308]\n",
            "[Epoch  11/100 of autoencoder training] [Loss:    1306.06] [errors: 131308]\n",
            "[Epoch  12/100 of autoencoder training] [Loss:    1361.67] [errors: 131308]\n",
            "[Epoch  13/100 of autoencoder training] [Loss:    1242.81] [errors: 131308]\n",
            "[Epoch  14/100 of autoencoder training] [Loss:    1767.91] [errors: 131308]\n",
            "[Epoch  15/100 of autoencoder training] [Loss:    1163.00] [errors: 131308]\n",
            "[Epoch  16/100 of autoencoder training] [Loss:    1134.10] [errors: 131308]\n",
            "[Epoch  17/100 of autoencoder training] [Loss:    2068.51] [errors: 131308]\n",
            "[Epoch  18/100 of autoencoder training] [Loss:    1188.58] [errors: 131308]\n",
            "[Epoch  19/100 of autoencoder training] [Loss:    1056.69] [errors: 131308]\n",
            "[Epoch  20/100 of autoencoder training] [Loss:    1611.84] [errors: 131308]\n",
            "[Epoch  21/100 of autoencoder training] [Loss:    1895.79] [errors: 131308]\n",
            "[Epoch  22/100 of autoencoder training] [Loss:    1040.56] [errors: 131308]\n",
            "[Epoch  23/100 of autoencoder training] [Loss:    1290.44] [errors: 131308]\n",
            "[Epoch  24/100 of autoencoder training] [Loss:    1083.03] [errors: 131308]\n",
            "[Epoch  25/100 of autoencoder training] [Loss:    1000.88] [errors: 131308]\n",
            "[Epoch  26/100 of autoencoder training] [Loss:    2538.10] [errors: 131308]\n",
            "[Epoch  27/100 of autoencoder training] [Loss:    1187.27] [errors: 131308]\n",
            "[Epoch  28/100 of autoencoder training] [Loss:     961.82] [errors: 131308]\n",
            "[Epoch  29/100 of autoencoder training] [Loss:    1228.03] [errors: 131308]\n",
            "[Epoch  30/100 of autoencoder training] [Loss:    1107.54] [errors: 131308]\n",
            "[Epoch  31/100 of autoencoder training] [Loss:    1038.39] [errors: 131308]\n",
            "[Epoch  32/100 of autoencoder training] [Loss:     951.62] [errors: 131308]\n",
            "[Epoch  33/100 of autoencoder training] [Loss:    1127.98] [errors: 131308]\n",
            "[Epoch  34/100 of autoencoder training] [Loss:    1121.14] [errors: 131308]\n",
            "[Epoch  35/100 of autoencoder training] [Loss:    1126.14] [errors: 131308]\n",
            "[Epoch  36/100 of autoencoder training] [Loss:     994.47] [errors: 131308]\n",
            "[Epoch  37/100 of autoencoder training] [Loss:    1351.52] [errors: 131308]\n",
            "[Epoch  38/100 of autoencoder training] [Loss:    1067.90] [errors: 131308]\n",
            "[Epoch  39/100 of autoencoder training] [Loss:     938.18] [errors: 131308]\n",
            "[Epoch  40/100 of autoencoder training] [Loss:     915.29] [errors: 110343]\n",
            "[Epoch  41/100 of autoencoder training] [Loss:    1173.43] [errors: 105833]\n",
            "[Epoch  42/100 of autoencoder training] [Loss:    2305.23] [errors: 174298]\n",
            "[Epoch  43/100 of autoencoder training] [Loss:     778.68] [errors:  91088]\n",
            "[Epoch  44/100 of autoencoder training] [Loss:     978.94] [errors:  99469]\n",
            "[Epoch  45/100 of autoencoder training] [Loss:    1241.45] [errors: 109516]\n",
            "[Epoch  46/100 of autoencoder training] [Loss:     752.20] [errors:  91389]\n",
            "[Epoch  47/100 of autoencoder training] [Loss:     814.91] [errors:  85151]\n",
            "[Epoch  48/100 of autoencoder training] [Loss:     692.41] [errors:  72681]\n",
            "[Epoch  49/100 of autoencoder training] [Loss:     755.43] [errors:  77942]\n",
            "[Epoch  50/100 of autoencoder training] [Loss:     712.43] [errors:  68184]\n",
            "[Epoch  51/100 of autoencoder training] [Loss:    1131.96] [errors:  93687]\n",
            "[Epoch  52/100 of autoencoder training] [Loss:     670.75] [errors:  61236]\n",
            "[Epoch  53/100 of autoencoder training] [Loss:     847.58] [errors:  78791]\n",
            "[Epoch  54/100 of autoencoder training] [Loss:     784.55] [errors:  70448]\n",
            "[Epoch  55/100 of autoencoder training] [Loss:    1853.07] [errors: 183204]\n",
            "[Epoch  56/100 of autoencoder training] [Loss:     625.74] [errors:  52157]\n",
            "[Epoch  57/100 of autoencoder training] [Loss:     650.39] [errors:  54653]\n",
            "[Epoch  58/100 of autoencoder training] [Loss:    2684.16] [errors: 239896]\n",
            "[Epoch  59/100 of autoencoder training] [Loss:     973.65] [errors:  84409]\n",
            "[Epoch  60/100 of autoencoder training] [Loss:     792.09] [errors:  65020]\n",
            "[Epoch  61/100 of autoencoder training] [Loss:     551.55] [errors:  43520]\n",
            "[Epoch  62/100 of autoencoder training] [Loss:     685.34] [errors:  54023]\n",
            "[Epoch  63/100 of autoencoder training] [Loss:     963.58] [errors:  88233]\n",
            "[Epoch  64/100 of autoencoder training] [Loss:     979.71] [errors:  89144]\n",
            "[Epoch  65/100 of autoencoder training] [Loss:     646.78] [errors:  50007]\n",
            "[Epoch  66/100 of autoencoder training] [Loss:    1557.02] [errors:  99884]\n",
            "[Epoch  67/100 of autoencoder training] [Loss:     773.85] [errors:  65372]\n",
            "[Epoch  68/100 of autoencoder training] [Loss:     961.59] [errors:  74037]\n",
            "[Epoch  69/100 of autoencoder training] [Loss:     611.80] [errors:  48525]\n",
            "[Epoch  70/100 of autoencoder training] [Loss:     653.21] [errors:  50359]\n",
            "[Epoch  71/100 of autoencoder training] [Loss:     824.69] [errors:  62617]\n",
            "[Epoch  72/100 of autoencoder training] [Loss:     590.81] [errors:  42819]\n",
            "[Epoch  73/100 of autoencoder training] [Loss:     847.91] [errors:  68357]\n",
            "[Epoch  74/100 of autoencoder training] [Loss:     552.58] [errors:  41666]\n",
            "[Epoch  75/100 of autoencoder training] [Loss:     685.86] [errors:  53743]\n",
            "[Epoch  76/100 of autoencoder training] [Loss:     666.77] [errors:  51537]\n",
            "[Epoch  77/100 of autoencoder training] [Loss:     528.99] [errors:  38371]\n",
            "[Epoch  78/100 of autoencoder training] [Loss:    1032.67] [errors:  94486]\n",
            "[Epoch  79/100 of autoencoder training] [Loss:     517.43] [errors:  37821]\n",
            "[Epoch  80/100 of autoencoder training] [Loss:     620.10] [errors:  48448]\n",
            "[Epoch  81/100 of autoencoder training] [Loss:     523.96] [errors:  38679]\n",
            "[Epoch  82/100 of autoencoder training] [Loss:    1084.61] [errors:  80375]\n",
            "[Epoch  83/100 of autoencoder training] [Loss:     631.13] [errors:  51041]\n",
            "[Epoch  84/100 of autoencoder training] [Loss:     523.12] [errors:  36551]\n",
            "[Epoch  85/100 of autoencoder training] [Loss:     522.30] [errors:  37104]\n",
            "[Epoch  86/100 of autoencoder training] [Loss:     499.14] [errors:  37595]\n",
            "[Epoch  87/100 of autoencoder training] [Loss:     617.96] [errors:  44148]\n",
            "[Epoch  88/100 of autoencoder training] [Loss:     591.16] [errors:  41546]\n",
            "[Epoch  89/100 of autoencoder training] [Loss:     487.72] [errors:  37135]\n",
            "[Epoch  90/100 of autoencoder training] [Loss:     604.60] [errors:  45606]\n",
            "[Epoch  91/100 of autoencoder training] [Loss:     484.67] [errors:  35570]\n",
            "[Epoch  92/100 of autoencoder training] [Loss:     534.57] [errors:  38326]\n",
            "[Epoch  93/100 of autoencoder training] [Loss:     530.63] [errors:  37813]\n",
            "[Epoch  94/100 of autoencoder training] [Loss:     469.07] [errors:  34690]\n",
            "[Epoch  95/100 of autoencoder training] [Loss:     882.05] [errors:  73079]\n",
            "[Epoch  96/100 of autoencoder training] [Loss:     485.33] [errors:  35224]\n",
            "[Epoch  97/100 of autoencoder training] [Loss:     510.73] [errors:  37848]\n",
            "[Epoch  98/100 of autoencoder training] [Loss:     733.60] [errors:  58345]\n",
            "[Epoch  99/100 of autoencoder training] [Loss:     539.43] [errors:  37238]\n",
            "[Epoch 100/100 of autoencoder training] [Loss:     522.22] [errors:  39295]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xHg4CmL6BW",
        "outputId": "b9f4b893-3b8e-44ed-a861-2dc28fe143db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "errors = 0\n",
        "for batch in testing_dataloader:\n",
        "    batch = Variable(batch.type(Tensor))\n",
        "    generated = autoencoder(batch)\n",
        "    res = generated.round()\n",
        "    diff = torch.abs(res - batch).view(1, 1, -1)[0][0].cpu().detach().numpy()\n",
        "    bad_diffs = diff[diff > 0.5]\n",
        "    errors += len(bad_diffs)\n",
        "print(\"total number of bad digits: {}\".format(errors))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of bad digits: 39295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83EKUAC3Edo",
        "outputId": "4e2665c8-3dc2-447d-cf48-44d3c3c502b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if True:\n",
        "    batches_done = 0\n",
        "\n",
        "    discriminator.train()\n",
        "    generator.train()\n",
        "\n",
        "    gen_iterations = 0\n",
        "    for epoch in range(opt.n_epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        for batch in training_dataloader:\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "            batch = Variable(batch.type(Tensor))\n",
        "\n",
        "            for dp in discriminator.parameters():\n",
        "                dp.requires_grad = True\n",
        "\n",
        "            if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
        "                n_critic = 100\n",
        "            else:\n",
        "                n_critic = opt.n_critic\n",
        "\n",
        "            for _ in range(opt.n_critic):\n",
        "                for dp in discriminator.parameters():\n",
        "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
        "\n",
        "                # reset gradients of discriminator\n",
        "                optimizer_D.zero_grad()\n",
        "\n",
        "                loss_D_real = torch.mean(discriminator(batch), dim=0)\n",
        "                loss_D_real.backward(one)\n",
        "\n",
        "                # Sample noise as generator input\n",
        "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
        "                # Generate a batch of images\n",
        "                fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
        "\n",
        "                # Error\n",
        "                loss_D_fake = torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
        "                loss_D_fake.backward(mone)\n",
        "\n",
        "                # Optimizer stepz\n",
        "                optimizer_D.step()\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "\n",
        "            for dp in discriminator.parameters():\n",
        "                dp.requires_grad = False\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Sample noise as generator input\n",
        "            z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
        "\n",
        "            # Generate a batch of images\n",
        "            fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
        "\n",
        "            # uncomment if there is no autoencoder\n",
        "            loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
        "            loss_G.backward(one)\n",
        "            optimizer_G.step()\n",
        "            batches_done += 1\n",
        "\n",
        "            if batches_done % 100 == 0:\n",
        "                print('[Epoch {:3d}/{:3d}] [Batch {:3d}/{:3d}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, batches_done % len(training_dataloader), len(training_dataloader), loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
        "\n",
        "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.5f}] [G loss: {:.5f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D_real.item() + loss_D_fake.item(), loss_G.item()))\n",
        "\n",
        "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
        "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
        "else:\n",
        "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
        "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch   1/100] [Batch 100/146] [D loss: 1.00216] [G loss: 0.50894]\n",
            "[Epoch   1/100] [Time: 7.51] [D loss: 1.00261] [G loss: 0.50863]\n",
            "[Epoch   2/100] [Batch  54/146] [D loss: 1.00243] [G loss: 0.50720]\n",
            "[Epoch   2/100] [Time: 8.04] [D loss: 1.00267] [G loss: 0.50553]\n",
            "[Epoch   3/100] [Batch   8/146] [D loss: 1.00262] [G loss: 0.50614]\n",
            "[Epoch   3/100] [Batch 108/146] [D loss: 1.00317] [G loss: 0.50635]\n",
            "[Epoch   3/100] [Time: 7.89] [D loss: 1.00235] [G loss: 0.50555]\n",
            "[Epoch   4/100] [Batch  62/146] [D loss: 1.00203] [G loss: 0.50484]\n",
            "[Epoch   4/100] [Time: 7.72] [D loss: 1.00181] [G loss: 0.50414]\n",
            "[Epoch   5/100] [Batch  16/146] [D loss: 1.00214] [G loss: 0.50483]\n",
            "[Epoch   5/100] [Batch 116/146] [D loss: 1.00269] [G loss: 0.50555]\n",
            "[Epoch   5/100] [Time: 8.05] [D loss: 1.00268] [G loss: 0.50442]\n",
            "[Epoch   6/100] [Batch  70/146] [D loss: 1.00344] [G loss: 0.50437]\n",
            "[Epoch   6/100] [Time: 7.05] [D loss: 1.00372] [G loss: 0.50441]\n",
            "[Epoch   7/100] [Batch  24/146] [D loss: 1.00312] [G loss: 0.50473]\n",
            "[Epoch   7/100] [Batch 124/146] [D loss: 1.00305] [G loss: 0.50416]\n",
            "[Epoch   7/100] [Time: 7.61] [D loss: 1.00063] [G loss: 0.50411]\n",
            "[Epoch   8/100] [Batch  78/146] [D loss: 1.00414] [G loss: 0.50564]\n",
            "[Epoch   8/100] [Time: 7.53] [D loss: 1.00382] [G loss: 0.50561]\n",
            "[Epoch   9/100] [Batch  32/146] [D loss: 1.00405] [G loss: 0.50508]\n",
            "[Epoch   9/100] [Batch 132/146] [D loss: 1.00590] [G loss: 0.50530]\n",
            "[Epoch   9/100] [Time: 6.88] [D loss: 1.00383] [G loss: 0.50403]\n",
            "[Epoch  10/100] [Batch  86/146] [D loss: 1.00466] [G loss: 0.50459]\n",
            "[Epoch  10/100] [Time: 8.13] [D loss: 1.00564] [G loss: 0.50547]\n",
            "[Epoch  11/100] [Batch  40/146] [D loss: 1.00373] [G loss: 0.50442]\n",
            "[Epoch  11/100] [Batch 140/146] [D loss: 1.00443] [G loss: 0.50345]\n",
            "[Epoch  11/100] [Time: 7.88] [D loss: 1.00318] [G loss: 0.50349]\n",
            "[Epoch  12/100] [Batch  94/146] [D loss: 1.00366] [G loss: 0.50436]\n",
            "[Epoch  12/100] [Time: 7.35] [D loss: 1.00304] [G loss: 0.50259]\n",
            "[Epoch  13/100] [Batch  48/146] [D loss: 1.00589] [G loss: 0.50598]\n",
            "[Epoch  13/100] [Time: 7.52] [D loss: 1.00356] [G loss: 0.50434]\n",
            "[Epoch  14/100] [Batch   2/146] [D loss: 1.00575] [G loss: 0.50454]\n",
            "[Epoch  14/100] [Batch 102/146] [D loss: 1.00644] [G loss: 0.50559]\n",
            "[Epoch  14/100] [Time: 8.14] [D loss: 1.00443] [G loss: 0.50430]\n",
            "[Epoch  15/100] [Batch  56/146] [D loss: 1.00645] [G loss: 0.50502]\n",
            "[Epoch  15/100] [Time: 8.40] [D loss: 1.00461] [G loss: 0.50554]\n",
            "[Epoch  16/100] [Batch  10/146] [D loss: 1.00582] [G loss: 0.50485]\n",
            "[Epoch  16/100] [Batch 110/146] [D loss: 1.00741] [G loss: 0.50536]\n",
            "[Epoch  16/100] [Time: 8.06] [D loss: 1.00617] [G loss: 0.50401]\n",
            "[Epoch  17/100] [Batch  64/146] [D loss: 1.00216] [G loss: 0.50204]\n",
            "[Epoch  17/100] [Time: 7.93] [D loss: 1.00220] [G loss: 0.50284]\n",
            "[Epoch  18/100] [Batch  18/146] [D loss: 1.00424] [G loss: 0.50385]\n",
            "[Epoch  18/100] [Batch 118/146] [D loss: 1.00533] [G loss: 0.50523]\n",
            "[Epoch  18/100] [Time: 7.36] [D loss: 1.00516] [G loss: 0.50508]\n",
            "[Epoch  19/100] [Batch  72/146] [D loss: 1.00396] [G loss: 0.50677]\n",
            "[Epoch  19/100] [Time: 8.33] [D loss: 1.00407] [G loss: 0.50580]\n",
            "[Epoch  20/100] [Batch  26/146] [D loss: 1.00328] [G loss: 0.50348]\n",
            "[Epoch  20/100] [Batch 126/146] [D loss: 1.00400] [G loss: 0.50258]\n",
            "[Epoch  20/100] [Time: 8.27] [D loss: 1.00515] [G loss: 0.50579]\n",
            "[Epoch  21/100] [Batch  80/146] [D loss: 1.00396] [G loss: 0.50364]\n",
            "[Epoch  21/100] [Time: 7.42] [D loss: 1.00251] [G loss: 0.50409]\n",
            "[Epoch  22/100] [Batch  34/146] [D loss: 1.00260] [G loss: 0.50346]\n",
            "[Epoch  22/100] [Batch 134/146] [D loss: 1.00513] [G loss: 0.50394]\n",
            "[Epoch  22/100] [Time: 8.07] [D loss: 1.00240] [G loss: 0.50216]\n",
            "[Epoch  23/100] [Batch  88/146] [D loss: 1.00531] [G loss: 0.50424]\n",
            "[Epoch  23/100] [Time: 7.02] [D loss: 1.00229] [G loss: 0.50278]\n",
            "[Epoch  24/100] [Batch  42/146] [D loss: 1.00485] [G loss: 0.50356]\n",
            "[Epoch  24/100] [Batch 142/146] [D loss: 1.00322] [G loss: 0.50418]\n",
            "[Epoch  24/100] [Time: 7.79] [D loss: 1.00344] [G loss: 0.50340]\n",
            "[Epoch  25/100] [Batch  96/146] [D loss: 1.00503] [G loss: 0.50348]\n",
            "[Epoch  25/100] [Time: 8.32] [D loss: 1.00308] [G loss: 0.50470]\n",
            "[Epoch  26/100] [Batch  50/146] [D loss: 1.00073] [G loss: 0.50325]\n",
            "[Epoch  26/100] [Time: 6.18] [D loss: 1.00088] [G loss: 0.50277]\n",
            "[Epoch  27/100] [Batch   4/146] [D loss: 0.99927] [G loss: 0.50126]\n",
            "[Epoch  27/100] [Batch 104/146] [D loss: 1.00302] [G loss: 0.50308]\n",
            "[Epoch  27/100] [Time: 6.64] [D loss: 1.00270] [G loss: 0.50323]\n",
            "[Epoch  28/100] [Batch  58/146] [D loss: 1.00039] [G loss: 0.50110]\n",
            "[Epoch  28/100] [Time: 7.17] [D loss: 1.00199] [G loss: 0.50181]\n",
            "[Epoch  29/100] [Batch  12/146] [D loss: 1.00150] [G loss: 0.50365]\n",
            "[Epoch  29/100] [Batch 112/146] [D loss: 0.99622] [G loss: 0.50019]\n",
            "[Epoch  29/100] [Time: 8.33] [D loss: 1.00492] [G loss: 0.50457]\n",
            "[Epoch  30/100] [Batch  66/146] [D loss: 1.00013] [G loss: 0.50110]\n",
            "[Epoch  30/100] [Time: 7.49] [D loss: 1.00334] [G loss: 0.50505]\n",
            "[Epoch  31/100] [Batch  20/146] [D loss: 1.00327] [G loss: 0.50073]\n",
            "[Epoch  31/100] [Batch 120/146] [D loss: 1.00413] [G loss: 0.50058]\n",
            "[Epoch  31/100] [Time: 7.12] [D loss: 1.00097] [G loss: 0.50212]\n",
            "[Epoch  32/100] [Batch  74/146] [D loss: 1.00319] [G loss: 0.50178]\n",
            "[Epoch  32/100] [Time: 7.84] [D loss: 0.99887] [G loss: 0.50178]\n",
            "[Epoch  33/100] [Batch  28/146] [D loss: 1.00189] [G loss: 0.50165]\n",
            "[Epoch  33/100] [Batch 128/146] [D loss: 1.00100] [G loss: 0.50404]\n",
            "[Epoch  33/100] [Time: 6.43] [D loss: 1.00484] [G loss: 0.50330]\n",
            "[Epoch  34/100] [Batch  82/146] [D loss: 0.99977] [G loss: 0.50234]\n",
            "[Epoch  34/100] [Time: 7.28] [D loss: 1.00572] [G loss: 0.50240]\n",
            "[Epoch  35/100] [Batch  36/146] [D loss: 1.00453] [G loss: 0.50489]\n",
            "[Epoch  35/100] [Batch 136/146] [D loss: 0.99659] [G loss: 0.50008]\n",
            "[Epoch  35/100] [Time: 6.47] [D loss: 1.00052] [G loss: 0.50416]\n",
            "[Epoch  36/100] [Batch  90/146] [D loss: 1.00186] [G loss: 0.50197]\n",
            "[Epoch  36/100] [Time: 6.79] [D loss: 1.00925] [G loss: 0.50629]\n",
            "[Epoch  37/100] [Batch  44/146] [D loss: 1.00809] [G loss: 0.50552]\n",
            "[Epoch  37/100] [Batch 144/146] [D loss: 1.00833] [G loss: 0.50550]\n",
            "[Epoch  37/100] [Time: 6.46] [D loss: 1.00720] [G loss: 0.50359]\n",
            "[Epoch  38/100] [Batch  98/146] [D loss: 1.00195] [G loss: 0.50404]\n",
            "[Epoch  38/100] [Time: 7.34] [D loss: 1.00413] [G loss: 0.50512]\n",
            "[Epoch  39/100] [Batch  52/146] [D loss: 1.00443] [G loss: 0.50533]\n",
            "[Epoch  39/100] [Time: 7.22] [D loss: 1.00050] [G loss: 0.50238]\n",
            "[Epoch  40/100] [Batch   6/146] [D loss: 0.99850] [G loss: 0.50123]\n",
            "[Epoch  40/100] [Batch 106/146] [D loss: 1.00198] [G loss: 0.50337]\n",
            "[Epoch  40/100] [Time: 7.47] [D loss: 1.00696] [G loss: 0.50355]\n",
            "[Epoch  41/100] [Batch  60/146] [D loss: 1.00312] [G loss: 0.50339]\n",
            "[Epoch  41/100] [Time: 7.85] [D loss: 1.00372] [G loss: 0.50266]\n",
            "[Epoch  42/100] [Batch  14/146] [D loss: 1.00426] [G loss: 0.50301]\n",
            "[Epoch  42/100] [Batch 114/146] [D loss: 1.00392] [G loss: 0.50406]\n",
            "[Epoch  42/100] [Time: 7.92] [D loss: 1.00068] [G loss: 0.50241]\n",
            "[Epoch  43/100] [Batch  68/146] [D loss: 1.00642] [G loss: 0.50511]\n",
            "[Epoch  43/100] [Time: 8.20] [D loss: 1.00219] [G loss: 0.50261]\n",
            "[Epoch  44/100] [Batch  22/146] [D loss: 1.00447] [G loss: 0.50377]\n",
            "[Epoch  44/100] [Batch 122/146] [D loss: 1.00720] [G loss: 0.50507]\n",
            "[Epoch  44/100] [Time: 7.88] [D loss: 1.00141] [G loss: 0.50080]\n",
            "[Epoch  45/100] [Batch  76/146] [D loss: 1.00472] [G loss: 0.50399]\n",
            "[Epoch  45/100] [Time: 8.08] [D loss: 1.00648] [G loss: 0.50358]\n",
            "[Epoch  46/100] [Batch  30/146] [D loss: 1.01122] [G loss: 0.50762]\n",
            "[Epoch  46/100] [Batch 130/146] [D loss: 1.00722] [G loss: 0.50565]\n",
            "[Epoch  46/100] [Time: 7.28] [D loss: 1.00699] [G loss: 0.50533]\n",
            "[Epoch  47/100] [Batch  84/146] [D loss: 1.00407] [G loss: 0.50357]\n",
            "[Epoch  47/100] [Time: 7.66] [D loss: 1.00275] [G loss: 0.50398]\n",
            "[Epoch  48/100] [Batch  38/146] [D loss: 1.00257] [G loss: 0.50164]\n",
            "[Epoch  48/100] [Batch 138/146] [D loss: 1.00133] [G loss: 0.50285]\n",
            "[Epoch  48/100] [Time: 8.25] [D loss: 1.00691] [G loss: 0.50421]\n",
            "[Epoch  49/100] [Batch  92/146] [D loss: 1.00134] [G loss: 0.50159]\n",
            "[Epoch  49/100] [Time: 8.37] [D loss: 1.00312] [G loss: 0.50435]\n",
            "[Epoch  50/100] [Batch  46/146] [D loss: 1.00322] [G loss: 0.50335]\n",
            "[Epoch  50/100] [Batch   0/146] [D loss: 0.99933] [G loss: 0.49979]\n",
            "[Epoch  50/100] [Time: 8.33] [D loss: 0.99933] [G loss: 0.49979]\n",
            "[Epoch  51/100] [Batch 100/146] [D loss: 1.00036] [G loss: 0.50035]\n",
            "[Epoch  51/100] [Time: 8.21] [D loss: 1.00380] [G loss: 0.50401]\n",
            "[Epoch  52/100] [Batch  54/146] [D loss: 0.99989] [G loss: 0.50126]\n",
            "[Epoch  52/100] [Time: 7.46] [D loss: 0.99930] [G loss: 0.50082]\n",
            "[Epoch  53/100] [Batch   8/146] [D loss: 0.99877] [G loss: 0.50152]\n",
            "[Epoch  53/100] [Batch 108/146] [D loss: 1.00106] [G loss: 0.50197]\n",
            "[Epoch  53/100] [Time: 7.64] [D loss: 0.99896] [G loss: 0.50045]\n",
            "[Epoch  54/100] [Batch  62/146] [D loss: 1.00037] [G loss: 0.50137]\n",
            "[Epoch  54/100] [Time: 8.19] [D loss: 1.00217] [G loss: 0.50224]\n",
            "[Epoch  55/100] [Batch  16/146] [D loss: 1.00200] [G loss: 0.50191]\n",
            "[Epoch  55/100] [Batch 116/146] [D loss: 1.00110] [G loss: 0.50192]\n",
            "[Epoch  55/100] [Time: 7.45] [D loss: 1.00495] [G loss: 0.50327]\n",
            "[Epoch  56/100] [Batch  70/146] [D loss: 1.00519] [G loss: 0.50421]\n",
            "[Epoch  56/100] [Time: 7.49] [D loss: 0.99924] [G loss: 0.50084]\n",
            "[Epoch  57/100] [Batch  24/146] [D loss: 1.00271] [G loss: 0.50307]\n",
            "[Epoch  57/100] [Batch 124/146] [D loss: 1.00088] [G loss: 0.50070]\n",
            "[Epoch  57/100] [Time: 8.03] [D loss: 1.00230] [G loss: 0.50179]\n",
            "[Epoch  58/100] [Batch  78/146] [D loss: 1.00094] [G loss: 0.50114]\n",
            "[Epoch  58/100] [Time: 8.29] [D loss: 1.00679] [G loss: 0.50289]\n",
            "[Epoch  59/100] [Batch  32/146] [D loss: 1.00702] [G loss: 0.50609]\n",
            "[Epoch  59/100] [Batch 132/146] [D loss: 1.00291] [G loss: 0.50166]\n",
            "[Epoch  59/100] [Time: 7.33] [D loss: 1.00330] [G loss: 0.50169]\n",
            "[Epoch  60/100] [Batch  86/146] [D loss: 1.00633] [G loss: 0.50517]\n",
            "[Epoch  60/100] [Time: 8.40] [D loss: 1.00235] [G loss: 0.50373]\n",
            "[Epoch  61/100] [Batch  40/146] [D loss: 0.99335] [G loss: 0.49817]\n",
            "[Epoch  61/100] [Batch 140/146] [D loss: 1.00545] [G loss: 0.50413]\n",
            "[Epoch  61/100] [Time: 6.97] [D loss: 1.00607] [G loss: 0.50315]\n",
            "[Epoch  62/100] [Batch  94/146] [D loss: 1.00536] [G loss: 0.50186]\n",
            "[Epoch  62/100] [Time: 7.69] [D loss: 0.99860] [G loss: 0.49915]\n",
            "[Epoch  63/100] [Batch  48/146] [D loss: 0.99633] [G loss: 0.49910]\n",
            "[Epoch  63/100] [Time: 7.55] [D loss: 1.00127] [G loss: 0.50156]\n",
            "[Epoch  64/100] [Batch   2/146] [D loss: 1.00038] [G loss: 0.50110]\n",
            "[Epoch  64/100] [Batch 102/146] [D loss: 1.00477] [G loss: 0.50394]\n",
            "[Epoch  64/100] [Time: 8.03] [D loss: 1.00425] [G loss: 0.50290]\n",
            "[Epoch  65/100] [Batch  56/146] [D loss: 1.00486] [G loss: 0.50420]\n",
            "[Epoch  65/100] [Time: 7.64] [D loss: 1.00261] [G loss: 0.50268]\n",
            "[Epoch  66/100] [Batch  10/146] [D loss: 1.00019] [G loss: 0.50104]\n",
            "[Epoch  66/100] [Batch 110/146] [D loss: 1.00058] [G loss: 0.50116]\n",
            "[Epoch  66/100] [Time: 8.03] [D loss: 1.00041] [G loss: 0.50174]\n",
            "[Epoch  67/100] [Batch  64/146] [D loss: 0.99994] [G loss: 0.50076]\n",
            "[Epoch  67/100] [Time: 7.51] [D loss: 1.00157] [G loss: 0.50134]\n",
            "[Epoch  68/100] [Batch  18/146] [D loss: 1.00107] [G loss: 0.50154]\n",
            "[Epoch  68/100] [Batch 118/146] [D loss: 0.99948] [G loss: 0.50027]\n",
            "[Epoch  68/100] [Time: 7.44] [D loss: 1.00244] [G loss: 0.50252]\n",
            "[Epoch  69/100] [Batch  72/146] [D loss: 1.00352] [G loss: 0.50220]\n",
            "[Epoch  69/100] [Time: 7.47] [D loss: 1.00012] [G loss: 0.50012]\n",
            "[Epoch  70/100] [Batch  26/146] [D loss: 1.00034] [G loss: 0.50099]\n",
            "[Epoch  70/100] [Batch 126/146] [D loss: 1.00500] [G loss: 0.50288]\n",
            "[Epoch  70/100] [Time: 7.47] [D loss: 1.00247] [G loss: 0.50174]\n",
            "[Epoch  71/100] [Batch  80/146] [D loss: 1.00478] [G loss: 0.50371]\n",
            "[Epoch  71/100] [Time: 7.44] [D loss: 1.00318] [G loss: 0.50344]\n",
            "[Epoch  72/100] [Batch  34/146] [D loss: 1.00066] [G loss: 0.50093]\n",
            "[Epoch  72/100] [Batch 134/146] [D loss: 1.00115] [G loss: 0.50064]\n",
            "[Epoch  72/100] [Time: 8.27] [D loss: 1.00234] [G loss: 0.50217]\n",
            "[Epoch  73/100] [Batch  88/146] [D loss: 1.00424] [G loss: 0.50366]\n",
            "[Epoch  73/100] [Time: 7.39] [D loss: 1.00548] [G loss: 0.50410]\n",
            "[Epoch  74/100] [Batch  42/146] [D loss: 1.00439] [G loss: 0.50292]\n",
            "[Epoch  74/100] [Batch 142/146] [D loss: 1.00309] [G loss: 0.50345]\n",
            "[Epoch  74/100] [Time: 8.28] [D loss: 1.00641] [G loss: 0.50457]\n",
            "[Epoch  75/100] [Batch  96/146] [D loss: 1.00497] [G loss: 0.50373]\n",
            "[Epoch  75/100] [Time: 7.43] [D loss: 1.00080] [G loss: 0.50110]\n",
            "[Epoch  76/100] [Batch  50/146] [D loss: 1.00244] [G loss: 0.50350]\n",
            "[Epoch  76/100] [Time: 8.25] [D loss: 1.00644] [G loss: 0.50289]\n",
            "[Epoch  77/100] [Batch   4/146] [D loss: 0.99252] [G loss: 0.49702]\n",
            "[Epoch  77/100] [Batch 104/146] [D loss: 1.00436] [G loss: 0.50276]\n",
            "[Epoch  77/100] [Time: 7.49] [D loss: 1.00707] [G loss: 0.50510]\n",
            "[Epoch  78/100] [Batch  58/146] [D loss: 1.00400] [G loss: 0.50210]\n",
            "[Epoch  78/100] [Time: 7.43] [D loss: 1.01009] [G loss: 0.50677]\n",
            "[Epoch  79/100] [Batch  12/146] [D loss: 1.00712] [G loss: 0.50500]\n",
            "[Epoch  79/100] [Batch 112/146] [D loss: 1.00852] [G loss: 0.50513]\n",
            "[Epoch  79/100] [Time: 8.49] [D loss: 1.00619] [G loss: 0.50527]\n",
            "[Epoch  80/100] [Batch  66/146] [D loss: 1.00781] [G loss: 0.50510]\n",
            "[Epoch  80/100] [Time: 7.85] [D loss: 1.00812] [G loss: 0.50576]\n",
            "[Epoch  81/100] [Batch  20/146] [D loss: 1.00975] [G loss: 0.50584]\n",
            "[Epoch  81/100] [Batch 120/146] [D loss: 1.00336] [G loss: 0.50307]\n",
            "[Epoch  81/100] [Time: 6.74] [D loss: 1.00330] [G loss: 0.50287]\n",
            "[Epoch  82/100] [Batch  74/146] [D loss: 1.00204] [G loss: 0.50135]\n",
            "[Epoch  82/100] [Time: 7.84] [D loss: 1.00483] [G loss: 0.50371]\n",
            "[Epoch  83/100] [Batch  28/146] [D loss: 0.99924] [G loss: 0.50035]\n",
            "[Epoch  83/100] [Batch 128/146] [D loss: 1.00466] [G loss: 0.50434]\n",
            "[Epoch  83/100] [Time: 8.01] [D loss: 1.00886] [G loss: 0.50535]\n",
            "[Epoch  84/100] [Batch  82/146] [D loss: 1.00651] [G loss: 0.50479]\n",
            "[Epoch  84/100] [Time: 7.06] [D loss: 0.99634] [G loss: 0.49901]\n",
            "[Epoch  85/100] [Batch  36/146] [D loss: 0.99727] [G loss: 0.49872]\n",
            "[Epoch  85/100] [Batch 136/146] [D loss: 1.00444] [G loss: 0.50270]\n",
            "[Epoch  85/100] [Time: 6.51] [D loss: 1.00772] [G loss: 0.50514]\n",
            "[Epoch  86/100] [Batch  90/146] [D loss: 1.00543] [G loss: 0.50206]\n",
            "[Epoch  86/100] [Time: 8.51] [D loss: 0.99311] [G loss: 0.49660]\n",
            "[Epoch  87/100] [Batch  44/146] [D loss: 0.98988] [G loss: 0.49504]\n",
            "[Epoch  87/100] [Batch 144/146] [D loss: 1.00894] [G loss: 0.50493]\n",
            "[Epoch  87/100] [Time: 8.53] [D loss: 1.00242] [G loss: 0.50185]\n",
            "[Epoch  88/100] [Batch  98/146] [D loss: 1.00295] [G loss: 0.50168]\n",
            "[Epoch  88/100] [Time: 7.79] [D loss: 1.00655] [G loss: 0.50420]\n",
            "[Epoch  89/100] [Batch  52/146] [D loss: 1.00470] [G loss: 0.50495]\n",
            "[Epoch  89/100] [Time: 7.50] [D loss: 1.00259] [G loss: 0.50338]\n",
            "[Epoch  90/100] [Batch   6/146] [D loss: 1.00025] [G loss: 0.50070]\n",
            "[Epoch  90/100] [Batch 106/146] [D loss: 1.00516] [G loss: 0.50539]\n",
            "[Epoch  90/100] [Time: 6.60] [D loss: 1.00704] [G loss: 0.50433]\n",
            "[Epoch  91/100] [Batch  60/146] [D loss: 0.99872] [G loss: 0.50104]\n",
            "[Epoch  91/100] [Time: 7.51] [D loss: 1.00203] [G loss: 0.50290]\n",
            "[Epoch  92/100] [Batch  14/146] [D loss: 0.99502] [G loss: 0.49903]\n",
            "[Epoch  92/100] [Batch 114/146] [D loss: 1.00158] [G loss: 0.50059]\n",
            "[Epoch  92/100] [Time: 7.82] [D loss: 0.99799] [G loss: 0.50051]\n",
            "[Epoch  93/100] [Batch  68/146] [D loss: 1.00480] [G loss: 0.50224]\n",
            "[Epoch  93/100] [Time: 7.06] [D loss: 1.00491] [G loss: 0.50500]\n",
            "[Epoch  94/100] [Batch  22/146] [D loss: 0.99869] [G loss: 0.49924]\n",
            "[Epoch  94/100] [Batch 122/146] [D loss: 1.00426] [G loss: 0.50349]\n",
            "[Epoch  94/100] [Time: 7.30] [D loss: 1.00665] [G loss: 0.50483]\n",
            "[Epoch  95/100] [Batch  76/146] [D loss: 1.00661] [G loss: 0.50578]\n",
            "[Epoch  95/100] [Time: 7.81] [D loss: 1.00634] [G loss: 0.50519]\n",
            "[Epoch  96/100] [Batch  30/146] [D loss: 1.00007] [G loss: 0.50158]\n",
            "[Epoch  96/100] [Batch 130/146] [D loss: 1.00453] [G loss: 0.50375]\n",
            "[Epoch  96/100] [Time: 7.14] [D loss: 1.00028] [G loss: 0.50263]\n",
            "[Epoch  97/100] [Batch  84/146] [D loss: 0.99687] [G loss: 0.50079]\n",
            "[Epoch  97/100] [Time: 7.23] [D loss: 1.00426] [G loss: 0.50556]\n",
            "[Epoch  98/100] [Batch  38/146] [D loss: 1.00271] [G loss: 0.50248]\n",
            "[Epoch  98/100] [Batch 138/146] [D loss: 1.00056] [G loss: 0.50108]\n",
            "[Epoch  98/100] [Time: 7.76] [D loss: 1.00072] [G loss: 0.50132]\n",
            "[Epoch  99/100] [Batch  92/146] [D loss: 1.00356] [G loss: 0.50278]\n",
            "[Epoch  99/100] [Time: 7.19] [D loss: 1.00266] [G loss: 0.50200]\n",
            "[Epoch 100/100] [Batch  46/146] [D loss: 1.00634] [G loss: 0.50397]\n",
            "[Epoch 100/100] [Batch   0/146] [D loss: 1.00933] [G loss: 0.50540]\n",
            "[Epoch 100/100] [Time: 7.89] [D loss: 1.00933] [G loss: 0.50540]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEcQ_acg1xqu",
        "outputId": "181ed958-3390-4162-a9b7-1160231b52d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "autoencoder.eval()\n",
        "generator.eval()\n",
        "discriminator.eval()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(1, 16, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(16, 32, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(32, 64, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv1d(64, 128, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Conv1d(128, 1, kernel_size=(3,), stride=(1,))\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuCmebS-zPp5"
      },
      "source": [
        "num_fake_batches = 80\n",
        "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
        "for _ in range(num_fake_batches):\n",
        "  z = torch.randn(opt.batch_size, 128, device=device)\n",
        "  generated_batch = generator(z)\n",
        "  fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
        "  fake_data = torch.cat((fake_data, fake_batch.round().to('cpu')), 0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UQvJHSY0a-s"
      },
      "source": [
        "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZOiulo800Ev",
        "outputId": "a45e87b7-97a1-4c4a-8d3b-4c3c34a9ef83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        }
      },
      "source": [
        "gen_samples = fake_data.detach().cpu().numpy()\n",
        "# gen_samples = np.load(os.path.join(opt.expPATH, \"synthetic.npy\"), allow_pickle=False)\n",
        "\n",
        "# Load real data\n",
        "real_samples = train_data[0:gen_samples.shape[0], :]\n",
        "\n",
        "# Dimenstion wise probability\n",
        "prob_real = np.mean(real_samples, axis=0)\n",
        "prob_syn = np.mean(gen_samples, axis=0)\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
        "p1 = plt.scatter(prob_real, prob_syn, c=\"b\", alpha=0.7, label=\"COR-GAN\", s=9)\n",
        "x_max = max(np.max(prob_real), np.max(prob_syn))\n",
        "x = np.linspace(0, x_max + 0.1, 1000)\n",
        "p2 = plt.plot(x, x, linestyle='-', color='k', label=\"Ideal\")  # solid\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.legend(loc=2, prop={'size': 15})\n",
        "# plt.title('Scatter plot p')\n",
        "# plt.xlabel('x')\n",
        "# plt.ylabel('y')\n",
        "plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x960 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uadDPenk74Ok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}