{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCAE.DC.DC.MA.WGAN-GC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1600481393982",
      "display_name": "Python 3.8.5 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZKq_k35W6_a"
      },
      "source": [
        "import argparse\n",
        "import copy\n",
        "import gc\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import h5py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or158iZXcTtF",
        "tags": [],
        "outputId": "2e9dec66-8147-463a-c0a9-9e778797200e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "experimentName = 'DCAE.DC.DC.MA.WGAN-GC'\n",
        "\n",
        "parser.add_argument(\"--DATASETPATH\", type=str, default=os.path.expanduser('~/workspace/data/mimic-iii-processed/BINARY.h5'), help=\"Dataset file\")\n",
        "\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--n_epochs_ae\", type=int, default=200, help=\"number of epochs of autoencoder training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=32, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument('--n_critic', type=int, default=5, help='number of Discriminator iterations per each Generator iteration')\n",
        "parser.add_argument('--clamp', type=float, default=0.01, help='weight clipping value')\n",
        "parser.add_argument(\"--cuda\", type=bool, default=True, help=\"CUDA activation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=128, help=\"dimensionality of the latent space\")\n",
        "\n",
        "parser.add_argument(\"--expPATH\", type=str, default=os.path.expanduser('~/workspace/experiments/pytorch/model/{}'.format(experimentName)), help=\"Training status\")\n",
        "\n",
        "opt = parser.parse_args([])\n",
        "print(opt)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(DATASETPATH='/home/mohi/workspace/data/mimic-iii-processed/BINARY.h5', batch_size=64, clamp=0.01, cuda=True, expPATH='/home/mohi/workspace/experiments/pytorch/model/DCAE.DC.DC.MA.WGAN-GC', latent_dim=128, lr=0.001, n_cpu=32, n_critic=5, n_epochs=200, n_epochs_ae=200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syZZGE3ixcZ",
        "tags": [],
        "outputId": "50d2c81f-8543-4d8e-b31c-570e40cd5718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################\n",
        "### Initialization ###\n",
        "######################\n",
        "\n",
        "# Create experiments DIR\n",
        "if not os.path.exists(opt.expPATH):\n",
        "    os.system('mkdir {0}'.format(opt.expPATH))\n",
        "\n",
        "# opt.seed = 1024 # fix seed\n",
        "opt.seed = random.randint(1, 10000)\n",
        "\n",
        "print('Random Seed: {}'.format(opt.seed))\n",
        "random.seed(opt.seed)\n",
        "torch.manual_seed(opt.seed)\n",
        "np.random.seed(opt.seed)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available() and not opt.cuda:\n",
        "    print(\"WARNING: You have a CUDA device BUT it is not in use...\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")\n",
        "print('using \"{}\" as the tensor processor'.format(device))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed: 7216\n",
            "using \"cuda:0\" as the tensor processor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYJtIeTEil-P"
      },
      "source": [
        "#################################\n",
        "### Reading Dataset from File ###\n",
        "#################################\n",
        "\n",
        "input_data = None\n",
        "with h5py.File(opt.DATASETPATH, 'r') as hf:\n",
        "    input_data = hf.get('dataset')[()]\n",
        "\n",
        "sample_size = input_data.shape[0]\n",
        "feature_size = input_data.shape[1]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP96S8Kbcs0y"
      },
      "source": [
        "#####################\n",
        "### Dataset Model ###\n",
        "#####################\n",
        "\n",
        "class EHRDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.sample_size = dataset.shape[0]\n",
        "        self.feature_size = dataset.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkAxe6HS-KJ",
        "tags": [],
        "outputId": "53c4c0ba-2514-4ef7-b475-180f539ba438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##########################\n",
        "### Dataset Processing ###\n",
        "##########################\n",
        "\n",
        "train_data = input_data[:int(0.8 * sample_size)]\n",
        "test_data = input_data[int(0.8 * sample_size):]\n",
        "print('total samples: {}, features: {}'.format(sample_size, feature_size))\n",
        "print('training data shape: {}, testing data shape: {}, dataset type: {}'.format(train_data.shape, test_data.shape, input_data.dtype))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total samples: 46520, features: 1071\n",
            "training data shape: (37216, 1071), testing data shape: (9304, 1071), dataset type: float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvS8xM1k8Teu"
      },
      "source": [
        "training_dataloader = DataLoader(\n",
        "    EHRDataset(dataset=train_data),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu\n",
        ")\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "    EHRDataset(dataset=test_data),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=opt.n_cpu\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSYLExToytb"
      },
      "source": [
        "########################\n",
        "### AutoEncoder Loss ###\n",
        "########################\n",
        "\n",
        "class AutoEncoderLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoderLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        epsilon = 1e-12\n",
        "        term = target * torch.log(input + epsilon) + (1. - target) * torch.log(1. - input + epsilon)\n",
        "        return -torch.sum(term)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch3VtsBwn5p9"
      },
      "source": [
        "#########################\n",
        "### AutoEncoder Model ###\n",
        "#########################\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=5, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=3, padding=1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=8, stride=3, padding=0),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=8, stride=3, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=32, out_channels=16, kernel_size=5, stride=3, padding=1),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=16, out_channels=8, kernel_size=5, stride=2, padding=1),\n",
        "            nn.BatchNorm1d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x.view(-1, 1, feature_size))\n",
        "\n",
        "    def decode(self, x):\n",
        "        return torch.squeeze(self.decoder(x.view(-1, 64, 28)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decode(self.encode(x))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgp1ytGXFDwS"
      },
      "source": [
        "############################\n",
        "### Model Initialization ###\n",
        "############################\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "autoencoder = Autoencoder().cuda() if opt.cuda else Autoencoder()\n",
        "optimizer_A = torch.optim.Adam(autoencoder.parameters(), lr=opt.lr)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWlJt7_892vs",
        "tags": []
      },
      "source": [
        "#####################################\n",
        "###### AutoEncoder Training #########\n",
        "#####################################\n",
        "\n",
        "criterion = AutoEncoderLoss()\n",
        "\n",
        "if False:\n",
        "    for epoch in range(opt.n_epochs_ae):\n",
        "        train_loss = 0\n",
        "        autoencoder.train()\n",
        "        for batch in training_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            gen_batch = autoencoder(batch)\n",
        "            loss_A = criterion(gen_batch, batch)\n",
        "            optimizer_A.zero_grad()\n",
        "            loss_A.backward()\n",
        "            optimizer_A.step()\n",
        "            train_loss += loss_A\n",
        "\n",
        "        errors = 0\n",
        "        test_loss = 0\n",
        "        autoencoder.eval()\n",
        "        for batch in testing_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            gen_batch = autoencoder(batch)\n",
        "            test_loss += criterion(gen_batch, batch)\n",
        "\n",
        "            gen_batch = gen_batch.round()\n",
        "            diff = torch.abs(gen_batch - batch).view(-1).detach().cpu().numpy()\n",
        "            wrong_digits = diff[diff > 0.5]\n",
        "            errors += len(wrong_digits)\n",
        "        print(\"[Epoch {:3d}/{:3d}] [Training Loss: {:10.2f}] [Testing Loss: {:10.2f}] [errors: {:6d}]\".format(epoch + 1, opt.n_epochs_ae, train_loss, test_loss, errors), flush=True)\n",
        "    torch.save(autoencoder.state_dict(), opt.expPATH + '/autoencoder.model')\n",
        "else:\n",
        "    autoencoder.load_state_dict(torch.load(opt.expPATH + '/autoencoder.model'))\n",
        "    autoencoder.eval()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xHg4CmL6BW",
        "outputId": "76854ac9-0b94-4947-b59f-9a43cc4307ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "errors = 0\n",
        "for batch in testing_dataloader:\n",
        "    batch = batch.to(device)\n",
        "    gen_batch = autoencoder(batch).round()\n",
        "    diff = torch.abs(gen_batch - batch).view(-1).detach().cpu().numpy()\n",
        "    wrong_digits = diff[diff > 0.5]\n",
        "    errors += len(wrong_digits)\n",
        "print(\"total number of wrong digits: {}\".format(errors))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of wrong digits: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0I5dbr5cGlQ"
      },
      "source": [
        "#############################\n",
        "### Generator Model ###\n",
        "#############################\n",
        "\n",
        "# Output should be 64 * 28\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose1d(opt.latent_dim, 256, 7, 2, 0),\n",
        "            nn.BatchNorm1d(256, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm1d(128, eps=0.0001, momentum=0.01),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.ConvTranspose1d(128, 64, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x.view(-1, opt.latent_dim, 1))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oIATq7r9ek"
      },
      "source": [
        "###########################\n",
        "### Discriminator Model ###\n",
        "###########################\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        ndf = 16\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # minibatch averaging\n",
        "            nn.Linear(2 * feature_size, feature_size),\n",
        "\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv1d(1, ndf, 8, 4, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv1d(ndf, ndf * 2, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv1d(ndf * 2, ndf * 4, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv1d(ndf * 4, ndf * 8, 8, 4, 1),\n",
        "            nn.BatchNorm1d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv1d(ndf * 8, 1, 3, 1, 0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # minibatch averaging\n",
        "        x_mean = torch.mean(x, 0).repeat(x.shape[0], 1)\n",
        "        x = torch.cat((x, x_mean), 1)\n",
        "        return self.model(x.view(-1, 1, 2 * feature_size)).view(-1, 1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inVoiMu9QS_",
        "tags": []
      },
      "source": [
        "############################\n",
        "### Model Initialization ###\n",
        "############################\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "generator = Generator().cuda() if opt.cuda else Generator()\n",
        "discriminator = Discriminator().cuda() if opt.cuda else Discriminator()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83EKUAC3Edo",
        "outputId": "62c5ebd0-edcb-4961-8cc5-9cf00f96482b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if True:\n",
        "    batches_done = 0\n",
        "\n",
        "    discriminator.train()\n",
        "    generator.train()\n",
        "\n",
        "    for epoch in range(opt.n_epochs):\n",
        "        epoch_start = time.time()\n",
        "        for _ in range(opt.n_critic):\n",
        "            for batch in training_dataloader:\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                for dp in discriminator.parameters():\n",
        "                    dp.requires_grad = True\n",
        "\n",
        "                optimizer_D.zero_grad()\n",
        "\n",
        "                z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
        "                fake_batch = autoencoder.decode(generator(z))\n",
        "                loss_D = torch.mean(discriminator(batch), dim=0) - torch.mean(discriminator(fake_batch.detach()), dim=0)\n",
        "                loss_D.backward()\n",
        "\n",
        "                optimizer_D.step()\n",
        "\n",
        "                for dp in discriminator.parameters():\n",
        "                    dp.data.clamp_(-opt.clamp, opt.clamp)\n",
        "\n",
        "                if batches_done % opt.n_critic == 0:\n",
        "                    # -----------------\n",
        "                    #  Train Generator\n",
        "                    # -----------------\n",
        "                    for dp in discriminator.parameters():\n",
        "                        dp.requires_grad = False\n",
        "\n",
        "                    optimizer_G.zero_grad()\n",
        "\n",
        "                    z = torch.randn(batch.shape[0], opt.latent_dim, device=device)\n",
        "                    fake_batch = autoencoder.decode(generator(z))\n",
        "                    loss_G = torch.mean(discriminator(fake_batch), dim=0)\n",
        "                    loss_G.backward()\n",
        "\n",
        "                    optimizer_G.step()\n",
        "\n",
        "                batches_done += 1\n",
        "                if batches_done % (100 * opt.n_critic) == 0:\n",
        "                    print('[Epoch {:3d}/{:3d}] [Batch {:4d}/{:4d}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, batches_done % (opt.n_critic * len(training_dataloader)), opt.n_critic * len(training_dataloader), loss_D.item(), loss_G.item()))\n",
        "\n",
        "        print('[Epoch {:3d}/{:3d}] [Time: {:.2f}] [D loss: {:.6f}] [G loss: {:.6f}]'.format(epoch + 1, opt.n_epochs, time.time() - epoch_start, loss_D.item(), loss_G.item()))\n",
        "\n",
        "    torch.save(generator.state_dict(), opt.expPATH + '/generator.model')\n",
        "    torch.save(discriminator.state_dict(), opt.expPATH + '/discriminator.model')\n",
        "else:\n",
        "    generator.load_state_dict(torch.load(opt.expPATH + '/generator.model'))\n",
        "    discriminator.load_state_dict(torch.load(opt.expPATH + '/discriminator.model'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch   1/200] [Batch  500/2910] [D loss: -0.016587] [G loss: 0.508294]\n",
            "[Epoch   1/200] [Batch 1000/2910] [D loss: -0.016785] [G loss: 0.508392]\n",
            "[Epoch   1/200] [Batch 1500/2910] [D loss: -0.016845] [G loss: 0.508422]\n",
            "[Epoch   1/200] [Batch 2000/2910] [D loss: -0.016875] [G loss: 0.508437]\n",
            "[Epoch   1/200] [Batch 2500/2910] [D loss: -0.016895] [G loss: 0.508448]\n",
            "[Epoch   1/200] [Time: 30.97] [D loss: -0.016912] [G loss: 0.508456]\n",
            "[Epoch   2/200] [Batch   90/2910] [D loss: -0.016918] [G loss: 0.508459]\n",
            "[Epoch   2/200] [Batch  590/2910] [D loss: -0.016932] [G loss: 0.508466]\n",
            "[Epoch   2/200] [Batch 1090/2910] [D loss: -0.016940] [G loss: 0.508470]\n",
            "[Epoch   2/200] [Batch 1590/2910] [D loss: -0.016948] [G loss: 0.508474]\n",
            "[Epoch   2/200] [Batch 2090/2910] [D loss: -0.016950] [G loss: 0.508475]\n",
            "[Epoch   2/200] [Batch 2590/2910] [D loss: -0.016953] [G loss: 0.508477]\n",
            "[Epoch   2/200] [Time: 35.64] [D loss: -0.016952] [G loss: 0.508476]\n",
            "[Epoch   3/200] [Batch  180/2910] [D loss: -0.016954] [G loss: 0.508477]\n",
            "[Epoch   3/200] [Batch  680/2910] [D loss: -0.016955] [G loss: 0.508477]\n",
            "[Epoch   3/200] [Batch 1180/2910] [D loss: -0.016955] [G loss: 0.508478]\n",
            "[Epoch   3/200] [Batch 1680/2910] [D loss: -0.016955] [G loss: 0.508477]\n",
            "[Epoch   3/200] [Batch 2180/2910] [D loss: -0.016956] [G loss: 0.508477]\n",
            "[Epoch   3/200] [Batch 2680/2910] [D loss: -0.016956] [G loss: 0.508477]\n",
            "[Epoch   3/200] [Time: 34.15] [D loss: -0.016954] [G loss: 0.508478]\n",
            "[Epoch   4/200] [Batch  270/2910] [D loss: -0.016956] [G loss: 0.508478]\n",
            "[Epoch   4/200] [Batch  770/2910] [D loss: -0.016955] [G loss: 0.508476]\n",
            "[Epoch   4/200] [Batch 1270/2910] [D loss: -0.016956] [G loss: 0.508479]\n",
            "[Epoch   4/200] [Batch 1770/2910] [D loss: -0.016956] [G loss: 0.508480]\n",
            "[Epoch   4/200] [Batch 2270/2910] [D loss: -0.016956] [G loss: 0.508483]\n",
            "[Epoch   4/200] [Batch 2770/2910] [D loss: -0.016975] [G loss: 0.508487]\n",
            "[Epoch   4/200] [Time: 35.82] [D loss: -0.016977] [G loss: 0.508488]\n",
            "[Epoch   5/200] [Batch  360/2910] [D loss: -0.016978] [G loss: 0.508487]\n",
            "[Epoch   5/200] [Batch  860/2910] [D loss: -0.016978] [G loss: 0.508489]\n",
            "[Epoch   5/200] [Batch 1360/2910] [D loss: -0.016978] [G loss: 0.508490]\n",
            "[Epoch   5/200] [Batch 1860/2910] [D loss: -0.016979] [G loss: 0.508490]\n",
            "[Epoch   5/200] [Batch 2360/2910] [D loss: -0.016979] [G loss: 0.508487]\n",
            "[Epoch   5/200] [Batch 2860/2910] [D loss: -0.016975] [G loss: 0.508487]\n",
            "[Epoch   5/200] [Time: 34.14] [D loss: -0.016977] [G loss: 0.508490]\n",
            "[Epoch   6/200] [Batch  450/2910] [D loss: -0.016978] [G loss: 0.508491]\n",
            "[Epoch   6/200] [Batch  950/2910] [D loss: -0.016977] [G loss: 0.508464]\n",
            "[Epoch   6/200] [Batch 1450/2910] [D loss: -0.016974] [G loss: 0.508484]\n",
            "[Epoch   6/200] [Batch 1950/2910] [D loss: -0.016977] [G loss: 0.508489]\n",
            "[Epoch   6/200] [Batch 2450/2910] [D loss: -0.016978] [G loss: 0.508490]\n",
            "[Epoch   6/200] [Time: 35.33] [D loss: -0.016979] [G loss: 0.508489]\n",
            "[Epoch   7/200] [Batch   40/2910] [D loss: -0.016978] [G loss: 0.508490]\n",
            "[Epoch   7/200] [Batch  540/2910] [D loss: -0.016974] [G loss: 0.508493]\n",
            "[Epoch   7/200] [Batch 1040/2910] [D loss: -0.016936] [G loss: 0.508457]\n",
            "[Epoch   7/200] [Batch 1540/2910] [D loss: -0.016974] [G loss: 0.508486]\n",
            "[Epoch   7/200] [Batch 2040/2910] [D loss: -0.016958] [G loss: 0.508477]\n",
            "[Epoch   7/200] [Batch 2540/2910] [D loss: -0.016956] [G loss: 0.508469]\n",
            "[Epoch   7/200] [Time: 35.27] [D loss: -0.016970] [G loss: 0.508481]\n",
            "[Epoch   8/200] [Batch  130/2910] [D loss: -0.016963] [G loss: 0.508482]\n",
            "[Epoch   8/200] [Batch  630/2910] [D loss: -0.016973] [G loss: 0.508489]\n",
            "[Epoch   8/200] [Batch 1130/2910] [D loss: -0.016939] [G loss: 0.508463]\n",
            "[Epoch   8/200] [Batch 1630/2910] [D loss: -0.016950] [G loss: 0.508436]\n",
            "[Epoch   8/200] [Batch 2130/2910] [D loss: -0.016955] [G loss: 0.508503]\n",
            "[Epoch   8/200] [Batch 2630/2910] [D loss: -0.016957] [G loss: 0.508482]\n",
            "[Epoch   8/200] [Time: 35.30] [D loss: -0.016959] [G loss: 0.508471]\n",
            "[Epoch   9/200] [Batch  220/2910] [D loss: -0.016952] [G loss: 0.508456]\n",
            "[Epoch   9/200] [Batch  720/2910] [D loss: -0.016946] [G loss: 0.508470]\n",
            "[Epoch   9/200] [Batch 1220/2910] [D loss: -0.016951] [G loss: 0.508455]\n",
            "[Epoch   9/200] [Batch 1720/2910] [D loss: -0.016950] [G loss: 0.508490]\n",
            "[Epoch   9/200] [Batch 2220/2910] [D loss: -0.016949] [G loss: 0.508471]\n",
            "[Epoch   9/200] [Batch 2720/2910] [D loss: -0.016953] [G loss: 0.508479]\n",
            "[Epoch   9/200] [Time: 35.05] [D loss: -0.016947] [G loss: 0.508504]\n",
            "[Epoch  10/200] [Batch  310/2910] [D loss: -0.016955] [G loss: 0.508488]\n",
            "[Epoch  10/200] [Batch  810/2910] [D loss: -0.016954] [G loss: 0.508472]\n",
            "[Epoch  10/200] [Batch 1310/2910] [D loss: -0.016967] [G loss: 0.508494]\n",
            "[Epoch  10/200] [Batch 1810/2910] [D loss: -0.016953] [G loss: 0.508485]\n",
            "[Epoch  10/200] [Batch 2310/2910] [D loss: -0.016958] [G loss: 0.508451]\n",
            "[Epoch  10/200] [Batch 2810/2910] [D loss: -0.016963] [G loss: 0.508483]\n",
            "[Epoch  10/200] [Time: 34.71] [D loss: -0.016939] [G loss: 0.508471]\n",
            "[Epoch  11/200] [Batch  400/2910] [D loss: -0.016943] [G loss: 0.508453]\n",
            "[Epoch  11/200] [Batch  900/2910] [D loss: -0.016955] [G loss: 0.508459]\n",
            "[Epoch  11/200] [Batch 1400/2910] [D loss: -0.016952] [G loss: 0.508486]\n",
            "[Epoch  11/200] [Batch 1900/2910] [D loss: -0.016929] [G loss: 0.508474]\n",
            "[Epoch  11/200] [Batch 2400/2910] [D loss: -0.016937] [G loss: 0.508468]\n",
            "[Epoch  11/200] [Batch 2900/2910] [D loss: -0.016944] [G loss: 0.508484]\n",
            "[Epoch  11/200] [Time: 34.47] [D loss: -0.016943] [G loss: 0.508472]\n",
            "[Epoch  12/200] [Batch  490/2910] [D loss: -0.016952] [G loss: 0.508481]\n",
            "[Epoch  12/200] [Batch  990/2910] [D loss: -0.016945] [G loss: 0.508464]\n",
            "[Epoch  12/200] [Batch 1490/2910] [D loss: -0.016912] [G loss: 0.508488]\n",
            "[Epoch  12/200] [Batch 1990/2910] [D loss: -0.016959] [G loss: 0.508454]\n",
            "[Epoch  12/200] [Batch 2490/2910] [D loss: -0.016916] [G loss: 0.508451]\n",
            "[Epoch  12/200] [Time: 34.40] [D loss: -0.016910] [G loss: 0.508424]\n",
            "[Epoch  13/200] [Batch   80/2910] [D loss: -0.016924] [G loss: 0.508448]\n",
            "[Epoch  13/200] [Batch  580/2910] [D loss: -0.016948] [G loss: 0.508477]\n",
            "[Epoch  13/200] [Batch 1080/2910] [D loss: -0.016945] [G loss: 0.508451]\n",
            "[Epoch  13/200] [Batch 1580/2910] [D loss: -0.016936] [G loss: 0.508473]\n",
            "[Epoch  13/200] [Batch 2080/2910] [D loss: -0.016944] [G loss: 0.508454]\n",
            "[Epoch  13/200] [Batch 2580/2910] [D loss: -0.016935] [G loss: 0.508469]\n",
            "[Epoch  13/200] [Time: 31.94] [D loss: -0.016775] [G loss: 0.508437]\n",
            "[Epoch  14/200] [Batch  170/2910] [D loss: -0.016951] [G loss: 0.508480]\n",
            "[Epoch  14/200] [Batch  670/2910] [D loss: -0.016933] [G loss: 0.508454]\n",
            "[Epoch  14/200] [Batch 1170/2910] [D loss: -0.016924] [G loss: 0.508450]\n",
            "[Epoch  14/200] [Batch 1670/2910] [D loss: -0.016462] [G loss: 0.508664]\n",
            "[Epoch  14/200] [Batch 2170/2910] [D loss: -0.016959] [G loss: 0.508475]\n",
            "[Epoch  14/200] [Batch 2670/2910] [D loss: -0.016967] [G loss: 0.508482]\n",
            "[Epoch  14/200] [Time: 35.21] [D loss: -0.016950] [G loss: 0.508474]\n",
            "[Epoch  15/200] [Batch  260/2910] [D loss: -0.016928] [G loss: 0.508437]\n",
            "[Epoch  15/200] [Batch  760/2910] [D loss: -0.016691] [G loss: 0.508498]\n",
            "[Epoch  15/200] [Batch 1260/2910] [D loss: -0.016943] [G loss: 0.508479]\n",
            "[Epoch  15/200] [Batch 1760/2910] [D loss: -0.016947] [G loss: 0.508474]\n",
            "[Epoch  15/200] [Batch 2260/2910] [D loss: -0.016881] [G loss: 0.508463]\n",
            "[Epoch  15/200] [Batch 2760/2910] [D loss: -0.016928] [G loss: 0.508465]\n",
            "[Epoch  15/200] [Time: 35.05] [D loss: -0.016877] [G loss: 0.508247]\n",
            "[Epoch  16/200] [Batch  350/2910] [D loss: -0.016914] [G loss: 0.508387]\n",
            "[Epoch  16/200] [Batch  850/2910] [D loss: -0.016828] [G loss: 0.508418]\n",
            "[Epoch  16/200] [Batch 1350/2910] [D loss: -0.016805] [G loss: 0.508439]\n",
            "[Epoch  16/200] [Batch 1850/2910] [D loss: -0.016962] [G loss: 0.508481]\n",
            "[Epoch  16/200] [Batch 2350/2910] [D loss: -0.016967] [G loss: 0.508485]\n",
            "[Epoch  16/200] [Batch 2850/2910] [D loss: -0.016962] [G loss: 0.508487]\n",
            "[Epoch  16/200] [Time: 32.98] [D loss: -0.016886] [G loss: 0.508468]\n",
            "[Epoch  17/200] [Batch  440/2910] [D loss: -0.016898] [G loss: 0.508472]\n",
            "[Epoch  17/200] [Batch  940/2910] [D loss: -0.016536] [G loss: 0.508375]\n",
            "[Epoch  17/200] [Batch 1440/2910] [D loss: -0.016608] [G loss: 0.507419]\n",
            "[Epoch  17/200] [Batch 1940/2910] [D loss: -0.016665] [G loss: 0.508269]\n",
            "[Epoch  17/200] [Batch 2440/2910] [D loss: -0.016450] [G loss: 0.507974]\n",
            "[Epoch  17/200] [Time: 34.69] [D loss: -0.015590] [G loss: 0.507991]\n",
            "[Epoch  18/200] [Batch   30/2910] [D loss: -0.016066] [G loss: 0.508348]\n",
            "[Epoch  18/200] [Batch  530/2910] [D loss: -0.016800] [G loss: 0.508446]\n",
            "[Epoch  18/200] [Batch 1030/2910] [D loss: -0.016887] [G loss: 0.508428]\n",
            "[Epoch  18/200] [Batch 1530/2910] [D loss: -0.016228] [G loss: 0.508069]\n",
            "[Epoch  18/200] [Batch 2030/2910] [D loss: -0.016891] [G loss: 0.508414]\n",
            "[Epoch  18/200] [Batch 2530/2910] [D loss: -0.016647] [G loss: 0.508387]\n",
            "[Epoch  18/200] [Time: 35.18] [D loss: -0.016595] [G loss: 0.508299]\n",
            "[Epoch  19/200] [Batch  120/2910] [D loss: -0.015413] [G loss: 0.508047]\n",
            "[Epoch  19/200] [Batch  620/2910] [D loss: -0.014248] [G loss: 0.508412]\n",
            "[Epoch  19/200] [Batch 1120/2910] [D loss: -0.016460] [G loss: 0.508110]\n",
            "[Epoch  19/200] [Batch 1620/2910] [D loss: -0.016662] [G loss: 0.507856]\n",
            "[Epoch  19/200] [Batch 2120/2910] [D loss: -0.016395] [G loss: 0.508349]\n",
            "[Epoch  19/200] [Batch 2620/2910] [D loss: -0.016932] [G loss: 0.508467]\n",
            "[Epoch  19/200] [Time: 35.62] [D loss: -0.016946] [G loss: 0.508476]\n",
            "[Epoch  20/200] [Batch  210/2910] [D loss: -0.016943] [G loss: 0.508459]\n",
            "[Epoch  20/200] [Batch  710/2910] [D loss: -0.016666] [G loss: 0.508451]\n",
            "[Epoch  20/200] [Batch 1210/2910] [D loss: -0.016888] [G loss: 0.508456]\n",
            "[Epoch  20/200] [Batch 1710/2910] [D loss: -0.016954] [G loss: 0.508476]\n",
            "[Epoch  20/200] [Batch 2210/2910] [D loss: -0.016949] [G loss: 0.508471]\n",
            "[Epoch  20/200] [Batch 2710/2910] [D loss: -0.015115] [G loss: 0.508230]\n",
            "[Epoch  20/200] [Time: 35.08] [D loss: -0.015470] [G loss: 0.508077]\n",
            "[Epoch  21/200] [Batch  300/2910] [D loss: -0.016385] [G loss: 0.508200]\n",
            "[Epoch  21/200] [Batch  800/2910] [D loss: -0.015331] [G loss: 0.507931]\n",
            "[Epoch  21/200] [Batch 1300/2910] [D loss: -0.016327] [G loss: 0.508278]\n",
            "[Epoch  21/200] [Batch 1800/2910] [D loss: -0.016059] [G loss: 0.507954]\n",
            "[Epoch  21/200] [Batch 2300/2910] [D loss: -0.016186] [G loss: 0.508367]\n",
            "[Epoch  21/200] [Batch 2800/2910] [D loss: -0.015256] [G loss: 0.508352]\n",
            "[Epoch  21/200] [Time: 35.66] [D loss: -0.016462] [G loss: 0.508402]\n",
            "[Epoch  22/200] [Batch  390/2910] [D loss: -0.015871] [G loss: 0.508387]\n",
            "[Epoch  22/200] [Batch  890/2910] [D loss: -0.015559] [G loss: 0.508051]\n",
            "[Epoch  22/200] [Batch 1390/2910] [D loss: -0.016692] [G loss: 0.508216]\n",
            "[Epoch  22/200] [Batch 1890/2910] [D loss: -0.015597] [G loss: 0.508262]\n",
            "[Epoch  22/200] [Batch 2390/2910] [D loss: -0.015964] [G loss: 0.507144]\n",
            "[Epoch  22/200] [Batch 2890/2910] [D loss: -0.016616] [G loss: 0.508293]\n",
            "[Epoch  22/200] [Time: 35.55] [D loss: -0.016465] [G loss: 0.508028]\n",
            "[Epoch  23/200] [Batch  480/2910] [D loss: -0.016391] [G loss: 0.507918]\n",
            "[Epoch  23/200] [Batch  980/2910] [D loss: -0.016017] [G loss: 0.508276]\n",
            "[Epoch  23/200] [Batch 1480/2910] [D loss: -0.015436] [G loss: 0.507442]\n",
            "[Epoch  23/200] [Batch 1980/2910] [D loss: -0.015478] [G loss: 0.507264]\n",
            "[Epoch  23/200] [Batch 2480/2910] [D loss: -0.016329] [G loss: 0.508441]\n",
            "[Epoch  23/200] [Time: 34.89] [D loss: -0.016369] [G loss: 0.508199]\n",
            "[Epoch  24/200] [Batch   70/2910] [D loss: -0.014405] [G loss: 0.508203]\n",
            "[Epoch  24/200] [Batch  570/2910] [D loss: -0.016119] [G loss: 0.508254]\n",
            "[Epoch  24/200] [Batch 1070/2910] [D loss: -0.015840] [G loss: 0.507835]\n",
            "[Epoch  24/200] [Batch 1570/2910] [D loss: -0.016489] [G loss: 0.507774]\n",
            "[Epoch  24/200] [Batch 2070/2910] [D loss: -0.016498] [G loss: 0.507588]\n",
            "[Epoch  24/200] [Batch 2570/2910] [D loss: -0.015238] [G loss: 0.506461]\n",
            "[Epoch  24/200] [Time: 35.58] [D loss: -0.016270] [G loss: 0.508354]\n",
            "[Epoch  25/200] [Batch  160/2910] [D loss: -0.016355] [G loss: 0.507882]\n",
            "[Epoch  25/200] [Batch  660/2910] [D loss: -0.014370] [G loss: 0.507973]\n",
            "[Epoch  25/200] [Batch 1160/2910] [D loss: -0.014752] [G loss: 0.508146]\n",
            "[Epoch  25/200] [Batch 1660/2910] [D loss: -0.015301] [G loss: 0.508491]\n",
            "[Epoch  25/200] [Batch 2160/2910] [D loss: -0.016347] [G loss: 0.508282]\n",
            "[Epoch  25/200] [Batch 2660/2910] [D loss: -0.016104] [G loss: 0.508207]\n",
            "[Epoch  25/200] [Time: 35.49] [D loss: -0.015889] [G loss: 0.507491]\n",
            "[Epoch  26/200] [Batch  250/2910] [D loss: -0.016203] [G loss: 0.508386]\n",
            "[Epoch  26/200] [Batch  750/2910] [D loss: -0.015435] [G loss: 0.507879]\n",
            "[Epoch  26/200] [Batch 1250/2910] [D loss: -0.014321] [G loss: 0.507571]\n",
            "[Epoch  26/200] [Batch 1750/2910] [D loss: -0.015855] [G loss: 0.507932]\n",
            "[Epoch  26/200] [Batch 2250/2910] [D loss: -0.015849] [G loss: 0.508371]\n",
            "[Epoch  26/200] [Batch 2750/2910] [D loss: -0.015434] [G loss: 0.507566]\n",
            "[Epoch  26/200] [Time: 34.53] [D loss: -0.016498] [G loss: 0.508042]\n",
            "[Epoch  27/200] [Batch  340/2910] [D loss: -0.015122] [G loss: 0.507607]\n",
            "[Epoch  27/200] [Batch  840/2910] [D loss: -0.016324] [G loss: 0.508412]\n",
            "[Epoch  27/200] [Batch 1340/2910] [D loss: -0.015764] [G loss: 0.508107]\n",
            "[Epoch  27/200] [Batch 1840/2910] [D loss: -0.015661] [G loss: 0.508247]\n",
            "[Epoch  27/200] [Batch 2340/2910] [D loss: -0.015478] [G loss: 0.508054]\n",
            "[Epoch  27/200] [Batch 2840/2910] [D loss: -0.016347] [G loss: 0.508129]\n",
            "[Epoch  27/200] [Time: 32.43] [D loss: -0.011997] [G loss: 0.508440]\n",
            "[Epoch  28/200] [Batch  430/2910] [D loss: -0.012869] [G loss: 0.508345]\n",
            "[Epoch  28/200] [Batch  930/2910] [D loss: -0.012237] [G loss: 0.506998]\n",
            "[Epoch  28/200] [Batch 1430/2910] [D loss: -0.015818] [G loss: 0.507046]\n",
            "[Epoch  28/200] [Batch 1930/2910] [D loss: -0.014060] [G loss: 0.507401]\n",
            "[Epoch  28/200] [Batch 2430/2910] [D loss: -0.011994] [G loss: 0.508244]\n",
            "[Epoch  28/200] [Time: 34.99] [D loss: -0.015861] [G loss: 0.506426]\n",
            "[Epoch  29/200] [Batch   20/2910] [D loss: -0.014865] [G loss: 0.508113]\n",
            "[Epoch  29/200] [Batch  520/2910] [D loss: -0.013501] [G loss: 0.506267]\n",
            "[Epoch  29/200] [Batch 1020/2910] [D loss: -0.015297] [G loss: 0.507137]\n",
            "[Epoch  29/200] [Batch 1520/2910] [D loss: -0.014901] [G loss: 0.507860]\n",
            "[Epoch  29/200] [Batch 2020/2910] [D loss: -0.015178] [G loss: 0.507990]\n",
            "[Epoch  29/200] [Batch 2520/2910] [D loss: -0.016019] [G loss: 0.508153]\n",
            "[Epoch  29/200] [Time: 35.41] [D loss: -0.013962] [G loss: 0.508262]\n",
            "[Epoch  30/200] [Batch  110/2910] [D loss: -0.014493] [G loss: 0.507468]\n",
            "[Epoch  30/200] [Batch  610/2910] [D loss: -0.015627] [G loss: 0.508007]\n",
            "[Epoch  30/200] [Batch 1110/2910] [D loss: -0.015452] [G loss: 0.505403]\n",
            "[Epoch  30/200] [Batch 1610/2910] [D loss: -0.012169] [G loss: 0.504521]\n",
            "[Epoch  30/200] [Batch 2110/2910] [D loss: -0.012933] [G loss: 0.506650]\n",
            "[Epoch  30/200] [Batch 2610/2910] [D loss: -0.011982] [G loss: 0.508419]\n",
            "[Epoch  30/200] [Time: 35.46] [D loss: -0.015722] [G loss: 0.508107]\n",
            "[Epoch  31/200] [Batch  200/2910] [D loss: -0.012133] [G loss: 0.507594]\n",
            "[Epoch  31/200] [Batch  700/2910] [D loss: -0.016280] [G loss: 0.508209]\n",
            "[Epoch  31/200] [Batch 1200/2910] [D loss: -0.014907] [G loss: 0.507757]\n",
            "[Epoch  31/200] [Batch 1700/2910] [D loss: -0.015893] [G loss: 0.507466]\n",
            "[Epoch  31/200] [Batch 2200/2910] [D loss: -0.015787] [G loss: 0.507794]\n",
            "[Epoch  31/200] [Batch 2700/2910] [D loss: -0.014971] [G loss: 0.506967]\n",
            "[Epoch  31/200] [Time: 33.40] [D loss: -0.012803] [G loss: 0.507587]\n",
            "[Epoch  32/200] [Batch  290/2910] [D loss: -0.013676] [G loss: 0.507645]\n",
            "[Epoch  32/200] [Batch  790/2910] [D loss: -0.015119] [G loss: 0.507362]\n",
            "[Epoch  32/200] [Batch 1290/2910] [D loss: -0.015288] [G loss: 0.506684]\n",
            "[Epoch  32/200] [Batch 1790/2910] [D loss: -0.014454] [G loss: 0.502279]\n",
            "[Epoch  32/200] [Batch 2290/2910] [D loss: -0.012648] [G loss: 0.508165]\n",
            "[Epoch  32/200] [Batch 2790/2910] [D loss: -0.015695] [G loss: 0.507527]\n",
            "[Epoch  32/200] [Time: 35.48] [D loss: -0.013956] [G loss: 0.506747]\n",
            "[Epoch  33/200] [Batch  380/2910] [D loss: -0.013002] [G loss: 0.506166]\n",
            "[Epoch  33/200] [Batch  880/2910] [D loss: -0.013913] [G loss: 0.506845]\n",
            "[Epoch  33/200] [Batch 1380/2910] [D loss: -0.013691] [G loss: 0.507946]\n",
            "[Epoch  33/200] [Batch 1880/2910] [D loss: -0.016130] [G loss: 0.508160]\n",
            "[Epoch  33/200] [Batch 2380/2910] [D loss: -0.013860] [G loss: 0.507509]\n",
            "[Epoch  33/200] [Batch 2880/2910] [D loss: -0.015766] [G loss: 0.508213]\n",
            "[Epoch  33/200] [Time: 33.03] [D loss: -0.011732] [G loss: 0.507717]\n",
            "[Epoch  34/200] [Batch  470/2910] [D loss: -0.015466] [G loss: 0.507371]\n",
            "[Epoch  34/200] [Batch  970/2910] [D loss: -0.016198] [G loss: 0.507537]\n",
            "[Epoch  34/200] [Batch 1470/2910] [D loss: -0.016178] [G loss: 0.508060]\n",
            "[Epoch  34/200] [Batch 1970/2910] [D loss: -0.013939] [G loss: 0.508219]\n",
            "[Epoch  34/200] [Batch 2470/2910] [D loss: -0.012319] [G loss: 0.505724]\n",
            "[Epoch  34/200] [Time: 35.79] [D loss: -0.009857] [G loss: 0.506763]\n",
            "[Epoch  35/200] [Batch   60/2910] [D loss: -0.014362] [G loss: 0.507178]\n",
            "[Epoch  35/200] [Batch  560/2910] [D loss: -0.015076] [G loss: 0.508180]\n",
            "[Epoch  35/200] [Batch 1060/2910] [D loss: -0.014680] [G loss: 0.506283]\n",
            "[Epoch  35/200] [Batch 1560/2910] [D loss: -0.010789] [G loss: 0.507760]\n",
            "[Epoch  35/200] [Batch 2060/2910] [D loss: -0.014143] [G loss: 0.507918]\n",
            "[Epoch  35/200] [Batch 2560/2910] [D loss: -0.015161] [G loss: 0.507937]\n",
            "[Epoch  35/200] [Time: 33.48] [D loss: -0.015042] [G loss: 0.508045]\n",
            "[Epoch  36/200] [Batch  150/2910] [D loss: -0.012988] [G loss: 0.507455]\n",
            "[Epoch  36/200] [Batch  650/2910] [D loss: -0.015438] [G loss: 0.505877]\n",
            "[Epoch  36/200] [Batch 1150/2910] [D loss: -0.015691] [G loss: 0.507914]\n",
            "[Epoch  36/200] [Batch 1650/2910] [D loss: -0.014560] [G loss: 0.506019]\n",
            "[Epoch  36/200] [Batch 2150/2910] [D loss: -0.015440] [G loss: 0.505800]\n",
            "[Epoch  36/200] [Batch 2650/2910] [D loss: -0.011237] [G loss: 0.508224]\n",
            "[Epoch  36/200] [Time: 35.09] [D loss: -0.011314] [G loss: 0.508318]\n",
            "[Epoch  37/200] [Batch  240/2910] [D loss: -0.015268] [G loss: 0.505988]\n",
            "[Epoch  37/200] [Batch  740/2910] [D loss: -0.013263] [G loss: 0.506180]\n",
            "[Epoch  37/200] [Batch 1240/2910] [D loss: -0.016208] [G loss: 0.508185]\n",
            "[Epoch  37/200] [Batch 1740/2910] [D loss: -0.014790] [G loss: 0.508031]\n",
            "[Epoch  37/200] [Batch 2240/2910] [D loss: -0.015361] [G loss: 0.508174]\n",
            "[Epoch  37/200] [Batch 2740/2910] [D loss: -0.012687] [G loss: 0.507401]\n",
            "[Epoch  37/200] [Time: 35.38] [D loss: -0.015654] [G loss: 0.508118]\n",
            "[Epoch  38/200] [Batch  330/2910] [D loss: -0.013315] [G loss: 0.507141]\n",
            "[Epoch  38/200] [Batch  830/2910] [D loss: -0.013699] [G loss: 0.507985]\n",
            "[Epoch  38/200] [Batch 1330/2910] [D loss: -0.012731] [G loss: 0.505607]\n",
            "[Epoch  38/200] [Batch 1830/2910] [D loss: -0.016008] [G loss: 0.507848]\n",
            "[Epoch  38/200] [Batch 2330/2910] [D loss: -0.015401] [G loss: 0.505983]\n",
            "[Epoch  38/200] [Batch 2830/2910] [D loss: -0.012346] [G loss: 0.506982]\n",
            "[Epoch  38/200] [Time: 35.22] [D loss: -0.014733] [G loss: 0.507446]\n",
            "[Epoch  39/200] [Batch  420/2910] [D loss: -0.014238] [G loss: 0.507373]\n",
            "[Epoch  39/200] [Batch  920/2910] [D loss: -0.014850] [G loss: 0.508107]\n",
            "[Epoch  39/200] [Batch 1420/2910] [D loss: -0.013406] [G loss: 0.508149]\n",
            "[Epoch  39/200] [Batch 1920/2910] [D loss: -0.014916] [G loss: 0.507863]\n",
            "[Epoch  39/200] [Batch 2420/2910] [D loss: -0.014098] [G loss: 0.506691]\n",
            "[Epoch  39/200] [Time: 35.11] [D loss: -0.015163] [G loss: 0.507332]\n",
            "[Epoch  40/200] [Batch   10/2910] [D loss: -0.013261] [G loss: 0.507288]\n",
            "[Epoch  40/200] [Batch  510/2910] [D loss: -0.013656] [G loss: 0.507900]\n",
            "[Epoch  40/200] [Batch 1010/2910] [D loss: -0.013856] [G loss: 0.506855]\n",
            "[Epoch  40/200] [Batch 1510/2910] [D loss: -0.015248] [G loss: 0.507714]\n",
            "[Epoch  40/200] [Batch 2010/2910] [D loss: -0.013877] [G loss: 0.507307]\n",
            "[Epoch  40/200] [Batch 2510/2910] [D loss: -0.012464] [G loss: 0.507607]\n",
            "[Epoch  40/200] [Time: 32.89] [D loss: -0.012693] [G loss: 0.507978]\n",
            "[Epoch  41/200] [Batch  100/2910] [D loss: -0.014447] [G loss: 0.507404]\n",
            "[Epoch  41/200] [Batch  600/2910] [D loss: -0.013625] [G loss: 0.506633]\n",
            "[Epoch  41/200] [Batch 1100/2910] [D loss: -0.014617] [G loss: 0.507907]\n",
            "[Epoch  41/200] [Batch 1600/2910] [D loss: -0.016070] [G loss: 0.508294]\n",
            "[Epoch  41/200] [Batch 2100/2910] [D loss: -0.011316] [G loss: 0.504655]\n",
            "[Epoch  41/200] [Batch 2600/2910] [D loss: -0.010545] [G loss: 0.506239]\n",
            "[Epoch  41/200] [Time: 35.02] [D loss: -0.012033] [G loss: 0.507620]\n",
            "[Epoch  42/200] [Batch  190/2910] [D loss: -0.012672] [G loss: 0.506871]\n",
            "[Epoch  42/200] [Batch  690/2910] [D loss: -0.014277] [G loss: 0.503236]\n",
            "[Epoch  42/200] [Batch 1190/2910] [D loss: -0.013233] [G loss: 0.507704]\n",
            "[Epoch  42/200] [Batch 1690/2910] [D loss: -0.013118] [G loss: 0.504371]\n",
            "[Epoch  42/200] [Batch 2190/2910] [D loss: -0.014686] [G loss: 0.504546]\n",
            "[Epoch  42/200] [Batch 2690/2910] [D loss: -0.012382] [G loss: 0.507379]\n",
            "[Epoch  42/200] [Time: 35.73] [D loss: -0.013177] [G loss: 0.507194]\n",
            "[Epoch  43/200] [Batch  280/2910] [D loss: -0.015063] [G loss: 0.505497]\n",
            "[Epoch  43/200] [Batch  780/2910] [D loss: -0.014875] [G loss: 0.506569]\n",
            "[Epoch  43/200] [Batch 1280/2910] [D loss: -0.007448] [G loss: 0.508024]\n",
            "[Epoch  43/200] [Batch 1780/2910] [D loss: -0.014517] [G loss: 0.507529]\n",
            "[Epoch  43/200] [Batch 2280/2910] [D loss: -0.015435] [G loss: 0.507295]\n",
            "[Epoch  43/200] [Batch 2780/2910] [D loss: -0.012397] [G loss: 0.507625]\n",
            "[Epoch  43/200] [Time: 35.53] [D loss: -0.013071] [G loss: 0.506126]\n",
            "[Epoch  44/200] [Batch  370/2910] [D loss: -0.012871] [G loss: 0.507290]\n",
            "[Epoch  44/200] [Batch  870/2910] [D loss: -0.013760] [G loss: 0.507295]\n",
            "[Epoch  44/200] [Batch 1370/2910] [D loss: -0.014086] [G loss: 0.507726]\n",
            "[Epoch  44/200] [Batch 1870/2910] [D loss: -0.015699] [G loss: 0.507269]\n",
            "[Epoch  44/200] [Batch 2370/2910] [D loss: -0.014343] [G loss: 0.507604]\n",
            "[Epoch  44/200] [Batch 2870/2910] [D loss: -0.013708] [G loss: 0.507795]\n",
            "[Epoch  44/200] [Time: 33.99] [D loss: -0.010892] [G loss: 0.507665]\n",
            "[Epoch  45/200] [Batch  460/2910] [D loss: -0.013218] [G loss: 0.507342]\n",
            "[Epoch  45/200] [Batch  960/2910] [D loss: -0.015572] [G loss: 0.503626]\n",
            "[Epoch  45/200] [Batch 1460/2910] [D loss: -0.007768] [G loss: 0.507610]\n",
            "[Epoch  45/200] [Batch 1960/2910] [D loss: -0.015782] [G loss: 0.506574]\n",
            "[Epoch  45/200] [Batch 2460/2910] [D loss: -0.010969] [G loss: 0.508113]\n",
            "[Epoch  45/200] [Time: 34.77] [D loss: -0.013259] [G loss: 0.507572]\n",
            "[Epoch  46/200] [Batch   50/2910] [D loss: -0.010804] [G loss: 0.507017]\n",
            "[Epoch  46/200] [Batch  550/2910] [D loss: -0.013400] [G loss: 0.505588]\n",
            "[Epoch  46/200] [Batch 1050/2910] [D loss: -0.014542] [G loss: 0.507320]\n",
            "[Epoch  46/200] [Batch 1550/2910] [D loss: -0.013177] [G loss: 0.506076]\n",
            "[Epoch  46/200] [Batch 2050/2910] [D loss: -0.008210] [G loss: 0.506637]\n",
            "[Epoch  46/200] [Batch 2550/2910] [D loss: -0.014442] [G loss: 0.505161]\n",
            "[Epoch  46/200] [Time: 35.35] [D loss: -0.012877] [G loss: 0.507266]\n",
            "[Epoch  47/200] [Batch  140/2910] [D loss: -0.014066] [G loss: 0.505964]\n",
            "[Epoch  47/200] [Batch  640/2910] [D loss: -0.009709] [G loss: 0.507237]\n",
            "[Epoch  47/200] [Batch 1140/2910] [D loss: -0.012481] [G loss: 0.499674]\n",
            "[Epoch  47/200] [Batch 1640/2910] [D loss: -0.013924] [G loss: 0.506469]\n",
            "[Epoch  47/200] [Batch 2140/2910] [D loss: -0.013503] [G loss: 0.506882]\n",
            "[Epoch  47/200] [Batch 2640/2910] [D loss: -0.015240] [G loss: 0.500825]\n",
            "[Epoch  47/200] [Time: 34.10] [D loss: -0.013649] [G loss: 0.507150]\n",
            "[Epoch  48/200] [Batch  230/2910] [D loss: -0.012463] [G loss: 0.507344]\n",
            "[Epoch  48/200] [Batch  730/2910] [D loss: -0.013959] [G loss: 0.506335]\n",
            "[Epoch  48/200] [Batch 1230/2910] [D loss: -0.008891] [G loss: 0.505924]\n",
            "[Epoch  48/200] [Batch 1730/2910] [D loss: -0.012546] [G loss: 0.506300]\n",
            "[Epoch  48/200] [Batch 2230/2910] [D loss: -0.012150] [G loss: 0.507164]\n",
            "[Epoch  48/200] [Batch 2730/2910] [D loss: -0.012762] [G loss: 0.507030]\n",
            "[Epoch  48/200] [Time: 35.47] [D loss: -0.012717] [G loss: 0.506516]\n",
            "[Epoch  49/200] [Batch  320/2910] [D loss: -0.014995] [G loss: 0.506294]\n",
            "[Epoch  49/200] [Batch  820/2910] [D loss: -0.009986] [G loss: 0.507221]\n",
            "[Epoch  49/200] [Batch 1320/2910] [D loss: -0.012098] [G loss: 0.507571]\n",
            "[Epoch  49/200] [Batch 1820/2910] [D loss: -0.008364] [G loss: 0.508019]\n",
            "[Epoch  49/200] [Batch 2320/2910] [D loss: -0.014435] [G loss: 0.507103]\n",
            "[Epoch  49/200] [Batch 2820/2910] [D loss: -0.010874] [G loss: 0.506576]\n",
            "[Epoch  49/200] [Time: 34.55] [D loss: -0.014418] [G loss: 0.506627]\n",
            "[Epoch  50/200] [Batch  410/2910] [D loss: -0.013152] [G loss: 0.506193]\n",
            "[Epoch  50/200] [Batch  910/2910] [D loss: -0.013475] [G loss: 0.506019]\n",
            "[Epoch  50/200] [Batch 1410/2910] [D loss: -0.013378] [G loss: 0.504311]\n",
            "[Epoch  50/200] [Batch 1910/2910] [D loss: -0.008896] [G loss: 0.507820]\n",
            "[Epoch  50/200] [Batch 2410/2910] [D loss: -0.014415] [G loss: 0.507929]\n",
            "[Epoch  50/200] [Batch    0/2910] [D loss: -0.008281] [G loss: 0.506876]\n",
            "[Epoch  50/200] [Time: 34.45] [D loss: -0.008281] [G loss: 0.506876]\n",
            "[Epoch  51/200] [Batch  500/2910] [D loss: -0.014490] [G loss: 0.507776]\n",
            "[Epoch  51/200] [Batch 1000/2910] [D loss: -0.009842] [G loss: 0.507021]\n",
            "[Epoch  51/200] [Batch 1500/2910] [D loss: -0.013406] [G loss: 0.504395]\n",
            "[Epoch  51/200] [Batch 2000/2910] [D loss: -0.013095] [G loss: 0.507890]\n",
            "[Epoch  51/200] [Batch 2500/2910] [D loss: -0.007735] [G loss: 0.505118]\n",
            "[Epoch  51/200] [Time: 35.62] [D loss: -0.012391] [G loss: 0.506281]\n",
            "[Epoch  52/200] [Batch   90/2910] [D loss: -0.014165] [G loss: 0.506894]\n",
            "[Epoch  52/200] [Batch  590/2910] [D loss: -0.012526] [G loss: 0.503853]\n",
            "[Epoch  52/200] [Batch 1090/2910] [D loss: -0.010345] [G loss: 0.507319]\n",
            "[Epoch  52/200] [Batch 1590/2910] [D loss: -0.009764] [G loss: 0.507627]\n",
            "[Epoch  52/200] [Batch 2090/2910] [D loss: -0.014576] [G loss: 0.507408]\n",
            "[Epoch  52/200] [Batch 2590/2910] [D loss: -0.012079] [G loss: 0.507277]\n",
            "[Epoch  52/200] [Time: 34.48] [D loss: -0.014519] [G loss: 0.507080]\n",
            "[Epoch  53/200] [Batch  180/2910] [D loss: -0.010336] [G loss: 0.507305]\n",
            "[Epoch  53/200] [Batch  680/2910] [D loss: -0.009763] [G loss: 0.503984]\n",
            "[Epoch  53/200] [Batch 1180/2910] [D loss: -0.013494] [G loss: 0.506087]\n",
            "[Epoch  53/200] [Batch 1680/2910] [D loss: -0.012585] [G loss: 0.503374]\n",
            "[Epoch  53/200] [Batch 2180/2910] [D loss: -0.014926] [G loss: 0.508177]\n",
            "[Epoch  53/200] [Batch 2680/2910] [D loss: -0.005474] [G loss: 0.504081]\n",
            "[Epoch  53/200] [Time: 35.18] [D loss: -0.010867] [G loss: 0.507856]\n",
            "[Epoch  54/200] [Batch  270/2910] [D loss: -0.013944] [G loss: 0.507484]\n",
            "[Epoch  54/200] [Batch  770/2910] [D loss: -0.011531] [G loss: 0.504742]\n",
            "[Epoch  54/200] [Batch 1270/2910] [D loss: -0.013418] [G loss: 0.505304]\n",
            "[Epoch  54/200] [Batch 1770/2910] [D loss: -0.014533] [G loss: 0.507943]\n",
            "[Epoch  54/200] [Batch 2270/2910] [D loss: -0.011225] [G loss: 0.505613]\n",
            "[Epoch  54/200] [Batch 2770/2910] [D loss: -0.012152] [G loss: 0.503837]\n",
            "[Epoch  54/200] [Time: 35.57] [D loss: -0.014448] [G loss: 0.506526]\n",
            "[Epoch  55/200] [Batch  360/2910] [D loss: -0.014279] [G loss: 0.505513]\n",
            "[Epoch  55/200] [Batch  860/2910] [D loss: -0.013851] [G loss: 0.507802]\n",
            "[Epoch  55/200] [Batch 1360/2910] [D loss: -0.013444] [G loss: 0.507136]\n",
            "[Epoch  55/200] [Batch 1860/2910] [D loss: -0.013338] [G loss: 0.507487]\n",
            "[Epoch  55/200] [Batch 2360/2910] [D loss: -0.013554] [G loss: 0.508098]\n",
            "[Epoch  55/200] [Batch 2860/2910] [D loss: -0.011815] [G loss: 0.506916]\n",
            "[Epoch  55/200] [Time: 33.87] [D loss: -0.011416] [G loss: 0.507851]\n",
            "[Epoch  56/200] [Batch  450/2910] [D loss: -0.012514] [G loss: 0.500514]\n",
            "[Epoch  56/200] [Batch  950/2910] [D loss: -0.013991] [G loss: 0.505762]\n",
            "[Epoch  56/200] [Batch 1450/2910] [D loss: -0.013753] [G loss: 0.507640]\n",
            "[Epoch  56/200] [Batch 1950/2910] [D loss: -0.014144] [G loss: 0.506347]\n",
            "[Epoch  56/200] [Batch 2450/2910] [D loss: -0.012716] [G loss: 0.506827]\n",
            "[Epoch  56/200] [Time: 34.19] [D loss: -0.011743] [G loss: 0.504509]\n",
            "[Epoch  57/200] [Batch   40/2910] [D loss: -0.011533] [G loss: 0.505903]\n",
            "[Epoch  57/200] [Batch  540/2910] [D loss: -0.013318] [G loss: 0.507220]\n",
            "[Epoch  57/200] [Batch 1040/2910] [D loss: -0.010315] [G loss: 0.507699]\n",
            "[Epoch  57/200] [Batch 1540/2910] [D loss: -0.012646] [G loss: 0.505995]\n",
            "[Epoch  57/200] [Batch 2040/2910] [D loss: -0.013379] [G loss: 0.506218]\n",
            "[Epoch  57/200] [Batch 2540/2910] [D loss: -0.012510] [G loss: 0.506618]\n",
            "[Epoch  57/200] [Time: 32.99] [D loss: -0.009270] [G loss: 0.507856]\n",
            "[Epoch  58/200] [Batch  130/2910] [D loss: -0.013154] [G loss: 0.507880]\n",
            "[Epoch  58/200] [Batch  630/2910] [D loss: -0.012619] [G loss: 0.505732]\n",
            "[Epoch  58/200] [Batch 1130/2910] [D loss: -0.011046] [G loss: 0.505815]\n",
            "[Epoch  58/200] [Batch 1630/2910] [D loss: -0.008625] [G loss: 0.505831]\n",
            "[Epoch  58/200] [Batch 2130/2910] [D loss: -0.005973] [G loss: 0.507362]\n",
            "[Epoch  58/200] [Batch 2630/2910] [D loss: -0.012613] [G loss: 0.507983]\n",
            "[Epoch  58/200] [Time: 33.96] [D loss: -0.010832] [G loss: 0.507104]\n",
            "[Epoch  59/200] [Batch  220/2910] [D loss: -0.011998] [G loss: 0.508049]\n",
            "[Epoch  59/200] [Batch  720/2910] [D loss: -0.011940] [G loss: 0.505424]\n",
            "[Epoch  59/200] [Batch 1220/2910] [D loss: -0.014549] [G loss: 0.504287]\n",
            "[Epoch  59/200] [Batch 1720/2910] [D loss: -0.013111] [G loss: 0.506510]\n",
            "[Epoch  59/200] [Batch 2220/2910] [D loss: -0.006610] [G loss: 0.507125]\n",
            "[Epoch  59/200] [Batch 2720/2910] [D loss: -0.010417] [G loss: 0.505210]\n",
            "[Epoch  59/200] [Time: 33.62] [D loss: -0.014367] [G loss: 0.506806]\n",
            "[Epoch  60/200] [Batch  310/2910] [D loss: -0.012051] [G loss: 0.507182]\n",
            "[Epoch  60/200] [Batch  810/2910] [D loss: -0.009550] [G loss: 0.505553]\n",
            "[Epoch  60/200] [Batch 1310/2910] [D loss: -0.013366] [G loss: 0.506705]\n",
            "[Epoch  60/200] [Batch 1810/2910] [D loss: -0.013663] [G loss: 0.508013]\n",
            "[Epoch  60/200] [Batch 2310/2910] [D loss: -0.010664] [G loss: 0.503033]\n",
            "[Epoch  60/200] [Batch 2810/2910] [D loss: -0.012607] [G loss: 0.507622]\n",
            "[Epoch  60/200] [Time: 35.10] [D loss: -0.010597] [G loss: 0.506716]\n",
            "[Epoch  61/200] [Batch  400/2910] [D loss: -0.011754] [G loss: 0.505366]\n",
            "[Epoch  61/200] [Batch  900/2910] [D loss: -0.014465] [G loss: 0.507216]\n",
            "[Epoch  61/200] [Batch 1400/2910] [D loss: -0.011550] [G loss: 0.506545]\n",
            "[Epoch  61/200] [Batch 1900/2910] [D loss: -0.011319] [G loss: 0.506560]\n",
            "[Epoch  61/200] [Batch 2400/2910] [D loss: -0.011328] [G loss: 0.507121]\n",
            "[Epoch  61/200] [Batch 2900/2910] [D loss: -0.008769] [G loss: 0.508292]\n",
            "[Epoch  61/200] [Time: 35.66] [D loss: -0.010215] [G loss: 0.505321]\n",
            "[Epoch  62/200] [Batch  490/2910] [D loss: -0.014392] [G loss: 0.506445]\n",
            "[Epoch  62/200] [Batch  990/2910] [D loss: -0.013499] [G loss: 0.506481]\n",
            "[Epoch  62/200] [Batch 1490/2910] [D loss: -0.011201] [G loss: 0.506035]\n",
            "[Epoch  62/200] [Batch 1990/2910] [D loss: -0.014546] [G loss: 0.507658]\n",
            "[Epoch  62/200] [Batch 2490/2910] [D loss: -0.013712] [G loss: 0.506613]\n",
            "[Epoch  62/200] [Time: 35.35] [D loss: -0.009801] [G loss: 0.506329]\n",
            "[Epoch  63/200] [Batch   80/2910] [D loss: -0.011596] [G loss: 0.507609]\n",
            "[Epoch  63/200] [Batch  580/2910] [D loss: -0.010208] [G loss: 0.504868]\n",
            "[Epoch  63/200] [Batch 1080/2910] [D loss: -0.013327] [G loss: 0.508058]\n",
            "[Epoch  63/200] [Batch 1580/2910] [D loss: -0.011011] [G loss: 0.507195]\n",
            "[Epoch  63/200] [Batch 2080/2910] [D loss: -0.012594] [G loss: 0.507736]\n",
            "[Epoch  63/200] [Batch 2580/2910] [D loss: -0.012778] [G loss: 0.507356]\n",
            "[Epoch  63/200] [Time: 35.41] [D loss: -0.013502] [G loss: 0.506385]\n",
            "[Epoch  64/200] [Batch  170/2910] [D loss: -0.007776] [G loss: 0.507714]\n",
            "[Epoch  64/200] [Batch  670/2910] [D loss: -0.008078] [G loss: 0.505586]\n",
            "[Epoch  64/200] [Batch 1170/2910] [D loss: -0.009908] [G loss: 0.505153]\n",
            "[Epoch  64/200] [Batch 1670/2910] [D loss: -0.006660] [G loss: 0.505613]\n",
            "[Epoch  64/200] [Batch 2170/2910] [D loss: -0.011158] [G loss: 0.507701]\n",
            "[Epoch  64/200] [Batch 2670/2910] [D loss: -0.010654] [G loss: 0.499858]\n",
            "[Epoch  64/200] [Time: 34.01] [D loss: -0.013191] [G loss: 0.507707]\n",
            "[Epoch  65/200] [Batch  260/2910] [D loss: -0.010739] [G loss: 0.506435]\n",
            "[Epoch  65/200] [Batch  760/2910] [D loss: -0.012866] [G loss: 0.502249]\n",
            "[Epoch  65/200] [Batch 1260/2910] [D loss: -0.012127] [G loss: 0.505867]\n",
            "[Epoch  65/200] [Batch 1760/2910] [D loss: -0.010540] [G loss: 0.506434]\n",
            "[Epoch  65/200] [Batch 2260/2910] [D loss: -0.012844] [G loss: 0.504791]\n",
            "[Epoch  65/200] [Batch 2760/2910] [D loss: -0.004882] [G loss: 0.507548]\n",
            "[Epoch  65/200] [Time: 35.53] [D loss: -0.007100] [G loss: 0.506172]\n",
            "[Epoch  66/200] [Batch  350/2910] [D loss: -0.010927] [G loss: 0.505881]\n",
            "[Epoch  66/200] [Batch  850/2910] [D loss: -0.008378] [G loss: 0.507610]\n",
            "[Epoch  66/200] [Batch 1350/2910] [D loss: -0.009946] [G loss: 0.507331]\n",
            "[Epoch  66/200] [Batch 1850/2910] [D loss: -0.007240] [G loss: 0.507046]\n",
            "[Epoch  66/200] [Batch 2350/2910] [D loss: -0.013762] [G loss: 0.507632]\n",
            "[Epoch  66/200] [Batch 2850/2910] [D loss: -0.010570] [G loss: 0.506616]\n",
            "[Epoch  66/200] [Time: 34.76] [D loss: -0.011172] [G loss: 0.503664]\n",
            "[Epoch  67/200] [Batch  440/2910] [D loss: -0.013607] [G loss: 0.504015]\n",
            "[Epoch  67/200] [Batch  940/2910] [D loss: -0.012946] [G loss: 0.506285]\n",
            "[Epoch  67/200] [Batch 1440/2910] [D loss: -0.013284] [G loss: 0.507957]\n",
            "[Epoch  67/200] [Batch 1940/2910] [D loss: -0.011014] [G loss: 0.507820]\n",
            "[Epoch  67/200] [Batch 2440/2910] [D loss: -0.012376] [G loss: 0.498865]\n",
            "[Epoch  67/200] [Time: 34.65] [D loss: -0.010978] [G loss: 0.505543]\n",
            "[Epoch  68/200] [Batch   30/2910] [D loss: -0.005944] [G loss: 0.506923]\n",
            "[Epoch  68/200] [Batch  530/2910] [D loss: -0.012760] [G loss: 0.507126]\n",
            "[Epoch  68/200] [Batch 1030/2910] [D loss: -0.014143] [G loss: 0.507082]\n",
            "[Epoch  68/200] [Batch 1530/2910] [D loss: -0.007753] [G loss: 0.507195]\n",
            "[Epoch  68/200] [Batch 2030/2910] [D loss: -0.011428] [G loss: 0.506232]\n",
            "[Epoch  68/200] [Batch 2530/2910] [D loss: -0.010646] [G loss: 0.502993]\n",
            "[Epoch  68/200] [Time: 34.83] [D loss: -0.006350] [G loss: 0.496281]\n",
            "[Epoch  69/200] [Batch  120/2910] [D loss: -0.010721] [G loss: 0.502649]\n",
            "[Epoch  69/200] [Batch  620/2910] [D loss: -0.011124] [G loss: 0.507534]\n",
            "[Epoch  69/200] [Batch 1120/2910] [D loss: -0.012415] [G loss: 0.506908]\n",
            "[Epoch  69/200] [Batch 1620/2910] [D loss: -0.014093] [G loss: 0.505737]\n",
            "[Epoch  69/200] [Batch 2120/2910] [D loss: -0.006151] [G loss: 0.505497]\n",
            "[Epoch  69/200] [Batch 2620/2910] [D loss: -0.012675] [G loss: 0.506445]\n",
            "[Epoch  69/200] [Time: 35.36] [D loss: -0.011678] [G loss: 0.503724]\n",
            "[Epoch  70/200] [Batch  210/2910] [D loss: -0.013412] [G loss: 0.507435]\n",
            "[Epoch  70/200] [Batch  710/2910] [D loss: -0.011641] [G loss: 0.505335]\n",
            "[Epoch  70/200] [Batch 1210/2910] [D loss: -0.012230] [G loss: 0.508333]\n",
            "[Epoch  70/200] [Batch 1710/2910] [D loss: -0.011299] [G loss: 0.506367]\n",
            "[Epoch  70/200] [Batch 2210/2910] [D loss: -0.009263] [G loss: 0.505902]\n",
            "[Epoch  70/200] [Batch 2710/2910] [D loss: -0.012339] [G loss: 0.506918]\n",
            "[Epoch  70/200] [Time: 34.44] [D loss: -0.009502] [G loss: 0.505244]\n",
            "[Epoch  71/200] [Batch  300/2910] [D loss: -0.005673] [G loss: 0.507266]\n",
            "[Epoch  71/200] [Batch  800/2910] [D loss: -0.009981] [G loss: 0.504382]\n",
            "[Epoch  71/200] [Batch 1300/2910] [D loss: -0.013591] [G loss: 0.505154]\n",
            "[Epoch  71/200] [Batch 1800/2910] [D loss: -0.008137] [G loss: 0.506876]\n",
            "[Epoch  71/200] [Batch 2300/2910] [D loss: -0.006588] [G loss: 0.502598]\n",
            "[Epoch  71/200] [Batch 2800/2910] [D loss: -0.012739] [G loss: 0.505247]\n",
            "[Epoch  71/200] [Time: 35.43] [D loss: -0.013165] [G loss: 0.507962]\n",
            "[Epoch  72/200] [Batch  390/2910] [D loss: -0.012511] [G loss: 0.506763]\n",
            "[Epoch  72/200] [Batch  890/2910] [D loss: -0.005410] [G loss: 0.504618]\n",
            "[Epoch  72/200] [Batch 1390/2910] [D loss: -0.006840] [G loss: 0.506751]\n",
            "[Epoch  72/200] [Batch 1890/2910] [D loss: -0.010728] [G loss: 0.505661]\n",
            "[Epoch  72/200] [Batch 2390/2910] [D loss: -0.006221] [G loss: 0.506165]\n",
            "[Epoch  72/200] [Batch 2890/2910] [D loss: -0.011190] [G loss: 0.503707]\n",
            "[Epoch  72/200] [Time: 34.47] [D loss: -0.012370] [G loss: 0.503058]\n",
            "[Epoch  73/200] [Batch  480/2910] [D loss: -0.012839] [G loss: 0.506927]\n",
            "[Epoch  73/200] [Batch  980/2910] [D loss: -0.014094] [G loss: 0.506567]\n",
            "[Epoch  73/200] [Batch 1480/2910] [D loss: -0.012847] [G loss: 0.502197]\n",
            "[Epoch  73/200] [Batch 1980/2910] [D loss: -0.004621] [G loss: 0.507247]\n",
            "[Epoch  73/200] [Batch 2480/2910] [D loss: -0.009532] [G loss: 0.507759]\n",
            "[Epoch  73/200] [Time: 33.48] [D loss: -0.013941] [G loss: 0.507053]\n",
            "[Epoch  74/200] [Batch   70/2910] [D loss: -0.011464] [G loss: 0.505213]\n",
            "[Epoch  74/200] [Batch  570/2910] [D loss: -0.012188] [G loss: 0.503766]\n",
            "[Epoch  74/200] [Batch 1070/2910] [D loss: -0.009461] [G loss: 0.506845]\n",
            "[Epoch  74/200] [Batch 1570/2910] [D loss: -0.011994] [G loss: 0.506055]\n",
            "[Epoch  74/200] [Batch 2070/2910] [D loss: -0.008424] [G loss: 0.505396]\n",
            "[Epoch  74/200] [Batch 2570/2910] [D loss: -0.009420] [G loss: 0.508060]\n",
            "[Epoch  74/200] [Time: 34.91] [D loss: -0.005845] [G loss: 0.507195]\n",
            "[Epoch  75/200] [Batch  160/2910] [D loss: -0.012774] [G loss: 0.505494]\n",
            "[Epoch  75/200] [Batch  660/2910] [D loss: -0.009495] [G loss: 0.506337]\n",
            "[Epoch  75/200] [Batch 1160/2910] [D loss: -0.010599] [G loss: 0.500475]\n",
            "[Epoch  75/200] [Batch 1660/2910] [D loss: -0.010760] [G loss: 0.507152]\n",
            "[Epoch  75/200] [Batch 2160/2910] [D loss: -0.013614] [G loss: 0.505065]\n",
            "[Epoch  75/200] [Batch 2660/2910] [D loss: -0.006716] [G loss: 0.506804]\n",
            "[Epoch  75/200] [Time: 35.68] [D loss: -0.014388] [G loss: 0.506068]\n",
            "[Epoch  76/200] [Batch  250/2910] [D loss: -0.007685] [G loss: 0.505293]\n",
            "[Epoch  76/200] [Batch  750/2910] [D loss: -0.012034] [G loss: 0.505566]\n",
            "[Epoch  76/200] [Batch 1250/2910] [D loss: -0.010067] [G loss: 0.506526]\n",
            "[Epoch  76/200] [Batch 1750/2910] [D loss: -0.010067] [G loss: 0.496962]\n",
            "[Epoch  76/200] [Batch 2250/2910] [D loss: -0.008926] [G loss: 0.507921]\n",
            "[Epoch  76/200] [Batch 2750/2910] [D loss: -0.009036] [G loss: 0.504855]\n",
            "[Epoch  76/200] [Time: 35.68] [D loss: -0.011549] [G loss: 0.506667]\n",
            "[Epoch  77/200] [Batch  340/2910] [D loss: -0.010550] [G loss: 0.506175]\n",
            "[Epoch  77/200] [Batch  840/2910] [D loss: -0.009754] [G loss: 0.507693]\n",
            "[Epoch  77/200] [Batch 1340/2910] [D loss: -0.012704] [G loss: 0.507785]\n",
            "[Epoch  77/200] [Batch 1840/2910] [D loss: -0.011293] [G loss: 0.504684]\n",
            "[Epoch  77/200] [Batch 2340/2910] [D loss: -0.009071] [G loss: 0.504749]\n",
            "[Epoch  77/200] [Batch 2840/2910] [D loss: -0.004803] [G loss: 0.498186]\n",
            "[Epoch  77/200] [Time: 33.48] [D loss: -0.011794] [G loss: 0.508102]\n",
            "[Epoch  78/200] [Batch  430/2910] [D loss: -0.011506] [G loss: 0.506586]\n",
            "[Epoch  78/200] [Batch  930/2910] [D loss: -0.011411] [G loss: 0.507378]\n",
            "[Epoch  78/200] [Batch 1430/2910] [D loss: -0.009223] [G loss: 0.505573]\n",
            "[Epoch  78/200] [Batch 1930/2910] [D loss: -0.013986] [G loss: 0.504115]\n",
            "[Epoch  78/200] [Batch 2430/2910] [D loss: -0.011292] [G loss: 0.504551]\n",
            "[Epoch  78/200] [Time: 32.82] [D loss: -0.012960] [G loss: 0.501096]\n",
            "[Epoch  79/200] [Batch   20/2910] [D loss: -0.006165] [G loss: 0.500380]\n",
            "[Epoch  79/200] [Batch  520/2910] [D loss: -0.010360] [G loss: 0.507115]\n",
            "[Epoch  79/200] [Batch 1020/2910] [D loss: -0.012546] [G loss: 0.504763]\n",
            "[Epoch  79/200] [Batch 1520/2910] [D loss: -0.008688] [G loss: 0.503526]\n",
            "[Epoch  79/200] [Batch 2020/2910] [D loss: -0.010509] [G loss: 0.505232]\n",
            "[Epoch  79/200] [Batch 2520/2910] [D loss: -0.005687] [G loss: 0.505396]\n",
            "[Epoch  79/200] [Time: 33.45] [D loss: -0.005886] [G loss: 0.502583]\n",
            "[Epoch  80/200] [Batch  110/2910] [D loss: -0.006711] [G loss: 0.503987]\n",
            "[Epoch  80/200] [Batch  610/2910] [D loss: -0.011388] [G loss: 0.505947]\n",
            "[Epoch  80/200] [Batch 1110/2910] [D loss: -0.008762] [G loss: 0.507041]\n",
            "[Epoch  80/200] [Batch 1610/2910] [D loss: -0.010768] [G loss: 0.504822]\n",
            "[Epoch  80/200] [Batch 2110/2910] [D loss: -0.011075] [G loss: 0.506035]\n",
            "[Epoch  80/200] [Batch 2610/2910] [D loss: -0.011638] [G loss: 0.502882]\n",
            "[Epoch  80/200] [Time: 33.15] [D loss: -0.010716] [G loss: 0.505487]\n",
            "[Epoch  81/200] [Batch  200/2910] [D loss: -0.008972] [G loss: 0.507153]\n",
            "[Epoch  81/200] [Batch  700/2910] [D loss: -0.009599] [G loss: 0.507281]\n",
            "[Epoch  81/200] [Batch 1200/2910] [D loss: -0.012763] [G loss: 0.507139]\n",
            "[Epoch  81/200] [Batch 1700/2910] [D loss: -0.011132] [G loss: 0.506320]\n",
            "[Epoch  81/200] [Batch 2200/2910] [D loss: -0.012588] [G loss: 0.507535]\n",
            "[Epoch  81/200] [Batch 2700/2910] [D loss: -0.009018] [G loss: 0.506053]\n",
            "[Epoch  81/200] [Time: 33.98] [D loss: -0.014005] [G loss: 0.507063]\n",
            "[Epoch  82/200] [Batch  290/2910] [D loss: -0.010803] [G loss: 0.502902]\n",
            "[Epoch  82/200] [Batch  790/2910] [D loss: -0.007906] [G loss: 0.504006]\n",
            "[Epoch  82/200] [Batch 1290/2910] [D loss: -0.012567] [G loss: 0.506118]\n",
            "[Epoch  82/200] [Batch 1790/2910] [D loss: -0.010777] [G loss: 0.506884]\n",
            "[Epoch  82/200] [Batch 2290/2910] [D loss: -0.006914] [G loss: 0.506263]\n",
            "[Epoch  82/200] [Batch 2790/2910] [D loss: -0.012135] [G loss: 0.503335]\n",
            "[Epoch  82/200] [Time: 29.06] [D loss: -0.005401] [G loss: 0.497610]\n",
            "[Epoch  83/200] [Batch  380/2910] [D loss: -0.009537] [G loss: 0.505165]\n",
            "[Epoch  83/200] [Batch  880/2910] [D loss: -0.012267] [G loss: 0.504668]\n",
            "[Epoch  83/200] [Batch 1380/2910] [D loss: -0.012334] [G loss: 0.506910]\n",
            "[Epoch  83/200] [Batch 1880/2910] [D loss: -0.009194] [G loss: 0.503860]\n",
            "[Epoch  83/200] [Batch 2380/2910] [D loss: -0.014141] [G loss: 0.507098]\n",
            "[Epoch  83/200] [Batch 2880/2910] [D loss: -0.009264] [G loss: 0.502436]\n",
            "[Epoch  83/200] [Time: 33.43] [D loss: -0.009912] [G loss: 0.502119]\n",
            "[Epoch  84/200] [Batch  470/2910] [D loss: -0.012740] [G loss: 0.507182]\n",
            "[Epoch  84/200] [Batch  970/2910] [D loss: -0.010803] [G loss: 0.503863]\n",
            "[Epoch  84/200] [Batch 1470/2910] [D loss: -0.010467] [G loss: 0.502850]\n",
            "[Epoch  84/200] [Batch 1970/2910] [D loss: -0.009308] [G loss: 0.507636]\n",
            "[Epoch  84/200] [Batch 2470/2910] [D loss: -0.012105] [G loss: 0.505456]\n",
            "[Epoch  84/200] [Time: 33.85] [D loss: -0.011247] [G loss: 0.502522]\n",
            "[Epoch  85/200] [Batch   60/2910] [D loss: -0.011250] [G loss: 0.506360]\n",
            "[Epoch  85/200] [Batch  560/2910] [D loss: -0.013782] [G loss: 0.507339]\n",
            "[Epoch  85/200] [Batch 1060/2910] [D loss: -0.013287] [G loss: 0.507148]\n",
            "[Epoch  85/200] [Batch 1560/2910] [D loss: -0.012597] [G loss: 0.504770]\n",
            "[Epoch  85/200] [Batch 2060/2910] [D loss: -0.010261] [G loss: 0.498958]\n",
            "[Epoch  85/200] [Batch 2560/2910] [D loss: -0.012172] [G loss: 0.505279]\n",
            "[Epoch  85/200] [Time: 35.20] [D loss: -0.012060] [G loss: 0.504038]\n",
            "[Epoch  86/200] [Batch  150/2910] [D loss: -0.011448] [G loss: 0.507131]\n",
            "[Epoch  86/200] [Batch  650/2910] [D loss: -0.010060] [G loss: 0.506186]\n",
            "[Epoch  86/200] [Batch 1150/2910] [D loss: -0.011289] [G loss: 0.503527]\n",
            "[Epoch  86/200] [Batch 1650/2910] [D loss: -0.006692] [G loss: 0.505252]\n",
            "[Epoch  86/200] [Batch 2150/2910] [D loss: -0.008890] [G loss: 0.506061]\n",
            "[Epoch  86/200] [Batch 2650/2910] [D loss: -0.008790] [G loss: 0.506799]\n",
            "[Epoch  86/200] [Time: 34.09] [D loss: -0.009602] [G loss: 0.503360]\n",
            "[Epoch  87/200] [Batch  240/2910] [D loss: -0.013664] [G loss: 0.507432]\n",
            "[Epoch  87/200] [Batch  740/2910] [D loss: -0.011253] [G loss: 0.506215]\n",
            "[Epoch  87/200] [Batch 1240/2910] [D loss: -0.013290] [G loss: 0.506798]\n",
            "[Epoch  87/200] [Batch 1740/2910] [D loss: -0.010952] [G loss: 0.507146]\n",
            "[Epoch  87/200] [Batch 2240/2910] [D loss: -0.005955] [G loss: 0.506047]\n",
            "[Epoch  87/200] [Batch 2740/2910] [D loss: -0.013447] [G loss: 0.505073]\n",
            "[Epoch  87/200] [Time: 35.62] [D loss: -0.009997] [G loss: 0.506462]\n",
            "[Epoch  88/200] [Batch  330/2910] [D loss: -0.012704] [G loss: 0.505699]\n",
            "[Epoch  88/200] [Batch  830/2910] [D loss: -0.010477] [G loss: 0.506699]\n",
            "[Epoch  88/200] [Batch 1330/2910] [D loss: -0.008418] [G loss: 0.506374]\n",
            "[Epoch  88/200] [Batch 1830/2910] [D loss: -0.002397] [G loss: 0.507851]\n",
            "[Epoch  88/200] [Batch 2330/2910] [D loss: -0.009810] [G loss: 0.504818]\n",
            "[Epoch  88/200] [Batch 2830/2910] [D loss: -0.010137] [G loss: 0.504578]\n",
            "[Epoch  88/200] [Time: 35.31] [D loss: -0.007132] [G loss: 0.499006]\n",
            "[Epoch  89/200] [Batch  420/2910] [D loss: -0.009857] [G loss: 0.505340]\n",
            "[Epoch  89/200] [Batch  920/2910] [D loss: -0.006330] [G loss: 0.496310]\n",
            "[Epoch  89/200] [Batch 1420/2910] [D loss: -0.009746] [G loss: 0.506704]\n",
            "[Epoch  89/200] [Batch 1920/2910] [D loss: -0.013015] [G loss: 0.504443]\n",
            "[Epoch  89/200] [Batch 2420/2910] [D loss: -0.009563] [G loss: 0.506263]\n",
            "[Epoch  89/200] [Time: 33.68] [D loss: -0.004245] [G loss: 0.505713]\n",
            "[Epoch  90/200] [Batch   10/2910] [D loss: -0.004241] [G loss: 0.504996]\n",
            "[Epoch  90/200] [Batch  510/2910] [D loss: -0.009927] [G loss: 0.501285]\n",
            "[Epoch  90/200] [Batch 1010/2910] [D loss: -0.008852] [G loss: 0.502005]\n",
            "[Epoch  90/200] [Batch 1510/2910] [D loss: -0.008214] [G loss: 0.504963]\n",
            "[Epoch  90/200] [Batch 2010/2910] [D loss: -0.008302] [G loss: 0.507150]\n",
            "[Epoch  90/200] [Batch 2510/2910] [D loss: -0.010275] [G loss: 0.503163]\n",
            "[Epoch  90/200] [Time: 30.93] [D loss: -0.010807] [G loss: 0.504704]\n",
            "[Epoch  91/200] [Batch  100/2910] [D loss: -0.012881] [G loss: 0.501206]\n",
            "[Epoch  91/200] [Batch  600/2910] [D loss: -0.009410] [G loss: 0.506633]\n",
            "[Epoch  91/200] [Batch 1100/2910] [D loss: -0.009512] [G loss: 0.505486]\n",
            "[Epoch  91/200] [Batch 1600/2910] [D loss: -0.009496] [G loss: 0.506325]\n",
            "[Epoch  91/200] [Batch 2100/2910] [D loss: -0.012351] [G loss: 0.505426]\n",
            "[Epoch  91/200] [Batch 2600/2910] [D loss: -0.012060] [G loss: 0.501967]\n",
            "[Epoch  91/200] [Time: 34.90] [D loss: -0.010642] [G loss: 0.507234]\n",
            "[Epoch  92/200] [Batch  190/2910] [D loss: -0.008840] [G loss: 0.505489]\n",
            "[Epoch  92/200] [Batch  690/2910] [D loss: -0.008121] [G loss: 0.506656]\n",
            "[Epoch  92/200] [Batch 1190/2910] [D loss: -0.009515] [G loss: 0.507962]\n",
            "[Epoch  92/200] [Batch 1690/2910] [D loss: -0.005342] [G loss: 0.503018]\n",
            "[Epoch  92/200] [Batch 2190/2910] [D loss: -0.006309] [G loss: 0.507517]\n",
            "[Epoch  92/200] [Batch 2690/2910] [D loss: -0.007320] [G loss: 0.503828]\n",
            "[Epoch  92/200] [Time: 35.55] [D loss: -0.009216] [G loss: 0.506465]\n",
            "[Epoch  93/200] [Batch  280/2910] [D loss: -0.011917] [G loss: 0.498077]\n",
            "[Epoch  93/200] [Batch  780/2910] [D loss: -0.009010] [G loss: 0.506746]\n",
            "[Epoch  93/200] [Batch 1280/2910] [D loss: -0.008476] [G loss: 0.507360]\n",
            "[Epoch  93/200] [Batch 1780/2910] [D loss: -0.012610] [G loss: 0.502032]\n",
            "[Epoch  93/200] [Batch 2280/2910] [D loss: -0.009520] [G loss: 0.505807]\n",
            "[Epoch  93/200] [Batch 2780/2910] [D loss: -0.011803] [G loss: 0.503071]\n",
            "[Epoch  93/200] [Time: 35.04] [D loss: -0.006737] [G loss: 0.504295]\n",
            "[Epoch  94/200] [Batch  370/2910] [D loss: -0.010272] [G loss: 0.503343]\n",
            "[Epoch  94/200] [Batch  870/2910] [D loss: -0.012388] [G loss: 0.508024]\n",
            "[Epoch  94/200] [Batch 1370/2910] [D loss: -0.006811] [G loss: 0.507776]\n",
            "[Epoch  94/200] [Batch 1870/2910] [D loss: -0.010095] [G loss: 0.504940]\n",
            "[Epoch  94/200] [Batch 2370/2910] [D loss: -0.010423] [G loss: 0.502422]\n",
            "[Epoch  94/200] [Batch 2870/2910] [D loss: -0.010841] [G loss: 0.506977]\n",
            "[Epoch  94/200] [Time: 35.27] [D loss: -0.002705] [G loss: 0.502504]\n",
            "[Epoch  95/200] [Batch  460/2910] [D loss: -0.008845] [G loss: 0.506660]\n",
            "[Epoch  95/200] [Batch  960/2910] [D loss: -0.008675] [G loss: 0.503597]\n",
            "[Epoch  95/200] [Batch 1460/2910] [D loss: -0.009888] [G loss: 0.506457]\n",
            "[Epoch  95/200] [Batch 1960/2910] [D loss: -0.007933] [G loss: 0.497637]\n",
            "[Epoch  95/200] [Batch 2460/2910] [D loss: -0.011273] [G loss: 0.500650]\n",
            "[Epoch  95/200] [Time: 34.91] [D loss: -0.013513] [G loss: 0.503991]\n",
            "[Epoch  96/200] [Batch   50/2910] [D loss: -0.007016] [G loss: 0.504139]\n",
            "[Epoch  96/200] [Batch  550/2910] [D loss: -0.008836] [G loss: 0.506608]\n",
            "[Epoch  96/200] [Batch 1050/2910] [D loss: -0.008580] [G loss: 0.504509]\n",
            "[Epoch  96/200] [Batch 1550/2910] [D loss: -0.014004] [G loss: 0.507429]\n",
            "[Epoch  96/200] [Batch 2050/2910] [D loss: -0.009859] [G loss: 0.504599]\n",
            "[Epoch  96/200] [Batch 2550/2910] [D loss: -0.012421] [G loss: 0.503418]\n",
            "[Epoch  96/200] [Time: 34.67] [D loss: -0.013756] [G loss: 0.506142]\n",
            "[Epoch  97/200] [Batch  140/2910] [D loss: -0.009406] [G loss: 0.504225]\n",
            "[Epoch  97/200] [Batch  640/2910] [D loss: -0.010832] [G loss: 0.504676]\n",
            "[Epoch  97/200] [Batch 1140/2910] [D loss: -0.010349] [G loss: 0.498772]\n",
            "[Epoch  97/200] [Batch 1640/2910] [D loss: -0.010493] [G loss: 0.506925]\n",
            "[Epoch  97/200] [Batch 2140/2910] [D loss: -0.003565] [G loss: 0.506313]\n",
            "[Epoch  97/200] [Batch 2640/2910] [D loss: -0.007065] [G loss: 0.505955]\n",
            "[Epoch  97/200] [Time: 32.96] [D loss: -0.009678] [G loss: 0.503211]\n",
            "[Epoch  98/200] [Batch  230/2910] [D loss: -0.011602] [G loss: 0.506575]\n",
            "[Epoch  98/200] [Batch  730/2910] [D loss: -0.011071] [G loss: 0.507429]\n",
            "[Epoch  98/200] [Batch 1230/2910] [D loss: -0.010814] [G loss: 0.507125]\n",
            "[Epoch  98/200] [Batch 1730/2910] [D loss: -0.012683] [G loss: 0.505839]\n",
            "[Epoch  98/200] [Batch 2230/2910] [D loss: -0.011206] [G loss: 0.501420]\n",
            "[Epoch  98/200] [Batch 2730/2910] [D loss: -0.009454] [G loss: 0.503176]\n",
            "[Epoch  98/200] [Time: 34.71] [D loss: -0.009593] [G loss: 0.505722]\n",
            "[Epoch  99/200] [Batch  320/2910] [D loss: -0.008308] [G loss: 0.506656]\n",
            "[Epoch  99/200] [Batch  820/2910] [D loss: -0.008681] [G loss: 0.505819]\n",
            "[Epoch  99/200] [Batch 1320/2910] [D loss: -0.011170] [G loss: 0.506338]\n",
            "[Epoch  99/200] [Batch 1820/2910] [D loss: -0.009279] [G loss: 0.506127]\n",
            "[Epoch  99/200] [Batch 2320/2910] [D loss: -0.007595] [G loss: 0.507224]\n",
            "[Epoch  99/200] [Batch 2820/2910] [D loss: -0.007821] [G loss: 0.504923]\n",
            "[Epoch  99/200] [Time: 34.68] [D loss: -0.006876] [G loss: 0.501908]\n",
            "[Epoch 100/200] [Batch  410/2910] [D loss: -0.009572] [G loss: 0.503878]\n",
            "[Epoch 100/200] [Batch  910/2910] [D loss: -0.010063] [G loss: 0.506724]\n",
            "[Epoch 100/200] [Batch 1410/2910] [D loss: -0.010267] [G loss: 0.506729]\n",
            "[Epoch 100/200] [Batch 1910/2910] [D loss: -0.009862] [G loss: 0.500141]\n",
            "[Epoch 100/200] [Batch 2410/2910] [D loss: -0.011590] [G loss: 0.502555]\n",
            "[Epoch 100/200] [Batch    0/2910] [D loss: -0.014007] [G loss: 0.507665]\n",
            "[Epoch 100/200] [Time: 33.43] [D loss: -0.014007] [G loss: 0.507665]\n",
            "[Epoch 101/200] [Batch  500/2910] [D loss: -0.008834] [G loss: 0.504241]\n",
            "[Epoch 101/200] [Batch 1000/2910] [D loss: -0.009345] [G loss: 0.506037]\n",
            "[Epoch 101/200] [Batch 1500/2910] [D loss: -0.010894] [G loss: 0.498325]\n",
            "[Epoch 101/200] [Batch 2000/2910] [D loss: -0.013499] [G loss: 0.507625]\n",
            "[Epoch 101/200] [Batch 2500/2910] [D loss: -0.005018] [G loss: 0.507468]\n",
            "[Epoch 101/200] [Time: 34.81] [D loss: -0.009730] [G loss: 0.502384]\n",
            "[Epoch 102/200] [Batch   90/2910] [D loss: -0.005265] [G loss: 0.505439]\n",
            "[Epoch 102/200] [Batch  590/2910] [D loss: -0.009447] [G loss: 0.506692]\n",
            "[Epoch 102/200] [Batch 1090/2910] [D loss: -0.009073] [G loss: 0.504643]\n",
            "[Epoch 102/200] [Batch 1590/2910] [D loss: -0.005812] [G loss: 0.504577]\n",
            "[Epoch 102/200] [Batch 2090/2910] [D loss: -0.011036] [G loss: 0.507755]\n",
            "[Epoch 102/200] [Batch 2590/2910] [D loss: -0.012699] [G loss: 0.503925]\n",
            "[Epoch 102/200] [Time: 32.14] [D loss: -0.012450] [G loss: 0.504113]\n",
            "[Epoch 103/200] [Batch  180/2910] [D loss: -0.006509] [G loss: 0.507155]\n",
            "[Epoch 103/200] [Batch  680/2910] [D loss: -0.010680] [G loss: 0.503931]\n",
            "[Epoch 103/200] [Batch 1180/2910] [D loss: -0.011410] [G loss: 0.506786]\n",
            "[Epoch 103/200] [Batch 1680/2910] [D loss: -0.009527] [G loss: 0.501375]\n",
            "[Epoch 103/200] [Batch 2180/2910] [D loss: -0.012700] [G loss: 0.500178]\n",
            "[Epoch 103/200] [Batch 2680/2910] [D loss: -0.011060] [G loss: 0.504802]\n",
            "[Epoch 103/200] [Time: 35.13] [D loss: -0.003438] [G loss: 0.505062]\n",
            "[Epoch 104/200] [Batch  270/2910] [D loss: -0.008093] [G loss: 0.506067]\n",
            "[Epoch 104/200] [Batch  770/2910] [D loss: -0.011552] [G loss: 0.502210]\n",
            "[Epoch 104/200] [Batch 1270/2910] [D loss: -0.008913] [G loss: 0.504249]\n",
            "[Epoch 104/200] [Batch 1770/2910] [D loss: -0.005065] [G loss: 0.501424]\n",
            "[Epoch 104/200] [Batch 2270/2910] [D loss: -0.012400] [G loss: 0.505633]\n",
            "[Epoch 104/200] [Batch 2770/2910] [D loss: -0.010356] [G loss: 0.501237]\n",
            "[Epoch 104/200] [Time: 35.43] [D loss: -0.005563] [G loss: 0.503488]\n",
            "[Epoch 105/200] [Batch  360/2910] [D loss: -0.009308] [G loss: 0.506857]\n",
            "[Epoch 105/200] [Batch  860/2910] [D loss: -0.005776] [G loss: 0.503026]\n",
            "[Epoch 105/200] [Batch 1360/2910] [D loss: -0.003224] [G loss: 0.503547]\n",
            "[Epoch 105/200] [Batch 1860/2910] [D loss: -0.012560] [G loss: 0.506561]\n",
            "[Epoch 105/200] [Batch 2360/2910] [D loss: -0.006211] [G loss: 0.507238]\n",
            "[Epoch 105/200] [Batch 2860/2910] [D loss: -0.009542] [G loss: 0.506919]\n",
            "[Epoch 105/200] [Time: 33.27] [D loss: -0.005334] [G loss: 0.502609]\n",
            "[Epoch 106/200] [Batch  450/2910] [D loss: -0.009372] [G loss: 0.504167]\n",
            "[Epoch 106/200] [Batch  950/2910] [D loss: -0.008482] [G loss: 0.507006]\n",
            "[Epoch 106/200] [Batch 1450/2910] [D loss: -0.009112] [G loss: 0.504625]\n",
            "[Epoch 106/200] [Batch 1950/2910] [D loss: -0.009007] [G loss: 0.505735]\n",
            "[Epoch 106/200] [Batch 2450/2910] [D loss: -0.006348] [G loss: 0.505341]\n",
            "[Epoch 106/200] [Time: 34.11] [D loss: -0.012450] [G loss: 0.503341]\n",
            "[Epoch 107/200] [Batch   40/2910] [D loss: -0.012450] [G loss: 0.505904]\n",
            "[Epoch 107/200] [Batch  540/2910] [D loss: -0.007427] [G loss: 0.504753]\n",
            "[Epoch 107/200] [Batch 1040/2910] [D loss: -0.010706] [G loss: 0.502321]\n",
            "[Epoch 107/200] [Batch 1540/2910] [D loss: -0.006969] [G loss: 0.500082]\n",
            "[Epoch 107/200] [Batch 2040/2910] [D loss: -0.011710] [G loss: 0.504584]\n",
            "[Epoch 107/200] [Batch 2540/2910] [D loss: -0.009440] [G loss: 0.506568]\n",
            "[Epoch 107/200] [Time: 35.38] [D loss: -0.003988] [G loss: 0.507369]\n",
            "[Epoch 108/200] [Batch  130/2910] [D loss: -0.013111] [G loss: 0.506240]\n",
            "[Epoch 108/200] [Batch  630/2910] [D loss: -0.006986] [G loss: 0.505714]\n",
            "[Epoch 108/200] [Batch 1130/2910] [D loss: -0.010759] [G loss: 0.504706]\n",
            "[Epoch 108/200] [Batch 1630/2910] [D loss: -0.010275] [G loss: 0.506799]\n",
            "[Epoch 108/200] [Batch 2130/2910] [D loss: -0.006625] [G loss: 0.503129]\n",
            "[Epoch 108/200] [Batch 2630/2910] [D loss: -0.004608] [G loss: 0.506095]\n",
            "[Epoch 108/200] [Time: 32.99] [D loss: -0.009925] [G loss: 0.505885]\n",
            "[Epoch 109/200] [Batch  220/2910] [D loss: -0.009461] [G loss: 0.504510]\n",
            "[Epoch 109/200] [Batch  720/2910] [D loss: -0.010475] [G loss: 0.502609]\n",
            "[Epoch 109/200] [Batch 1220/2910] [D loss: -0.004149] [G loss: 0.505589]\n",
            "[Epoch 109/200] [Batch 1720/2910] [D loss: -0.011991] [G loss: 0.506315]\n",
            "[Epoch 109/200] [Batch 2220/2910] [D loss: -0.011159] [G loss: 0.505415]\n",
            "[Epoch 109/200] [Batch 2720/2910] [D loss: -0.011784] [G loss: 0.504781]\n",
            "[Epoch 109/200] [Time: 35.00] [D loss: -0.010311] [G loss: 0.506713]\n",
            "[Epoch 110/200] [Batch  310/2910] [D loss: -0.009812] [G loss: 0.507140]\n",
            "[Epoch 110/200] [Batch  810/2910] [D loss: -0.007212] [G loss: 0.501476]\n",
            "[Epoch 110/200] [Batch 1310/2910] [D loss: -0.010857] [G loss: 0.506642]\n",
            "[Epoch 110/200] [Batch 1810/2910] [D loss: -0.011595] [G loss: 0.505922]\n",
            "[Epoch 110/200] [Batch 2310/2910] [D loss: -0.004363] [G loss: 0.507466]\n",
            "[Epoch 110/200] [Batch 2810/2910] [D loss: -0.008692] [G loss: 0.504883]\n",
            "[Epoch 110/200] [Time: 34.18] [D loss: -0.011018] [G loss: 0.506339]\n",
            "[Epoch 111/200] [Batch  400/2910] [D loss: -0.009633] [G loss: 0.506754]\n",
            "[Epoch 111/200] [Batch  900/2910] [D loss: -0.011436] [G loss: 0.505312]\n",
            "[Epoch 111/200] [Batch 1400/2910] [D loss: -0.006015] [G loss: 0.506759]\n",
            "[Epoch 111/200] [Batch 1900/2910] [D loss: -0.005473] [G loss: 0.506056]\n",
            "[Epoch 111/200] [Batch 2400/2910] [D loss: -0.012301] [G loss: 0.500708]\n",
            "[Epoch 111/200] [Batch 2900/2910] [D loss: -0.012462] [G loss: 0.506873]\n",
            "[Epoch 111/200] [Time: 34.61] [D loss: -0.001544] [G loss: 0.508143]\n",
            "[Epoch 112/200] [Batch  490/2910] [D loss: -0.010010] [G loss: 0.505698]\n",
            "[Epoch 112/200] [Batch  990/2910] [D loss: -0.012310] [G loss: 0.505734]\n",
            "[Epoch 112/200] [Batch 1490/2910] [D loss: -0.009239] [G loss: 0.507081]\n",
            "[Epoch 112/200] [Batch 1990/2910] [D loss: -0.009703] [G loss: 0.505931]\n",
            "[Epoch 112/200] [Batch 2490/2910] [D loss: -0.008004] [G loss: 0.502019]\n",
            "[Epoch 112/200] [Time: 35.64] [D loss: -0.010184] [G loss: 0.503265]\n",
            "[Epoch 113/200] [Batch   80/2910] [D loss: -0.009558] [G loss: 0.504765]\n",
            "[Epoch 113/200] [Batch  580/2910] [D loss: -0.008170] [G loss: 0.506840]\n",
            "[Epoch 113/200] [Batch 1080/2910] [D loss: -0.007385] [G loss: 0.505417]\n",
            "[Epoch 113/200] [Batch 1580/2910] [D loss: -0.003654] [G loss: 0.505440]\n",
            "[Epoch 113/200] [Batch 2080/2910] [D loss: -0.008201] [G loss: 0.503902]\n",
            "[Epoch 113/200] [Batch 2580/2910] [D loss: -0.006221] [G loss: 0.505893]\n",
            "[Epoch 113/200] [Time: 35.17] [D loss: -0.012210] [G loss: 0.501260]\n",
            "[Epoch 114/200] [Batch  170/2910] [D loss: -0.005990] [G loss: 0.503457]\n",
            "[Epoch 114/200] [Batch  670/2910] [D loss: -0.006422] [G loss: 0.505665]\n",
            "[Epoch 114/200] [Batch 1170/2910] [D loss: -0.005835] [G loss: 0.506730]\n",
            "[Epoch 114/200] [Batch 1670/2910] [D loss: -0.005813] [G loss: 0.507396]\n",
            "[Epoch 114/200] [Batch 2170/2910] [D loss: -0.007589] [G loss: 0.507125]\n",
            "[Epoch 114/200] [Batch 2670/2910] [D loss: -0.013515] [G loss: 0.506975]\n",
            "[Epoch 114/200] [Time: 34.14] [D loss: -0.010122] [G loss: 0.506099]\n",
            "[Epoch 115/200] [Batch  260/2910] [D loss: -0.009082] [G loss: 0.507481]\n",
            "[Epoch 115/200] [Batch  760/2910] [D loss: -0.013112] [G loss: 0.506559]\n",
            "[Epoch 115/200] [Batch 1260/2910] [D loss: -0.009371] [G loss: 0.506980]\n",
            "[Epoch 115/200] [Batch 1760/2910] [D loss: -0.010431] [G loss: 0.506259]\n",
            "[Epoch 115/200] [Batch 2260/2910] [D loss: -0.010694] [G loss: 0.506537]\n",
            "[Epoch 115/200] [Batch 2760/2910] [D loss: -0.011928] [G loss: 0.506100]\n",
            "[Epoch 115/200] [Time: 35.28] [D loss: -0.004167] [G loss: 0.507007]\n",
            "[Epoch 116/200] [Batch  350/2910] [D loss: -0.010164] [G loss: 0.504961]\n",
            "[Epoch 116/200] [Batch  850/2910] [D loss: -0.012774] [G loss: 0.507776]\n",
            "[Epoch 116/200] [Batch 1350/2910] [D loss: 0.001735] [G loss: 0.503831]\n",
            "[Epoch 116/200] [Batch 1850/2910] [D loss: -0.011012] [G loss: 0.505285]\n",
            "[Epoch 116/200] [Batch 2350/2910] [D loss: -0.013118] [G loss: 0.505520]\n",
            "[Epoch 116/200] [Batch 2850/2910] [D loss: -0.009419] [G loss: 0.505803]\n",
            "[Epoch 116/200] [Time: 35.14] [D loss: -0.011299] [G loss: 0.507073]\n",
            "[Epoch 117/200] [Batch  440/2910] [D loss: -0.009656] [G loss: 0.503382]\n",
            "[Epoch 117/200] [Batch  940/2910] [D loss: -0.006467] [G loss: 0.505030]\n",
            "[Epoch 117/200] [Batch 1440/2910] [D loss: -0.002741] [G loss: 0.503951]\n",
            "[Epoch 117/200] [Batch 1940/2910] [D loss: -0.011281] [G loss: 0.506377]\n",
            "[Epoch 117/200] [Batch 2440/2910] [D loss: -0.007245] [G loss: 0.505169]\n",
            "[Epoch 117/200] [Time: 35.62] [D loss: -0.000952] [G loss: 0.505779]\n",
            "[Epoch 118/200] [Batch   30/2910] [D loss: -0.005195] [G loss: 0.503380]\n",
            "[Epoch 118/200] [Batch  530/2910] [D loss: -0.004415] [G loss: 0.507021]\n",
            "[Epoch 118/200] [Batch 1030/2910] [D loss: -0.007110] [G loss: 0.506038]\n",
            "[Epoch 118/200] [Batch 1530/2910] [D loss: -0.011713] [G loss: 0.505850]\n",
            "[Epoch 118/200] [Batch 2030/2910] [D loss: -0.009385] [G loss: 0.504535]\n",
            "[Epoch 118/200] [Batch 2530/2910] [D loss: -0.003390] [G loss: 0.503196]\n",
            "[Epoch 118/200] [Time: 33.82] [D loss: -0.005728] [G loss: 0.502195]\n",
            "[Epoch 119/200] [Batch  120/2910] [D loss: -0.005596] [G loss: 0.504261]\n",
            "[Epoch 119/200] [Batch  620/2910] [D loss: -0.008977] [G loss: 0.505044]\n",
            "[Epoch 119/200] [Batch 1120/2910] [D loss: -0.010442] [G loss: 0.504319]\n",
            "[Epoch 119/200] [Batch 1620/2910] [D loss: -0.011355] [G loss: 0.507817]\n",
            "[Epoch 119/200] [Batch 2120/2910] [D loss: -0.007617] [G loss: 0.506572]\n",
            "[Epoch 119/200] [Batch 2620/2910] [D loss: -0.009950] [G loss: 0.504863]\n",
            "[Epoch 119/200] [Time: 33.34] [D loss: -0.008858] [G loss: 0.506191]\n",
            "[Epoch 120/200] [Batch  210/2910] [D loss: -0.009602] [G loss: 0.505599]\n",
            "[Epoch 120/200] [Batch  710/2910] [D loss: -0.010297] [G loss: 0.505333]\n",
            "[Epoch 120/200] [Batch 1210/2910] [D loss: -0.011095] [G loss: 0.506110]\n",
            "[Epoch 120/200] [Batch 1710/2910] [D loss: -0.011671] [G loss: 0.494126]\n",
            "[Epoch 120/200] [Batch 2210/2910] [D loss: -0.008971] [G loss: 0.504665]\n",
            "[Epoch 120/200] [Batch 2710/2910] [D loss: -0.010152] [G loss: 0.500485]\n",
            "[Epoch 120/200] [Time: 34.79] [D loss: -0.005147] [G loss: 0.504680]\n",
            "[Epoch 121/200] [Batch  300/2910] [D loss: -0.008494] [G loss: 0.505565]\n",
            "[Epoch 121/200] [Batch  800/2910] [D loss: -0.010643] [G loss: 0.506034]\n",
            "[Epoch 121/200] [Batch 1300/2910] [D loss: -0.006815] [G loss: 0.507299]\n",
            "[Epoch 121/200] [Batch 1800/2910] [D loss: -0.010073] [G loss: 0.503911]\n",
            "[Epoch 121/200] [Batch 2300/2910] [D loss: -0.004853] [G loss: 0.506262]\n",
            "[Epoch 121/200] [Batch 2800/2910] [D loss: -0.009186] [G loss: 0.501287]\n",
            "[Epoch 121/200] [Time: 35.44] [D loss: -0.008191] [G loss: 0.507552]\n",
            "[Epoch 122/200] [Batch  390/2910] [D loss: -0.004655] [G loss: 0.504954]\n",
            "[Epoch 122/200] [Batch  890/2910] [D loss: -0.003391] [G loss: 0.502379]\n",
            "[Epoch 122/200] [Batch 1390/2910] [D loss: -0.012631] [G loss: 0.504922]\n",
            "[Epoch 122/200] [Batch 1890/2910] [D loss: -0.010939] [G loss: 0.506812]\n",
            "[Epoch 122/200] [Batch 2390/2910] [D loss: -0.007551] [G loss: 0.503780]\n",
            "[Epoch 122/200] [Batch 2890/2910] [D loss: -0.008566] [G loss: 0.500218]\n",
            "[Epoch 122/200] [Time: 35.23] [D loss: -0.006220] [G loss: 0.504078]\n",
            "[Epoch 123/200] [Batch  480/2910] [D loss: -0.006705] [G loss: 0.502848]\n",
            "[Epoch 123/200] [Batch  980/2910] [D loss: -0.013165] [G loss: 0.506987]\n",
            "[Epoch 123/200] [Batch 1480/2910] [D loss: -0.006782] [G loss: 0.504960]\n",
            "[Epoch 123/200] [Batch 1980/2910] [D loss: -0.007937] [G loss: 0.503602]\n",
            "[Epoch 123/200] [Batch 2480/2910] [D loss: -0.013061] [G loss: 0.506004]\n",
            "[Epoch 123/200] [Time: 34.70] [D loss: -0.009398] [G loss: 0.506045]\n",
            "[Epoch 124/200] [Batch   70/2910] [D loss: -0.009035] [G loss: 0.503333]\n",
            "[Epoch 124/200] [Batch  570/2910] [D loss: -0.011277] [G loss: 0.503365]\n",
            "[Epoch 124/200] [Batch 1070/2910] [D loss: -0.012081] [G loss: 0.504227]\n",
            "[Epoch 124/200] [Batch 1570/2910] [D loss: -0.005201] [G loss: 0.503646]\n",
            "[Epoch 124/200] [Batch 2070/2910] [D loss: -0.008209] [G loss: 0.504823]\n",
            "[Epoch 124/200] [Batch 2570/2910] [D loss: -0.006484] [G loss: 0.503526]\n",
            "[Epoch 124/200] [Time: 34.86] [D loss: -0.002862] [G loss: 0.504838]\n",
            "[Epoch 125/200] [Batch  160/2910] [D loss: -0.001180] [G loss: 0.502704]\n",
            "[Epoch 125/200] [Batch  660/2910] [D loss: -0.005185] [G loss: 0.504359]\n",
            "[Epoch 125/200] [Batch 1160/2910] [D loss: -0.010888] [G loss: 0.500496]\n",
            "[Epoch 125/200] [Batch 1660/2910] [D loss: -0.010152] [G loss: 0.503929]\n",
            "[Epoch 125/200] [Batch 2160/2910] [D loss: -0.008903] [G loss: 0.506686]\n",
            "[Epoch 125/200] [Batch 2660/2910] [D loss: -0.006237] [G loss: 0.504262]\n",
            "[Epoch 125/200] [Time: 35.13] [D loss: -0.013737] [G loss: 0.504001]\n",
            "[Epoch 126/200] [Batch  250/2910] [D loss: -0.005533] [G loss: 0.507547]\n",
            "[Epoch 126/200] [Batch  750/2910] [D loss: -0.008912] [G loss: 0.505730]\n",
            "[Epoch 126/200] [Batch 1250/2910] [D loss: -0.010523] [G loss: 0.505739]\n",
            "[Epoch 126/200] [Batch 1750/2910] [D loss: -0.009115] [G loss: 0.503054]\n",
            "[Epoch 126/200] [Batch 2250/2910] [D loss: -0.009844] [G loss: 0.505078]\n",
            "[Epoch 126/200] [Batch 2750/2910] [D loss: -0.004776] [G loss: 0.502714]\n",
            "[Epoch 126/200] [Time: 32.89] [D loss: -0.004529] [G loss: 0.501507]\n",
            "[Epoch 127/200] [Batch  340/2910] [D loss: -0.009433] [G loss: 0.506283]\n",
            "[Epoch 127/200] [Batch  840/2910] [D loss: -0.009117] [G loss: 0.505479]\n",
            "[Epoch 127/200] [Batch 1340/2910] [D loss: -0.011877] [G loss: 0.505777]\n",
            "[Epoch 127/200] [Batch 1840/2910] [D loss: -0.010327] [G loss: 0.504455]\n",
            "[Epoch 127/200] [Batch 2340/2910] [D loss: -0.008331] [G loss: 0.505340]\n",
            "[Epoch 127/200] [Batch 2840/2910] [D loss: -0.006923] [G loss: 0.505601]\n",
            "[Epoch 127/200] [Time: 34.91] [D loss: -0.010388] [G loss: 0.503148]\n",
            "[Epoch 128/200] [Batch  430/2910] [D loss: -0.008836] [G loss: 0.503189]\n",
            "[Epoch 128/200] [Batch  930/2910] [D loss: -0.004955] [G loss: 0.506819]\n",
            "[Epoch 128/200] [Batch 1430/2910] [D loss: -0.006554] [G loss: 0.503057]\n",
            "[Epoch 128/200] [Batch 1930/2910] [D loss: -0.011621] [G loss: 0.502966]\n",
            "[Epoch 128/200] [Batch 2430/2910] [D loss: -0.010958] [G loss: 0.506815]\n",
            "[Epoch 128/200] [Time: 35.07] [D loss: -0.009144] [G loss: 0.507025]\n",
            "[Epoch 129/200] [Batch   20/2910] [D loss: -0.010363] [G loss: 0.505701]\n",
            "[Epoch 129/200] [Batch  520/2910] [D loss: -0.008381] [G loss: 0.504536]\n",
            "[Epoch 129/200] [Batch 1020/2910] [D loss: -0.006566] [G loss: 0.505718]\n",
            "[Epoch 129/200] [Batch 1520/2910] [D loss: -0.008207] [G loss: 0.503835]\n",
            "[Epoch 129/200] [Batch 2020/2910] [D loss: -0.014225] [G loss: 0.501796]\n",
            "[Epoch 129/200] [Batch 2520/2910] [D loss: -0.009584] [G loss: 0.504850]\n",
            "[Epoch 129/200] [Time: 35.32] [D loss: -0.002697] [G loss: 0.507682]\n",
            "[Epoch 130/200] [Batch  110/2910] [D loss: -0.008722] [G loss: 0.506539]\n",
            "[Epoch 130/200] [Batch  610/2910] [D loss: -0.005918] [G loss: 0.505765]\n",
            "[Epoch 130/200] [Batch 1110/2910] [D loss: -0.011554] [G loss: 0.503989]\n",
            "[Epoch 130/200] [Batch 1610/2910] [D loss: -0.008830] [G loss: 0.505462]\n",
            "[Epoch 130/200] [Batch 2110/2910] [D loss: -0.002146] [G loss: 0.502408]\n",
            "[Epoch 130/200] [Batch 2610/2910] [D loss: -0.007349] [G loss: 0.506728]\n",
            "[Epoch 130/200] [Time: 34.68] [D loss: -0.010441] [G loss: 0.506545]\n",
            "[Epoch 131/200] [Batch  200/2910] [D loss: -0.009100] [G loss: 0.506243]\n",
            "[Epoch 131/200] [Batch  700/2910] [D loss: -0.009178] [G loss: 0.502546]\n",
            "[Epoch 131/200] [Batch 1200/2910] [D loss: -0.008727] [G loss: 0.507152]\n",
            "[Epoch 131/200] [Batch 1700/2910] [D loss: -0.004279] [G loss: 0.506413]\n",
            "[Epoch 131/200] [Batch 2200/2910] [D loss: -0.013871] [G loss: 0.502415]\n",
            "[Epoch 131/200] [Batch 2700/2910] [D loss: -0.010609] [G loss: 0.504844]\n",
            "[Epoch 131/200] [Time: 33.24] [D loss: -0.005673] [G loss: 0.505205]\n",
            "[Epoch 132/200] [Batch  290/2910] [D loss: -0.007356] [G loss: 0.506888]\n",
            "[Epoch 132/200] [Batch  790/2910] [D loss: -0.009382] [G loss: 0.506406]\n",
            "[Epoch 132/200] [Batch 1290/2910] [D loss: -0.006350] [G loss: 0.506638]\n",
            "[Epoch 132/200] [Batch 1790/2910] [D loss: -0.003532] [G loss: 0.499014]\n",
            "[Epoch 132/200] [Batch 2290/2910] [D loss: -0.010995] [G loss: 0.505860]\n",
            "[Epoch 132/200] [Batch 2790/2910] [D loss: -0.002741] [G loss: 0.503600]\n",
            "[Epoch 132/200] [Time: 35.50] [D loss: -0.002846] [G loss: 0.506639]\n",
            "[Epoch 133/200] [Batch  380/2910] [D loss: -0.008053] [G loss: 0.505520]\n",
            "[Epoch 133/200] [Batch  880/2910] [D loss: -0.005326] [G loss: 0.506659]\n",
            "[Epoch 133/200] [Batch 1380/2910] [D loss: -0.002712] [G loss: 0.504436]\n",
            "[Epoch 133/200] [Batch 1880/2910] [D loss: -0.010593] [G loss: 0.506303]\n",
            "[Epoch 133/200] [Batch 2380/2910] [D loss: -0.009283] [G loss: 0.502973]\n",
            "[Epoch 133/200] [Batch 2880/2910] [D loss: -0.003148] [G loss: 0.505140]\n",
            "[Epoch 133/200] [Time: 36.02] [D loss: -0.010851] [G loss: 0.500692]\n",
            "[Epoch 134/200] [Batch  470/2910] [D loss: -0.010701] [G loss: 0.506260]\n",
            "[Epoch 134/200] [Batch  970/2910] [D loss: -0.009736] [G loss: 0.505392]\n",
            "[Epoch 134/200] [Batch 1470/2910] [D loss: -0.003557] [G loss: 0.506780]\n",
            "[Epoch 134/200] [Batch 1970/2910] [D loss: -0.010290] [G loss: 0.504230]\n",
            "[Epoch 134/200] [Batch 2470/2910] [D loss: -0.013902] [G loss: 0.504702]\n",
            "[Epoch 134/200] [Time: 35.09] [D loss: -0.010701] [G loss: 0.498580]\n",
            "[Epoch 135/200] [Batch   60/2910] [D loss: -0.008159] [G loss: 0.506064]\n",
            "[Epoch 135/200] [Batch  560/2910] [D loss: -0.009092] [G loss: 0.504834]\n",
            "[Epoch 135/200] [Batch 1060/2910] [D loss: -0.007247] [G loss: 0.506063]\n",
            "[Epoch 135/200] [Batch 1560/2910] [D loss: -0.010755] [G loss: 0.502432]\n",
            "[Epoch 135/200] [Batch 2060/2910] [D loss: -0.011849] [G loss: 0.501318]\n",
            "[Epoch 135/200] [Batch 2560/2910] [D loss: -0.011000] [G loss: 0.506286]\n",
            "[Epoch 135/200] [Time: 32.87] [D loss: -0.006042] [G loss: 0.502241]\n",
            "[Epoch 136/200] [Batch  150/2910] [D loss: -0.006907] [G loss: 0.505309]\n",
            "[Epoch 136/200] [Batch  650/2910] [D loss: -0.006110] [G loss: 0.503807]\n",
            "[Epoch 136/200] [Batch 1150/2910] [D loss: -0.010275] [G loss: 0.507808]\n",
            "[Epoch 136/200] [Batch 1650/2910] [D loss: -0.009173] [G loss: 0.507082]\n",
            "[Epoch 136/200] [Batch 2150/2910] [D loss: -0.003849] [G loss: 0.505075]\n",
            "[Epoch 136/200] [Batch 2650/2910] [D loss: -0.010038] [G loss: 0.500805]\n",
            "[Epoch 136/200] [Time: 34.46] [D loss: -0.007382] [G loss: 0.504798]\n",
            "[Epoch 137/200] [Batch  240/2910] [D loss: -0.008072] [G loss: 0.498190]\n",
            "[Epoch 137/200] [Batch  740/2910] [D loss: -0.011109] [G loss: 0.507439]\n",
            "[Epoch 137/200] [Batch 1240/2910] [D loss: -0.006666] [G loss: 0.506203]\n",
            "[Epoch 137/200] [Batch 1740/2910] [D loss: -0.008683] [G loss: 0.507071]\n",
            "[Epoch 137/200] [Batch 2240/2910] [D loss: -0.009704] [G loss: 0.500060]\n",
            "[Epoch 137/200] [Batch 2740/2910] [D loss: -0.006011] [G loss: 0.500612]\n",
            "[Epoch 137/200] [Time: 35.68] [D loss: -0.005569] [G loss: 0.504205]\n",
            "[Epoch 138/200] [Batch  330/2910] [D loss: -0.008525] [G loss: 0.501620]\n",
            "[Epoch 138/200] [Batch  830/2910] [D loss: -0.002810] [G loss: 0.504691]\n",
            "[Epoch 138/200] [Batch 1330/2910] [D loss: -0.004759] [G loss: 0.505938]\n",
            "[Epoch 138/200] [Batch 1830/2910] [D loss: -0.012627] [G loss: 0.504920]\n",
            "[Epoch 138/200] [Batch 2330/2910] [D loss: -0.009944] [G loss: 0.498040]\n",
            "[Epoch 138/200] [Batch 2830/2910] [D loss: -0.008065] [G loss: 0.506319]\n",
            "[Epoch 138/200] [Time: 34.95] [D loss: -0.013309] [G loss: 0.506474]\n",
            "[Epoch 139/200] [Batch  420/2910] [D loss: -0.008571] [G loss: 0.503666]\n",
            "[Epoch 139/200] [Batch  920/2910] [D loss: -0.010955] [G loss: 0.507204]\n",
            "[Epoch 139/200] [Batch 1420/2910] [D loss: -0.005959] [G loss: 0.504385]\n",
            "[Epoch 139/200] [Batch 1920/2910] [D loss: -0.007959] [G loss: 0.507752]\n",
            "[Epoch 139/200] [Batch 2420/2910] [D loss: -0.006569] [G loss: 0.505182]\n",
            "[Epoch 139/200] [Time: 32.25] [D loss: -0.002350] [G loss: 0.504109]\n",
            "[Epoch 140/200] [Batch   10/2910] [D loss: -0.008003] [G loss: 0.501246]\n",
            "[Epoch 140/200] [Batch  510/2910] [D loss: -0.011717] [G loss: 0.504789]\n",
            "[Epoch 140/200] [Batch 1010/2910] [D loss: -0.011306] [G loss: 0.505150]\n",
            "[Epoch 140/200] [Batch 1510/2910] [D loss: -0.009793] [G loss: 0.505118]\n",
            "[Epoch 140/200] [Batch 2010/2910] [D loss: -0.007092] [G loss: 0.498213]\n",
            "[Epoch 140/200] [Batch 2510/2910] [D loss: -0.010128] [G loss: 0.506298]\n",
            "[Epoch 140/200] [Time: 33.79] [D loss: -0.006730] [G loss: 0.506698]\n",
            "[Epoch 141/200] [Batch  100/2910] [D loss: -0.006072] [G loss: 0.506015]\n",
            "[Epoch 141/200] [Batch  600/2910] [D loss: -0.009109] [G loss: 0.506731]\n",
            "[Epoch 141/200] [Batch 1100/2910] [D loss: -0.000012] [G loss: 0.508400]\n",
            "[Epoch 141/200] [Batch 1600/2910] [D loss: 0.003791] [G loss: 0.503684]\n",
            "[Epoch 141/200] [Batch 2100/2910] [D loss: -0.001715] [G loss: 0.504231]\n",
            "[Epoch 141/200] [Batch 2600/2910] [D loss: 0.000508] [G loss: 0.495979]\n",
            "[Epoch 141/200] [Time: 35.18] [D loss: -0.005263] [G loss: 0.504410]\n",
            "[Epoch 142/200] [Batch  190/2910] [D loss: -0.002082] [G loss: 0.497924]\n",
            "[Epoch 142/200] [Batch  690/2910] [D loss: -0.008371] [G loss: 0.503709]\n",
            "[Epoch 142/200] [Batch 1190/2910] [D loss: -0.006364] [G loss: 0.505104]\n",
            "[Epoch 142/200] [Batch 1690/2910] [D loss: -0.007684] [G loss: 0.498995]\n",
            "[Epoch 142/200] [Batch 2190/2910] [D loss: -0.004279] [G loss: 0.500971]\n",
            "[Epoch 142/200] [Batch 2690/2910] [D loss: -0.005447] [G loss: 0.499899]\n",
            "[Epoch 142/200] [Time: 35.61] [D loss: -0.007160] [G loss: 0.505685]\n",
            "[Epoch 143/200] [Batch  280/2910] [D loss: -0.007401] [G loss: 0.503436]\n",
            "[Epoch 143/200] [Batch  780/2910] [D loss: -0.001918] [G loss: 0.503842]\n",
            "[Epoch 143/200] [Batch 1280/2910] [D loss: -0.007733] [G loss: 0.504246]\n",
            "[Epoch 143/200] [Batch 1780/2910] [D loss: -0.006525] [G loss: 0.505799]\n",
            "[Epoch 143/200] [Batch 2280/2910] [D loss: -0.008251] [G loss: 0.506424]\n",
            "[Epoch 143/200] [Batch 2780/2910] [D loss: -0.008004] [G loss: 0.506963]\n",
            "[Epoch 143/200] [Time: 34.56] [D loss: -0.010442] [G loss: 0.507818]\n",
            "[Epoch 144/200] [Batch  370/2910] [D loss: -0.002145] [G loss: 0.502798]\n",
            "[Epoch 144/200] [Batch  870/2910] [D loss: -0.007505] [G loss: 0.503724]\n",
            "[Epoch 144/200] [Batch 1370/2910] [D loss: -0.003706] [G loss: 0.506028]\n",
            "[Epoch 144/200] [Batch 1870/2910] [D loss: -0.006563] [G loss: 0.502521]\n",
            "[Epoch 144/200] [Batch 2370/2910] [D loss: -0.007950] [G loss: 0.504130]\n",
            "[Epoch 144/200] [Batch 2870/2910] [D loss: -0.007189] [G loss: 0.502088]\n",
            "[Epoch 144/200] [Time: 31.39] [D loss: -0.003417] [G loss: 0.505454]\n",
            "[Epoch 145/200] [Batch  460/2910] [D loss: -0.004554] [G loss: 0.505833]\n",
            "[Epoch 145/200] [Batch  960/2910] [D loss: -0.004414] [G loss: 0.503473]\n",
            "[Epoch 145/200] [Batch 1460/2910] [D loss: -0.011537] [G loss: 0.506479]\n",
            "[Epoch 145/200] [Batch 1960/2910] [D loss: -0.007057] [G loss: 0.499322]\n",
            "[Epoch 145/200] [Batch 2460/2910] [D loss: -0.007838] [G loss: 0.505304]\n",
            "[Epoch 145/200] [Time: 35.41] [D loss: -0.009304] [G loss: 0.504698]\n",
            "[Epoch 146/200] [Batch   50/2910] [D loss: -0.003881] [G loss: 0.502484]\n",
            "[Epoch 146/200] [Batch  550/2910] [D loss: -0.007335] [G loss: 0.497616]\n",
            "[Epoch 146/200] [Batch 1050/2910] [D loss: -0.005245] [G loss: 0.503337]\n",
            "[Epoch 146/200] [Batch 1550/2910] [D loss: -0.008290] [G loss: 0.506117]\n",
            "[Epoch 146/200] [Batch 2050/2910] [D loss: -0.002606] [G loss: 0.505494]\n",
            "[Epoch 146/200] [Batch 2550/2910] [D loss: -0.006992] [G loss: 0.505325]\n",
            "[Epoch 146/200] [Time: 34.81] [D loss: -0.004270] [G loss: 0.504296]\n",
            "[Epoch 147/200] [Batch  140/2910] [D loss: -0.005636] [G loss: 0.503004]\n",
            "[Epoch 147/200] [Batch  640/2910] [D loss: -0.008289] [G loss: 0.504114]\n",
            "[Epoch 147/200] [Batch 1140/2910] [D loss: -0.006168] [G loss: 0.503957]\n",
            "[Epoch 147/200] [Batch 1640/2910] [D loss: -0.003436] [G loss: 0.499808]\n",
            "[Epoch 147/200] [Batch 2140/2910] [D loss: -0.006631] [G loss: 0.505272]\n",
            "[Epoch 147/200] [Batch 2640/2910] [D loss: -0.008336] [G loss: 0.504492]\n",
            "[Epoch 147/200] [Time: 31.83] [D loss: 0.003739] [G loss: 0.505787]\n",
            "[Epoch 148/200] [Batch  230/2910] [D loss: -0.009727] [G loss: 0.502591]\n",
            "[Epoch 148/200] [Batch  730/2910] [D loss: -0.005154] [G loss: 0.504877]\n",
            "[Epoch 148/200] [Batch 1230/2910] [D loss: -0.005521] [G loss: 0.506711]\n",
            "[Epoch 148/200] [Batch 1730/2910] [D loss: -0.005347] [G loss: 0.500090]\n",
            "[Epoch 148/200] [Batch 2230/2910] [D loss: -0.001602] [G loss: 0.507285]\n",
            "[Epoch 148/200] [Batch 2730/2910] [D loss: -0.003766] [G loss: 0.506771]\n",
            "[Epoch 148/200] [Time: 35.10] [D loss: -0.002531] [G loss: 0.502355]\n",
            "[Epoch 149/200] [Batch  320/2910] [D loss: -0.003811] [G loss: 0.506933]\n",
            "[Epoch 149/200] [Batch  820/2910] [D loss: -0.007233] [G loss: 0.504521]\n",
            "[Epoch 149/200] [Batch 1320/2910] [D loss: -0.006149] [G loss: 0.506918]\n",
            "[Epoch 149/200] [Batch 1820/2910] [D loss: -0.005135] [G loss: 0.505856]\n",
            "[Epoch 149/200] [Batch 2320/2910] [D loss: 0.000877] [G loss: 0.500773]\n",
            "[Epoch 149/200] [Batch 2820/2910] [D loss: -0.004000] [G loss: 0.504503]\n",
            "[Epoch 149/200] [Time: 34.30] [D loss: -0.006728] [G loss: 0.501513]\n",
            "[Epoch 150/200] [Batch  410/2910] [D loss: -0.011945] [G loss: 0.502468]\n",
            "[Epoch 150/200] [Batch  910/2910] [D loss: -0.006402] [G loss: 0.504799]\n",
            "[Epoch 150/200] [Batch 1410/2910] [D loss: -0.009555] [G loss: 0.505432]\n",
            "[Epoch 150/200] [Batch 1910/2910] [D loss: -0.001897] [G loss: 0.503362]\n",
            "[Epoch 150/200] [Batch 2410/2910] [D loss: -0.006064] [G loss: 0.503558]\n",
            "[Epoch 150/200] [Batch    0/2910] [D loss: -0.007780] [G loss: 0.504337]\n",
            "[Epoch 150/200] [Time: 32.78] [D loss: -0.007780] [G loss: 0.504337]\n",
            "[Epoch 151/200] [Batch  500/2910] [D loss: -0.007057] [G loss: 0.505433]\n",
            "[Epoch 151/200] [Batch 1000/2910] [D loss: -0.001106] [G loss: 0.508913]\n",
            "[Epoch 151/200] [Batch 1500/2910] [D loss: -0.010747] [G loss: 0.503921]\n",
            "[Epoch 151/200] [Batch 2000/2910] [D loss: -0.007629] [G loss: 0.505619]\n",
            "[Epoch 151/200] [Batch 2500/2910] [D loss: -0.007215] [G loss: 0.503622]\n",
            "[Epoch 151/200] [Time: 32.60] [D loss: -0.010146] [G loss: 0.506362]\n",
            "[Epoch 152/200] [Batch   90/2910] [D loss: -0.003729] [G loss: 0.505977]\n",
            "[Epoch 152/200] [Batch  590/2910] [D loss: -0.009065] [G loss: 0.506595]\n",
            "[Epoch 152/200] [Batch 1090/2910] [D loss: -0.003824] [G loss: 0.503672]\n",
            "[Epoch 152/200] [Batch 1590/2910] [D loss: -0.007094] [G loss: 0.504142]\n",
            "[Epoch 152/200] [Batch 2090/2910] [D loss: -0.006148] [G loss: 0.499877]\n",
            "[Epoch 152/200] [Batch 2590/2910] [D loss: -0.006891] [G loss: 0.501879]\n",
            "[Epoch 152/200] [Time: 33.39] [D loss: -0.007046] [G loss: 0.501750]\n",
            "[Epoch 153/200] [Batch  180/2910] [D loss: -0.006652] [G loss: 0.504623]\n",
            "[Epoch 153/200] [Batch  680/2910] [D loss: -0.008264] [G loss: 0.503287]\n",
            "[Epoch 153/200] [Batch 1180/2910] [D loss: -0.009248] [G loss: 0.507646]\n",
            "[Epoch 153/200] [Batch 1680/2910] [D loss: -0.006869] [G loss: 0.505137]\n",
            "[Epoch 153/200] [Batch 2180/2910] [D loss: -0.004930] [G loss: 0.505739]\n",
            "[Epoch 153/200] [Batch 2680/2910] [D loss: -0.003514] [G loss: 0.499841]\n",
            "[Epoch 153/200] [Time: 34.16] [D loss: -0.003919] [G loss: 0.507348]\n",
            "[Epoch 154/200] [Batch  270/2910] [D loss: -0.007234] [G loss: 0.503853]\n",
            "[Epoch 154/200] [Batch  770/2910] [D loss: -0.002297] [G loss: 0.506789]\n",
            "[Epoch 154/200] [Batch 1270/2910] [D loss: -0.009770] [G loss: 0.506526]\n",
            "[Epoch 154/200] [Batch 1770/2910] [D loss: -0.010443] [G loss: 0.502376]\n",
            "[Epoch 154/200] [Batch 2270/2910] [D loss: -0.002880] [G loss: 0.502784]\n",
            "[Epoch 154/200] [Batch 2770/2910] [D loss: -0.003816] [G loss: 0.505692]\n",
            "[Epoch 154/200] [Time: 30.33] [D loss: -0.000794] [G loss: 0.503373]\n",
            "[Epoch 155/200] [Batch  360/2910] [D loss: -0.005295] [G loss: 0.505053]\n",
            "[Epoch 155/200] [Batch  860/2910] [D loss: -0.005831] [G loss: 0.500663]\n",
            "[Epoch 155/200] [Batch 1360/2910] [D loss: -0.010369] [G loss: 0.498114]\n",
            "[Epoch 155/200] [Batch 1860/2910] [D loss: -0.005272] [G loss: 0.503775]\n",
            "[Epoch 155/200] [Batch 2360/2910] [D loss: -0.008970] [G loss: 0.506309]\n",
            "[Epoch 155/200] [Batch 2860/2910] [D loss: -0.003601] [G loss: 0.504535]\n",
            "[Epoch 155/200] [Time: 34.19] [D loss: -0.008719] [G loss: 0.500447]\n",
            "[Epoch 156/200] [Batch  450/2910] [D loss: -0.009159] [G loss: 0.506176]\n",
            "[Epoch 156/200] [Batch  950/2910] [D loss: -0.003214] [G loss: 0.505728]\n",
            "[Epoch 156/200] [Batch 1450/2910] [D loss: -0.003302] [G loss: 0.503136]\n",
            "[Epoch 156/200] [Batch 1950/2910] [D loss: -0.009942] [G loss: 0.501866]\n",
            "[Epoch 156/200] [Batch 2450/2910] [D loss: -0.003539] [G loss: 0.505827]\n",
            "[Epoch 156/200] [Time: 32.87] [D loss: -0.006453] [G loss: 0.501088]\n",
            "[Epoch 157/200] [Batch   40/2910] [D loss: -0.003851] [G loss: 0.504333]\n",
            "[Epoch 157/200] [Batch  540/2910] [D loss: -0.005494] [G loss: 0.501992]\n",
            "[Epoch 157/200] [Batch 1040/2910] [D loss: -0.006210] [G loss: 0.504683]\n",
            "[Epoch 157/200] [Batch 1540/2910] [D loss: -0.010772] [G loss: 0.505654]\n",
            "[Epoch 157/200] [Batch 2040/2910] [D loss: -0.004702] [G loss: 0.503848]\n",
            "[Epoch 157/200] [Batch 2540/2910] [D loss: -0.006971] [G loss: 0.501935]\n",
            "[Epoch 157/200] [Time: 34.88] [D loss: -0.011379] [G loss: 0.505203]\n",
            "[Epoch 158/200] [Batch  130/2910] [D loss: -0.009256] [G loss: 0.502089]\n",
            "[Epoch 158/200] [Batch  630/2910] [D loss: -0.010253] [G loss: 0.505330]\n",
            "[Epoch 158/200] [Batch 1130/2910] [D loss: -0.005963] [G loss: 0.504089]\n",
            "[Epoch 158/200] [Batch 1630/2910] [D loss: -0.008891] [G loss: 0.504585]\n",
            "[Epoch 158/200] [Batch 2130/2910] [D loss: -0.007142] [G loss: 0.502614]\n",
            "[Epoch 158/200] [Batch 2630/2910] [D loss: 0.000425] [G loss: 0.504914]\n",
            "[Epoch 158/200] [Time: 34.30] [D loss: -0.009514] [G loss: 0.503912]\n",
            "[Epoch 159/200] [Batch  220/2910] [D loss: -0.011050] [G loss: 0.499333]\n",
            "[Epoch 159/200] [Batch  720/2910] [D loss: -0.003767] [G loss: 0.506485]\n",
            "[Epoch 159/200] [Batch 1220/2910] [D loss: -0.000993] [G loss: 0.501230]\n",
            "[Epoch 159/200] [Batch 1720/2910] [D loss: -0.006039] [G loss: 0.504225]\n",
            "[Epoch 159/200] [Batch 2220/2910] [D loss: -0.002540] [G loss: 0.497254]\n",
            "[Epoch 159/200] [Batch 2720/2910] [D loss: -0.002096] [G loss: 0.505073]\n",
            "[Epoch 159/200] [Time: 35.54] [D loss: -0.004039] [G loss: 0.504716]\n",
            "[Epoch 160/200] [Batch  310/2910] [D loss: -0.007393] [G loss: 0.505563]\n",
            "[Epoch 160/200] [Batch  810/2910] [D loss: -0.004176] [G loss: 0.500975]\n",
            "[Epoch 160/200] [Batch 1310/2910] [D loss: -0.006527] [G loss: 0.504550]\n",
            "[Epoch 160/200] [Batch 1810/2910] [D loss: -0.006949] [G loss: 0.502857]\n",
            "[Epoch 160/200] [Batch 2310/2910] [D loss: -0.007057] [G loss: 0.505792]\n",
            "[Epoch 160/200] [Batch 2810/2910] [D loss: -0.006277] [G loss: 0.499485]\n",
            "[Epoch 160/200] [Time: 35.07] [D loss: -0.008791] [G loss: 0.504871]\n",
            "[Epoch 161/200] [Batch  400/2910] [D loss: -0.009183] [G loss: 0.505909]\n",
            "[Epoch 161/200] [Batch  900/2910] [D loss: -0.007634] [G loss: 0.503466]\n",
            "[Epoch 161/200] [Batch 1400/2910] [D loss: -0.008846] [G loss: 0.505007]\n",
            "[Epoch 161/200] [Batch 1900/2910] [D loss: -0.008599] [G loss: 0.505727]\n",
            "[Epoch 161/200] [Batch 2400/2910] [D loss: -0.006794] [G loss: 0.504961]\n",
            "[Epoch 161/200] [Batch 2900/2910] [D loss: -0.000687] [G loss: 0.505193]\n",
            "[Epoch 161/200] [Time: 35.30] [D loss: -0.006211] [G loss: 0.501013]\n",
            "[Epoch 162/200] [Batch  490/2910] [D loss: -0.002063] [G loss: 0.505342]\n",
            "[Epoch 162/200] [Batch  990/2910] [D loss: -0.004051] [G loss: 0.504113]\n",
            "[Epoch 162/200] [Batch 1490/2910] [D loss: -0.007889] [G loss: 0.500113]\n",
            "[Epoch 162/200] [Batch 1990/2910] [D loss: -0.008150] [G loss: 0.504035]\n",
            "[Epoch 162/200] [Batch 2490/2910] [D loss: -0.008222] [G loss: 0.505248]\n",
            "[Epoch 162/200] [Time: 35.24] [D loss: -0.000751] [G loss: 0.501478]\n",
            "[Epoch 163/200] [Batch   80/2910] [D loss: -0.008032] [G loss: 0.503546]\n",
            "[Epoch 163/200] [Batch  580/2910] [D loss: -0.005961] [G loss: 0.503531]\n",
            "[Epoch 163/200] [Batch 1080/2910] [D loss: -0.005698] [G loss: 0.502961]\n",
            "[Epoch 163/200] [Batch 1580/2910] [D loss: -0.010431] [G loss: 0.504029]\n",
            "[Epoch 163/200] [Batch 2080/2910] [D loss: -0.010520] [G loss: 0.504323]\n",
            "[Epoch 163/200] [Batch 2580/2910] [D loss: -0.011526] [G loss: 0.504759]\n",
            "[Epoch 163/200] [Time: 31.47] [D loss: -0.012604] [G loss: 0.506726]\n",
            "[Epoch 164/200] [Batch  170/2910] [D loss: -0.000785] [G loss: 0.502341]\n",
            "[Epoch 164/200] [Batch  670/2910] [D loss: -0.006245] [G loss: 0.500649]\n",
            "[Epoch 164/200] [Batch 1170/2910] [D loss: -0.008692] [G loss: 0.503671]\n",
            "[Epoch 164/200] [Batch 1670/2910] [D loss: -0.003498] [G loss: 0.503814]\n",
            "[Epoch 164/200] [Batch 2170/2910] [D loss: -0.008193] [G loss: 0.503994]\n",
            "[Epoch 164/200] [Batch 2670/2910] [D loss: -0.006747] [G loss: 0.504083]\n",
            "[Epoch 164/200] [Time: 35.15] [D loss: 0.005018] [G loss: 0.502220]\n",
            "[Epoch 165/200] [Batch  260/2910] [D loss: -0.003576] [G loss: 0.504882]\n",
            "[Epoch 165/200] [Batch  760/2910] [D loss: -0.003808] [G loss: 0.506001]\n",
            "[Epoch 165/200] [Batch 1260/2910] [D loss: -0.006209] [G loss: 0.498875]\n",
            "[Epoch 165/200] [Batch 1760/2910] [D loss: -0.004469] [G loss: 0.504501]\n",
            "[Epoch 165/200] [Batch 2260/2910] [D loss: -0.005962] [G loss: 0.504835]\n",
            "[Epoch 165/200] [Batch 2760/2910] [D loss: -0.008553] [G loss: 0.503798]\n",
            "[Epoch 165/200] [Time: 36.05] [D loss: -0.006548] [G loss: 0.498047]\n",
            "[Epoch 166/200] [Batch  350/2910] [D loss: -0.009990] [G loss: 0.502795]\n",
            "[Epoch 166/200] [Batch  850/2910] [D loss: -0.003743] [G loss: 0.498880]\n",
            "[Epoch 166/200] [Batch 1350/2910] [D loss: -0.006292] [G loss: 0.505294]\n",
            "[Epoch 166/200] [Batch 1850/2910] [D loss: -0.003587] [G loss: 0.500429]\n",
            "[Epoch 166/200] [Batch 2350/2910] [D loss: -0.000385] [G loss: 0.505705]\n",
            "[Epoch 166/200] [Batch 2850/2910] [D loss: -0.003202] [G loss: 0.503831]\n",
            "[Epoch 166/200] [Time: 35.45] [D loss: -0.002747] [G loss: 0.506147]\n",
            "[Epoch 167/200] [Batch  440/2910] [D loss: -0.006448] [G loss: 0.502820]\n",
            "[Epoch 167/200] [Batch  940/2910] [D loss: 0.001016] [G loss: 0.501720]\n",
            "[Epoch 167/200] [Batch 1440/2910] [D loss: -0.012483] [G loss: 0.505097]\n",
            "[Epoch 167/200] [Batch 1940/2910] [D loss: -0.000120] [G loss: 0.503003]\n",
            "[Epoch 167/200] [Batch 2440/2910] [D loss: -0.004908] [G loss: 0.504680]\n",
            "[Epoch 167/200] [Time: 35.60] [D loss: 0.005713] [G loss: 0.499557]\n",
            "[Epoch 168/200] [Batch   30/2910] [D loss: -0.008707] [G loss: 0.501813]\n",
            "[Epoch 168/200] [Batch  530/2910] [D loss: -0.007752] [G loss: 0.504938]\n",
            "[Epoch 168/200] [Batch 1030/2910] [D loss: -0.006262] [G loss: 0.498804]\n",
            "[Epoch 168/200] [Batch 1530/2910] [D loss: -0.006983] [G loss: 0.506435]\n",
            "[Epoch 168/200] [Batch 2030/2910] [D loss: -0.011934] [G loss: 0.505069]\n",
            "[Epoch 168/200] [Batch 2530/2910] [D loss: -0.003108] [G loss: 0.504590]\n",
            "[Epoch 168/200] [Time: 34.38] [D loss: -0.009778] [G loss: 0.502616]\n",
            "[Epoch 169/200] [Batch  120/2910] [D loss: -0.007499] [G loss: 0.505569]\n",
            "[Epoch 169/200] [Batch  620/2910] [D loss: -0.008773] [G loss: 0.504811]\n",
            "[Epoch 169/200] [Batch 1120/2910] [D loss: -0.006992] [G loss: 0.499723]\n",
            "[Epoch 169/200] [Batch 1620/2910] [D loss: -0.010077] [G loss: 0.503369]\n",
            "[Epoch 169/200] [Batch 2120/2910] [D loss: -0.007390] [G loss: 0.504559]\n",
            "[Epoch 169/200] [Batch 2620/2910] [D loss: -0.005278] [G loss: 0.503165]\n",
            "[Epoch 169/200] [Time: 34.49] [D loss: -0.007967] [G loss: 0.502445]\n",
            "[Epoch 170/200] [Batch  210/2910] [D loss: -0.001559] [G loss: 0.504539]\n",
            "[Epoch 170/200] [Batch  710/2910] [D loss: -0.004901] [G loss: 0.506748]\n",
            "[Epoch 170/200] [Batch 1210/2910] [D loss: -0.005289] [G loss: 0.505511]\n",
            "[Epoch 170/200] [Batch 1710/2910] [D loss: -0.006676] [G loss: 0.506203]\n",
            "[Epoch 170/200] [Batch 2210/2910] [D loss: -0.002177] [G loss: 0.499199]\n",
            "[Epoch 170/200] [Batch 2710/2910] [D loss: -0.006017] [G loss: 0.499369]\n",
            "[Epoch 170/200] [Time: 34.79] [D loss: -0.000034] [G loss: 0.504734]\n",
            "[Epoch 171/200] [Batch  300/2910] [D loss: -0.008361] [G loss: 0.502316]\n",
            "[Epoch 171/200] [Batch  800/2910] [D loss: -0.003360] [G loss: 0.504531]\n",
            "[Epoch 171/200] [Batch 1300/2910] [D loss: -0.002622] [G loss: 0.504734]\n",
            "[Epoch 171/200] [Batch 1800/2910] [D loss: -0.006330] [G loss: 0.506191]\n",
            "[Epoch 171/200] [Batch 2300/2910] [D loss: -0.011097] [G loss: 0.503382]\n",
            "[Epoch 171/200] [Batch 2800/2910] [D loss: -0.004183] [G loss: 0.507628]\n",
            "[Epoch 171/200] [Time: 33.60] [D loss: -0.009941] [G loss: 0.504208]\n",
            "[Epoch 172/200] [Batch  390/2910] [D loss: -0.000141] [G loss: 0.499525]\n",
            "[Epoch 172/200] [Batch  890/2910] [D loss: -0.007480] [G loss: 0.501467]\n",
            "[Epoch 172/200] [Batch 1390/2910] [D loss: -0.005148] [G loss: 0.504677]\n",
            "[Epoch 172/200] [Batch 1890/2910] [D loss: -0.009070] [G loss: 0.504557]\n",
            "[Epoch 172/200] [Batch 2390/2910] [D loss: -0.004045] [G loss: 0.502351]\n",
            "[Epoch 172/200] [Batch 2890/2910] [D loss: -0.004676] [G loss: 0.505760]\n",
            "[Epoch 172/200] [Time: 35.31] [D loss: -0.009100] [G loss: 0.498993]\n",
            "[Epoch 173/200] [Batch  480/2910] [D loss: -0.003198] [G loss: 0.506191]\n",
            "[Epoch 173/200] [Batch  980/2910] [D loss: -0.008171] [G loss: 0.505345]\n",
            "[Epoch 173/200] [Batch 1480/2910] [D loss: -0.004004] [G loss: 0.503370]\n",
            "[Epoch 173/200] [Batch 1980/2910] [D loss: -0.005326] [G loss: 0.504340]\n",
            "[Epoch 173/200] [Batch 2480/2910] [D loss: -0.006818] [G loss: 0.505684]\n",
            "[Epoch 173/200] [Time: 33.75] [D loss: -0.007726] [G loss: 0.502018]\n",
            "[Epoch 174/200] [Batch   70/2910] [D loss: -0.007345] [G loss: 0.506478]\n",
            "[Epoch 174/200] [Batch  570/2910] [D loss: -0.004787] [G loss: 0.502740]\n",
            "[Epoch 174/200] [Batch 1070/2910] [D loss: -0.010332] [G loss: 0.500967]\n",
            "[Epoch 174/200] [Batch 1570/2910] [D loss: -0.005936] [G loss: 0.506709]\n",
            "[Epoch 174/200] [Batch 2070/2910] [D loss: -0.008286] [G loss: 0.504260]\n",
            "[Epoch 174/200] [Batch 2570/2910] [D loss: -0.009098] [G loss: 0.502970]\n",
            "[Epoch 174/200] [Time: 35.12] [D loss: -0.001152] [G loss: 0.501382]\n",
            "[Epoch 175/200] [Batch  160/2910] [D loss: -0.002445] [G loss: 0.499546]\n",
            "[Epoch 175/200] [Batch  660/2910] [D loss: -0.010853] [G loss: 0.503064]\n",
            "[Epoch 175/200] [Batch 1160/2910] [D loss: -0.006032] [G loss: 0.503808]\n",
            "[Epoch 175/200] [Batch 1660/2910] [D loss: -0.009467] [G loss: 0.497937]\n",
            "[Epoch 175/200] [Batch 2160/2910] [D loss: -0.004199] [G loss: 0.501865]\n",
            "[Epoch 175/200] [Batch 2660/2910] [D loss: -0.006623] [G loss: 0.504340]\n",
            "[Epoch 175/200] [Time: 35.28] [D loss: -0.007479] [G loss: 0.504308]\n",
            "[Epoch 176/200] [Batch  250/2910] [D loss: 0.000156] [G loss: 0.499897]\n",
            "[Epoch 176/200] [Batch  750/2910] [D loss: -0.008052] [G loss: 0.494656]\n",
            "[Epoch 176/200] [Batch 1250/2910] [D loss: -0.004795] [G loss: 0.504026]\n",
            "[Epoch 176/200] [Batch 1750/2910] [D loss: -0.004089] [G loss: 0.506879]\n",
            "[Epoch 176/200] [Batch 2250/2910] [D loss: -0.005135] [G loss: 0.500665]\n",
            "[Epoch 176/200] [Batch 2750/2910] [D loss: -0.007061] [G loss: 0.501612]\n",
            "[Epoch 176/200] [Time: 35.05] [D loss: -0.006553] [G loss: 0.504245]\n",
            "[Epoch 177/200] [Batch  340/2910] [D loss: -0.009336] [G loss: 0.506101]\n",
            "[Epoch 177/200] [Batch  840/2910] [D loss: -0.013865] [G loss: 0.505651]\n",
            "[Epoch 177/200] [Batch 1340/2910] [D loss: -0.006876] [G loss: 0.501764]\n",
            "[Epoch 177/200] [Batch 1840/2910] [D loss: 0.001120] [G loss: 0.506789]\n",
            "[Epoch 177/200] [Batch 2340/2910] [D loss: -0.005786] [G loss: 0.502643]\n",
            "[Epoch 177/200] [Batch 2840/2910] [D loss: -0.001118] [G loss: 0.506779]\n",
            "[Epoch 177/200] [Time: 33.04] [D loss: -0.004486] [G loss: 0.503316]\n",
            "[Epoch 178/200] [Batch  430/2910] [D loss: -0.005417] [G loss: 0.505768]\n",
            "[Epoch 178/200] [Batch  930/2910] [D loss: -0.010614] [G loss: 0.504651]\n",
            "[Epoch 178/200] [Batch 1430/2910] [D loss: -0.005672] [G loss: 0.506598]\n",
            "[Epoch 178/200] [Batch 1930/2910] [D loss: -0.002306] [G loss: 0.502385]\n",
            "[Epoch 178/200] [Batch 2430/2910] [D loss: -0.007899] [G loss: 0.504095]\n",
            "[Epoch 178/200] [Time: 33.39] [D loss: -0.008719] [G loss: 0.507188]\n",
            "[Epoch 179/200] [Batch   20/2910] [D loss: -0.008259] [G loss: 0.505355]\n",
            "[Epoch 179/200] [Batch  520/2910] [D loss: -0.006752] [G loss: 0.504041]\n",
            "[Epoch 179/200] [Batch 1020/2910] [D loss: -0.005450] [G loss: 0.503378]\n",
            "[Epoch 179/200] [Batch 1520/2910] [D loss: -0.011905] [G loss: 0.504261]\n",
            "[Epoch 179/200] [Batch 2020/2910] [D loss: -0.002862] [G loss: 0.504269]\n",
            "[Epoch 179/200] [Batch 2520/2910] [D loss: -0.009007] [G loss: 0.502719]\n",
            "[Epoch 179/200] [Time: 35.37] [D loss: -0.005649] [G loss: 0.503423]\n",
            "[Epoch 180/200] [Batch  110/2910] [D loss: -0.012012] [G loss: 0.500453]\n",
            "[Epoch 180/200] [Batch  610/2910] [D loss: -0.007098] [G loss: 0.504776]\n",
            "[Epoch 180/200] [Batch 1110/2910] [D loss: -0.003877] [G loss: 0.506062]\n",
            "[Epoch 180/200] [Batch 1610/2910] [D loss: 0.000849] [G loss: 0.506095]\n",
            "[Epoch 180/200] [Batch 2110/2910] [D loss: -0.005806] [G loss: 0.500334]\n",
            "[Epoch 180/200] [Batch 2610/2910] [D loss: -0.004583] [G loss: 0.500432]\n",
            "[Epoch 180/200] [Time: 35.30] [D loss: 0.004763] [G loss: 0.501197]\n",
            "[Epoch 181/200] [Batch  200/2910] [D loss: -0.006154] [G loss: 0.505939]\n",
            "[Epoch 181/200] [Batch  700/2910] [D loss: -0.008484] [G loss: 0.501969]\n",
            "[Epoch 181/200] [Batch 1200/2910] [D loss: -0.009173] [G loss: 0.506266]\n",
            "[Epoch 181/200] [Batch 1700/2910] [D loss: -0.005615] [G loss: 0.505441]\n",
            "[Epoch 181/200] [Batch 2200/2910] [D loss: -0.008048] [G loss: 0.501284]\n",
            "[Epoch 181/200] [Batch 2700/2910] [D loss: -0.003715] [G loss: 0.502871]\n",
            "[Epoch 181/200] [Time: 35.32] [D loss: -0.009393] [G loss: 0.503787]\n",
            "[Epoch 182/200] [Batch  290/2910] [D loss: -0.009279] [G loss: 0.503413]\n",
            "[Epoch 182/200] [Batch  790/2910] [D loss: -0.002785] [G loss: 0.506445]\n",
            "[Epoch 182/200] [Batch 1290/2910] [D loss: -0.003759] [G loss: 0.501945]\n",
            "[Epoch 182/200] [Batch 1790/2910] [D loss: -0.005927] [G loss: 0.501286]\n",
            "[Epoch 182/200] [Batch 2290/2910] [D loss: -0.008634] [G loss: 0.503622]\n",
            "[Epoch 182/200] [Batch 2790/2910] [D loss: -0.007791] [G loss: 0.502229]\n",
            "[Epoch 182/200] [Time: 34.24] [D loss: -0.002043] [G loss: 0.505008]\n",
            "[Epoch 183/200] [Batch  380/2910] [D loss: -0.009509] [G loss: 0.502188]\n",
            "[Epoch 183/200] [Batch  880/2910] [D loss: 0.000442] [G loss: 0.506074]\n",
            "[Epoch 183/200] [Batch 1380/2910] [D loss: -0.008141] [G loss: 0.505929]\n",
            "[Epoch 183/200] [Batch 1880/2910] [D loss: -0.002317] [G loss: 0.505571]\n",
            "[Epoch 183/200] [Batch 2380/2910] [D loss: -0.009327] [G loss: 0.500525]\n",
            "[Epoch 183/200] [Batch 2880/2910] [D loss: -0.004412] [G loss: 0.505331]\n",
            "[Epoch 183/200] [Time: 35.35] [D loss: -0.000226] [G loss: 0.502278]\n",
            "[Epoch 184/200] [Batch  470/2910] [D loss: -0.009831] [G loss: 0.500825]\n",
            "[Epoch 184/200] [Batch  970/2910] [D loss: -0.005170] [G loss: 0.502967]\n",
            "[Epoch 184/200] [Batch 1470/2910] [D loss: -0.006654] [G loss: 0.500584]\n",
            "[Epoch 184/200] [Batch 1970/2910] [D loss: -0.007103] [G loss: 0.506350]\n",
            "[Epoch 184/200] [Batch 2470/2910] [D loss: -0.004515] [G loss: 0.501602]\n",
            "[Epoch 184/200] [Time: 35.51] [D loss: -0.006585] [G loss: 0.500877]\n",
            "[Epoch 185/200] [Batch   60/2910] [D loss: -0.007191] [G loss: 0.501895]\n",
            "[Epoch 185/200] [Batch  560/2910] [D loss: -0.006523] [G loss: 0.502989]\n",
            "[Epoch 185/200] [Batch 1060/2910] [D loss: -0.006622] [G loss: 0.505041]\n",
            "[Epoch 185/200] [Batch 1560/2910] [D loss: -0.006813] [G loss: 0.505315]\n",
            "[Epoch 185/200] [Batch 2060/2910] [D loss: -0.009965] [G loss: 0.504648]\n",
            "[Epoch 185/200] [Batch 2560/2910] [D loss: -0.000657] [G loss: 0.505127]\n",
            "[Epoch 185/200] [Time: 34.86] [D loss: -0.011411] [G loss: 0.506993]\n",
            "[Epoch 186/200] [Batch  150/2910] [D loss: -0.002605] [G loss: 0.501717]\n",
            "[Epoch 186/200] [Batch  650/2910] [D loss: -0.003650] [G loss: 0.501374]\n",
            "[Epoch 186/200] [Batch 1150/2910] [D loss: -0.004883] [G loss: 0.503418]\n",
            "[Epoch 186/200] [Batch 1650/2910] [D loss: -0.003096] [G loss: 0.500676]\n",
            "[Epoch 186/200] [Batch 2150/2910] [D loss: -0.005592] [G loss: 0.505468]\n",
            "[Epoch 186/200] [Batch 2650/2910] [D loss: -0.006211] [G loss: 0.504691]\n",
            "[Epoch 186/200] [Time: 34.58] [D loss: -0.007217] [G loss: 0.504871]\n",
            "[Epoch 187/200] [Batch  240/2910] [D loss: -0.001444] [G loss: 0.504504]\n",
            "[Epoch 187/200] [Batch  740/2910] [D loss: -0.006655] [G loss: 0.503058]\n",
            "[Epoch 187/200] [Batch 1240/2910] [D loss: -0.007810] [G loss: 0.495638]\n",
            "[Epoch 187/200] [Batch 1740/2910] [D loss: -0.004672] [G loss: 0.503326]\n",
            "[Epoch 187/200] [Batch 2240/2910] [D loss: -0.002507] [G loss: 0.507430]\n",
            "[Epoch 187/200] [Batch 2740/2910] [D loss: 0.000266] [G loss: 0.500766]\n",
            "[Epoch 187/200] [Time: 35.19] [D loss: -0.005425] [G loss: 0.503528]\n",
            "[Epoch 188/200] [Batch  330/2910] [D loss: -0.002717] [G loss: 0.505502]\n",
            "[Epoch 188/200] [Batch  830/2910] [D loss: -0.006994] [G loss: 0.505146]\n",
            "[Epoch 188/200] [Batch 1330/2910] [D loss: -0.002036] [G loss: 0.504808]\n",
            "[Epoch 188/200] [Batch 1830/2910] [D loss: 0.000512] [G loss: 0.503346]\n",
            "[Epoch 188/200] [Batch 2330/2910] [D loss: -0.006308] [G loss: 0.504001]\n",
            "[Epoch 188/200] [Batch 2830/2910] [D loss: -0.009548] [G loss: 0.503612]\n",
            "[Epoch 188/200] [Time: 34.64] [D loss: -0.008748] [G loss: 0.505648]\n",
            "[Epoch 189/200] [Batch  420/2910] [D loss: -0.008779] [G loss: 0.498430]\n",
            "[Epoch 189/200] [Batch  920/2910] [D loss: 0.001661] [G loss: 0.501606]\n",
            "[Epoch 189/200] [Batch 1420/2910] [D loss: -0.008629] [G loss: 0.502616]\n",
            "[Epoch 189/200] [Batch 1920/2910] [D loss: -0.007289] [G loss: 0.507779]\n",
            "[Epoch 189/200] [Batch 2420/2910] [D loss: -0.007539] [G loss: 0.505391]\n",
            "[Epoch 189/200] [Time: 34.97] [D loss: -0.011414] [G loss: 0.502542]\n",
            "[Epoch 190/200] [Batch   10/2910] [D loss: -0.009535] [G loss: 0.504701]\n",
            "[Epoch 190/200] [Batch  510/2910] [D loss: -0.004786] [G loss: 0.501309]\n",
            "[Epoch 190/200] [Batch 1010/2910] [D loss: -0.000047] [G loss: 0.505179]\n",
            "[Epoch 190/200] [Batch 1510/2910] [D loss: -0.007866] [G loss: 0.498548]\n",
            "[Epoch 190/200] [Batch 2010/2910] [D loss: -0.007641] [G loss: 0.504289]\n",
            "[Epoch 190/200] [Batch 2510/2910] [D loss: -0.009744] [G loss: 0.505834]\n",
            "[Epoch 190/200] [Time: 34.30] [D loss: -0.006477] [G loss: 0.502527]\n",
            "[Epoch 191/200] [Batch  100/2910] [D loss: -0.003619] [G loss: 0.501633]\n",
            "[Epoch 191/200] [Batch  600/2910] [D loss: -0.006825] [G loss: 0.504712]\n",
            "[Epoch 191/200] [Batch 1100/2910] [D loss: -0.005290] [G loss: 0.500615]\n",
            "[Epoch 191/200] [Batch 1600/2910] [D loss: -0.002320] [G loss: 0.505108]\n",
            "[Epoch 191/200] [Batch 2100/2910] [D loss: -0.009960] [G loss: 0.504862]\n",
            "[Epoch 191/200] [Batch 2600/2910] [D loss: -0.006993] [G loss: 0.505837]\n",
            "[Epoch 191/200] [Time: 35.01] [D loss: -0.010296] [G loss: 0.504354]\n",
            "[Epoch 192/200] [Batch  190/2910] [D loss: -0.007687] [G loss: 0.504932]\n",
            "[Epoch 192/200] [Batch  690/2910] [D loss: -0.004936] [G loss: 0.503613]\n",
            "[Epoch 192/200] [Batch 1190/2910] [D loss: -0.009997] [G loss: 0.503246]\n",
            "[Epoch 192/200] [Batch 1690/2910] [D loss: -0.007923] [G loss: 0.502290]\n",
            "[Epoch 192/200] [Batch 2190/2910] [D loss: -0.007478] [G loss: 0.502375]\n",
            "[Epoch 192/200] [Batch 2690/2910] [D loss: -0.005123] [G loss: 0.499316]\n",
            "[Epoch 192/200] [Time: 34.36] [D loss: -0.007004] [G loss: 0.505679]\n",
            "[Epoch 193/200] [Batch  280/2910] [D loss: -0.004919] [G loss: 0.502661]\n",
            "[Epoch 193/200] [Batch  780/2910] [D loss: -0.007131] [G loss: 0.502083]\n",
            "[Epoch 193/200] [Batch 1280/2910] [D loss: -0.008042] [G loss: 0.504917]\n",
            "[Epoch 193/200] [Batch 1780/2910] [D loss: -0.007521] [G loss: 0.503643]\n",
            "[Epoch 193/200] [Batch 2280/2910] [D loss: -0.010519] [G loss: 0.502617]\n",
            "[Epoch 193/200] [Batch 2780/2910] [D loss: -0.004855] [G loss: 0.505998]\n",
            "[Epoch 193/200] [Time: 35.86] [D loss: -0.009573] [G loss: 0.507398]\n",
            "[Epoch 194/200] [Batch  370/2910] [D loss: -0.001392] [G loss: 0.502841]\n",
            "[Epoch 194/200] [Batch  870/2910] [D loss: -0.008884] [G loss: 0.497040]\n",
            "[Epoch 194/200] [Batch 1370/2910] [D loss: -0.006489] [G loss: 0.507023]\n",
            "[Epoch 194/200] [Batch 1870/2910] [D loss: -0.006779] [G loss: 0.501936]\n",
            "[Epoch 194/200] [Batch 2370/2910] [D loss: -0.004273] [G loss: 0.502104]\n",
            "[Epoch 194/200] [Batch 2870/2910] [D loss: -0.003751] [G loss: 0.501195]\n",
            "[Epoch 194/200] [Time: 35.59] [D loss: -0.004467] [G loss: 0.504079]\n",
            "[Epoch 195/200] [Batch  460/2910] [D loss: -0.009773] [G loss: 0.501425]\n",
            "[Epoch 195/200] [Batch  960/2910] [D loss: 0.003493] [G loss: 0.506203]\n",
            "[Epoch 195/200] [Batch 1460/2910] [D loss: -0.011554] [G loss: 0.502957]\n",
            "[Epoch 195/200] [Batch 1960/2910] [D loss: -0.004479] [G loss: 0.505911]\n",
            "[Epoch 195/200] [Batch 2460/2910] [D loss: -0.010087] [G loss: 0.502879]\n",
            "[Epoch 195/200] [Time: 34.86] [D loss: -0.000882] [G loss: 0.506752]\n",
            "[Epoch 196/200] [Batch   50/2910] [D loss: -0.002717] [G loss: 0.507290]\n",
            "[Epoch 196/200] [Batch  550/2910] [D loss: -0.006433] [G loss: 0.505781]\n",
            "[Epoch 196/200] [Batch 1050/2910] [D loss: -0.001973] [G loss: 0.504934]\n",
            "[Epoch 196/200] [Batch 1550/2910] [D loss: -0.008121] [G loss: 0.504663]\n",
            "[Epoch 196/200] [Batch 2050/2910] [D loss: -0.005456] [G loss: 0.506391]\n",
            "[Epoch 196/200] [Batch 2550/2910] [D loss: -0.005084] [G loss: 0.505527]\n",
            "[Epoch 196/200] [Time: 34.05] [D loss: -0.007065] [G loss: 0.504776]\n",
            "[Epoch 197/200] [Batch  140/2910] [D loss: -0.006459] [G loss: 0.504254]\n",
            "[Epoch 197/200] [Batch  640/2910] [D loss: -0.005152] [G loss: 0.502247]\n",
            "[Epoch 197/200] [Batch 1140/2910] [D loss: -0.009037] [G loss: 0.504488]\n",
            "[Epoch 197/200] [Batch 1640/2910] [D loss: -0.008960] [G loss: 0.503972]\n",
            "[Epoch 197/200] [Batch 2140/2910] [D loss: -0.007737] [G loss: 0.504404]\n",
            "[Epoch 197/200] [Batch 2640/2910] [D loss: -0.004332] [G loss: 0.505415]\n",
            "[Epoch 197/200] [Time: 33.96] [D loss: -0.003457] [G loss: 0.504620]\n",
            "[Epoch 198/200] [Batch  230/2910] [D loss: 0.000358] [G loss: 0.504323]\n",
            "[Epoch 198/200] [Batch  730/2910] [D loss: -0.008292] [G loss: 0.505131]\n",
            "[Epoch 198/200] [Batch 1230/2910] [D loss: -0.008494] [G loss: 0.502028]\n",
            "[Epoch 198/200] [Batch 1730/2910] [D loss: -0.004924] [G loss: 0.501996]\n",
            "[Epoch 198/200] [Batch 2230/2910] [D loss: -0.004303] [G loss: 0.504024]\n",
            "[Epoch 198/200] [Batch 2730/2910] [D loss: -0.008586] [G loss: 0.507184]\n",
            "[Epoch 198/200] [Time: 32.59] [D loss: -0.004760] [G loss: 0.501502]\n",
            "[Epoch 199/200] [Batch  320/2910] [D loss: -0.002591] [G loss: 0.503668]\n",
            "[Epoch 199/200] [Batch  820/2910] [D loss: -0.005221] [G loss: 0.505736]\n",
            "[Epoch 199/200] [Batch 1320/2910] [D loss: -0.005223] [G loss: 0.500196]\n",
            "[Epoch 199/200] [Batch 1820/2910] [D loss: -0.003050] [G loss: 0.506089]\n",
            "[Epoch 199/200] [Batch 2320/2910] [D loss: -0.009605] [G loss: 0.504888]\n",
            "[Epoch 199/200] [Batch 2820/2910] [D loss: -0.007196] [G loss: 0.503099]\n",
            "[Epoch 199/200] [Time: 34.26] [D loss: -0.004009] [G loss: 0.503611]\n",
            "[Epoch 200/200] [Batch  410/2910] [D loss: -0.008292] [G loss: 0.503319]\n",
            "[Epoch 200/200] [Batch  910/2910] [D loss: -0.004669] [G loss: 0.506555]\n",
            "[Epoch 200/200] [Batch 1410/2910] [D loss: -0.005039] [G loss: 0.506337]\n",
            "[Epoch 200/200] [Batch 1910/2910] [D loss: -0.004126] [G loss: 0.503072]\n",
            "[Epoch 200/200] [Batch 2410/2910] [D loss: -0.006134] [G loss: 0.502153]\n",
            "[Epoch 200/200] [Batch    0/2910] [D loss: -0.001125] [G loss: 0.503596]\n",
            "[Epoch 200/200] [Time: 31.45] [D loss: -0.001125] [G loss: 0.503596]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEcQ_acg1xqu",
        "outputId": "148059c4-6224-4579-cf46-ac7fd260dfda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "autoencoder.eval()\n",
        "generator.eval()\n",
        "discriminator.eval()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=2142, out_features=1071, bias=True)\n",
              "    (1): Conv1d(1, 16, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (3): Conv1d(16, 32, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (6): Conv1d(32, 64, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Conv1d(64, 128, kernel_size=(8,), stride=(4,), padding=(1,))\n",
              "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (12): Conv1d(128, 1, kernel_size=(3,), stride=(1,))\n",
              "    (13): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuCmebS-zPp5"
      },
      "source": [
        "num_fake_batches = 80\n",
        "fake_data = torch.zeros((0, feature_size), device='cpu')\n",
        "for _ in range(num_fake_batches):\n",
        "  z = torch.randn(opt.batch_size, 128, device=device)\n",
        "  generated_batch = generator(z)\n",
        "  fake_batch = torch.squeeze(autoencoder.decode(generator(z).unsqueeze(dim=2)))\n",
        "  fake_data = torch.cat((fake_data, fake_batch.round().to('cpu')), 0)\n",
        "np.save(os.path.join(opt.expPATH, \"synthetic.npy\"), fake_data.detach().cpu().numpy(), allow_pickle=False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZOiulo800Ev",
        "outputId": "b8db960e-479f-44f1-b3ab-0c9b2fe6c5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "# gen_samples = fake_data.detach().cpu().numpy()\n",
        "gen_samples = np.load(os.path.join(opt.expPATH, \"synthetic.npy\"), allow_pickle=False)\n",
        "\n",
        "# load real data\n",
        "real_samples = train_data[0:gen_samples.shape[0], :]\n",
        "\n",
        "# dimenstion wise probability\n",
        "prob_real = np.mean(real_samples, axis=0)\n",
        "prob_syn = np.mean(gen_samples, axis=0)\n",
        "\n",
        "figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
        "p1 = plt.scatter(prob_real, prob_syn, c=\"b\", alpha=0.7, label=\"DCAE.DC.DC.MA.WGAN-GC\", s=9)\n",
        "x_max = max(np.max(prob_real), np.max(prob_syn))\n",
        "x = np.linspace(0, x_max + 0.05, 1000)\n",
        "p2 = plt.plot(x, x, linestyle='-', color='k', label=\"Ideal\")  # solid\n",
        "plt.tick_params(labelsize=12)\n",
        "plt.legend(loc=2, prop={'size': 13})\n",
        "plt.title('Dimension Wise Probability')\n",
        "plt.xlabel('MIMIC III')\n",
        "plt.ylabel('Synthetic Data')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 960x960 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyMAAAMYCAYAAADYbjirAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAxOAAAMTgF/d4wjAACU/UlEQVR4nOzdd3xN9+PH8XeGEELMWrFK6Zdqq02HVo2bRWxCValValVrVJUaXarU6NcoqjY1gtqCTK0OaalVo0o1RlEkZtY9vz/uT75iREhuTm7yej4eedzm3HPPeecGPe/7OedznAzDMAQAAAAAWczZ7AAAAAAAcifKCAAAAABTUEYAAAAAmIIyAgAAAMAUlBEAAAAApqCMAAAAADAFZQQAAACAKSgjAGAHo0ePlr+/v9kx0uTh4aGIiAizY6Sybds2eXh4KDk52ewo6Va/fn29//77GdqGk5OTtm7detfnb/3zdOs+s+PvEgDSgzICAPehfv36cnNzU8GCBeXp6aly5cqpRYsWWr9+far1hg4dqs2bN5uUMn0uX76s+vXr22XbhmGoRIkSmjZtWqrldevWVf78+RUfH5+ybPfu3XJyctLhw4f10ksv6fLly3Jxccn0TMeOHZOTk5MKFCggDw8PlShRQoGBgdq3b1+m7yuz3evP082/y4iICDk5OSkpKSmL0gHAg6OMAMB9Gjx4sC5duqTY2Fj98ssv8vf3V7t27TRs2DCzo2UbTk5O8vHxSfVp/+XLlxUdHa0KFSro+++/T1m+ZcsWVaxYUY888kiWZPvtt990+fJlHTp0SO7u7mrSpMkd10tISMiSPACQm1FGACADHnroIfXu3VuTJk3SmDFj9Mcff0iSRo0apTp16qSsV79+fb355pt6+eWXVahQIXl5eWnJkiXas2ePateurYIFC+rZZ5/VwYMHU16TnJys8ePH6z//+Y88PT319NNPKzQ0NOX5uXPnysvLSzNmzFDFihXl6empNm3aKC4uTpJtdGLEiBHy8vJSwYIF5eXlpaFDh6a8/tZTg9avX6+nn35anp6eqlq1qj7//HNZrdZU60+ePFkvvviiPDw8VLNmTX333Xd3fW/8/f0VHh6ecspVRESEnnzySTVv3lxbtmxJWW/Lli3y8/NLWefmT/XDw8Pl7e0tT09PFStWTC+++KIuXLiQrvfnXooUKaIuXbro2LFj+vfff1Pez6lTp6pixYoqVqyYJOn3339Xo0aNVLx4cXl5eemNN95QbGxsqm1dvHhRrVq1UsGCBVWlShXNnz8/5blTp06pSZMmKlmypAoWLKjHH39cy5cvvy3P7t279cwzz8jDw0PPPvusoqOjU5679c/TrW78Lo8fP65GjRpJkgoXLiwPDw+NHj1aw4cPV4MGDVK95vTp03Jzc9OuXbvS/Z4BQKYzAADpVq9ePWPYsGG3Lb969arh7OxsTJ8+3TAMwxg5cqTx4osvpnqdp6enERkZaSQnJxuTJk0y8ufPbwQGBhpHjx414uPjjVatWhn+/v4prxk5cqTxxBNPGAcOHDCSk5ONlStXGvnz5zf++OMPwzAMY86cOYaLi4vx9ttvG1evXjVOnjxpVKlSxRgxYoRhGIaxefNmo2zZssZff/1lGIZh/Pvvv8b27dtTti/J2LJli2EYhvHzzz8befLkMZYuXWokJiYa0dHRRunSpY2JEyemWv/xxx83Dh8+bCQmJhpvvfWWUb58+bu+V3///bchyfjhhx8MwzCMfv36GcOHDze2bNliPP3004ZhGMb169cNd3d3Y9myZYZhGEZ4eLghyUhMTDQMwzDKlCljzJ4927BarUZ8fLyxfft24/Lly+l6f2519OhRQ5Jx+PBhwzAM49y5c0bLli2Nhx9+ONX72b17d+PSpUvGlStXjLi4OKNMmTLGgAEDjCtXrhgnT5406tatazRv3jzV7zZfvnzGmjVrjMTERGP9+vVGnjx5jO+++y7lfVixYoVx6dIlIyEhwZg1a5bh6upq7N27N9V7W7lyZWPfvn3G9evXjZEjRxrFixc3Ll68eNc/Tzf/Obz5d3nre2gYhnH8+HHD1dXVOHToUMqyjz/+2Hjuuefu+vsDgKzAyAgAZAJ3d3cVL15c//77713Xad26terWrStnZ2d17txZV69eVYcOHVSxYkW5ubmpffv2+vnnn1PWnzhxoj777DNVq1ZNzs7OatmypV544QV98803Keu4urpq7Nixcnd3V+nSpdWiRYuUbbi5uen69evat2+frl27pqJFi6p27dp3zDZr1iw1btxYbdu2laurq55++mm98847mj59eqr1Bg4cqCpVqsjV1VXdu3fX8ePH9c8//9xxm15eXvrPf/6TMgqyZcsW+fr6qk6dOvr999/177//6vvvv1d8fLx8fHzuuA03NzcdOXJEJ0+elJubm2rXrq0CBQqk+/25k6eeekpFihTRE088IavVqnXr1qV6ftKkSfLw8FD+/Pm1bt06JSQk6LPPPlP+/PlVunRpTZo0SatXr9bp06dTXhMYGKimTZvK1dVVgYGBatmypWbPnp3yPrRq1UoeHh7KkyePunXrpurVqyssLCzVft966y1Vr15defPm1YgRI+Tq6qo1a9ak+bOkV7ly5RQYGKiZM2dKkqxWq7766iv17NkzU7YPAA+KMgIAmeDatWs6e/Zsyqk9d1K6dOmU/75xQH3rskuXLkmS/vnnH8XFxalNmzYqXLhwytf27dt14sSJlNcUL15cefLkueM26tWrp7Fjx2rMmDEqWbKk6tatm+r0qJv9/fffqly5cqplVapU0fHjx1MtK1OmzG0/w4393Ymfn5+2bNmiEydO6O+//1bt2rWVL18+Pf/88woNDdWWLVv09NNPq2jRond8/Zo1a/Tnn3/q6aefVpUqVTRy5EglJSWl+/25k19//VUXLlxQTEyMvv32W/3nP/9Jee6hhx5S/vz5U70vFSpUkKura6r3RVKq96ZSpUqp9lGpUiX9/fffkqQLFy6oe/fuqlSpkgoVKqTChQtr3759OnPmzG2vucHZ2VkVKlRI2UZm6N27t+bOnauEhASFhIQoNjZWL7/8cqZtHwAehOu9VwEA3Ms333wjJycnWSyWTNle4cKFlS9fPq1bt05169Z94O107dpVXbt2VXx8vKZOnaqmTZvq7NmzKliwYKr1ypUrpyNHjqRaduTIEZUvX/6B9y3Zrhv58ssvtXLlSr300kspxcnX11dbtmzRzp07FRAQcNfX16xZU4sXL5Yk7dq1SwEBAfLy8tJrr72WKe/PrZydU39GV65cOR0/flxJSUkpheTG+3Tze3Ps2LFUrzt27Ji8vLwkSUOGDNGBAwcUGRmpcuXKycnJSU888YQMw7jtNTdYrVYdP348ZRsZ+Rlu8Pf3l6enp1auXKklS5botddek7u7+31vHwAyEyMjAJABZ8+e1YwZM/T222/rnXfeybQZofLmzauePXtq8ODB+v3332UYhq5du6aoqCgdOnQoXdv4+eefFRUVpWvXrqVMR+zk5HTHaXO7du2q9evXa8WKFUpOTtbOnTs1btw49ejRI0M/R/369eXk5KRPP/1Uvr6+Kct9fHy0du1a7dy58673Y0lISNCcOXN09uxZSZKnp6dcXFzk6uqaKe9PejRu3Fiurq4aOnSorl27ptOnT6t///5q2rSpSpUqlbLehg0btH79eiUnJ2vTpk1atWqVunTpIkmKjY1V/vz5VaxYMSUmJmry5Ml3nE74iy++0O+//66EhAR98sknSkhIULNmze47841cN0+GINkucu/Zs6c+/fRTrV+/Xm+88cZ9bxsAMhtlBADu09ixY+Xh4aFChQqpVq1a2rBhgxYuXKgxY8Zk6n4+//xzvfLKKymnIlWsWFGffvqpEhMT0/X6y5cva8CAAXrooYdUuHBhzZw5U6tWrUp1GtINzz33nIKDg/XJJ5+oSJEiatOmjfr166e33norQz9DgQIF9MILL+jUqVOpyoi3t7fi4+Pl7u5+1+tYJCk4OFg1atRQgQIFVK9ePXXu3FmdOnWSlPH3Jz0KFSqkLVu26LfffpOXl1fK6WLz5s1LtV7Xrl319ddfq3DhwurTp4+mT5+ul156SZL08ccf69q1aypZsqQqVqyof/75Ry+++OJt++rVq5c6duyookWLas2aNdqwYYMKFy5835mrVq2qN998Uw0aNFDhwoVT/bns0qWLDh48qNq1a6t69er3vW0AyGxOxq3jxAAAIEdKTk5W+fLlNXbsWL366qtmxwEARkYAAMgtZs6cKWdnZ7Vp08bsKAAgiQvYAQDI8WJjY+Xl5SVPT0/NmTNHbm5uZkcCAEmcpgUAAADAJJymBQAAAMAUlBEAAAAApshx14zkzZtXJUqUMDsGAAAAANnuyRUfH3/H53JcGSlRooRiYmLMjgEAAABAkpeX112f4zQtAAAAAKagjAAAAAAwBWUEAAAAgCkoIwAAAABMkeMuYE8vq9Uq7vcIOD4nJyc5O/O5CgAAjijXlZELFy7o7NmzSk5ONjsKgEzi4uKiEiVKqEiRImZHAQAA9yFXlZELFy7ozJkzKlu2rPLlyycnJyezIwHIIMMwdP36dZ04cUKSKCQAADiQXFVGzp49q7Jly8rDw8PsKAAykYeHh8qWLauTJ09SRgAAcCC55kRrq9Wq5ORk5cuXz+woAOwgX758Sk5OltVqNTsKAABIp1xTRm5crM6pWUDOdOPvNhNTAADgOHJNGQEAAACQvVBGAAAAAJiCMpJDzJ071y6noNlruwAAAABlxEF07txZ9evXNzsGAAAAkGkoIwAAAABMQRlxQFarVcOHD9dDDz0kDw8Pvfzyy7pw4cJt6/3yyy8KCAhQwYIFVaJECbVs2VJHjx5Nef7o0aMKCgpS2bJl5e7urv/85z/673//y2xEAAAAyBK56qaHd9KsWTMdOXIkS/dZuXJlrVmz5oFfP3nyZI0fP15TpkxRnTp19O233+qDDz5Itc7+/ftVr149DRw4UF988YWSkpL0wQcfyNfXV3v37pW7u7suX76s+vXr6/3331ehQoUUGRmpPn36yNPTU506dcrojwkAAACkKdeXEUc0btw4vfnmm+rataskafDgwfr555+1YsWKlHXGjh2rwMDAVCVl4cKFKlKkiNavX6+goCDVrFlTNWvWTHn+4Ycf1o4dO7Ro0SLKCAAAAOwu15eRjIxQmCEuLk4nTpzQCy+8kGp5nTp1UpWRHTt26PDhw/Lw8Ei13vXr13X48GFJ0rVr1/Txxx9rzZo1OnnypOLj45WQkKCKFSva/ecAAAAAcn0ZyamsVqvat2+v999//7bnihYtKkl65513tGLFCo0fP17Vq1eXh4eHxo0bp5CQkKyOCwAAgFyIMuJgChUqpLJly2r79u1q3rx5yvLvv/8+1Xre3t7avXu3Hn74YTk733megsjISLVv317t27dPWXbo0CH7BAcAAABuwWxaDmjgwIGaMmWK5s2bp8OHD2v8+PHaunVrqnWGDh2qw4cP69VXX9XPP/+so0ePKjw8XG+//XbKaVqPPvqo1q5dqx9//FEHDhzQO++8o19//dWMHwkAAAC5EGXEAb311lt66623NHDgQD355JP64YcfNGLEiFTr/Oc//9H27dt19epVBQQE6D//+Y+6d++uK1euqEiRIpKkSZMmqUqVKvL19dVLL72khIQE9enTx4wfCQAAALmQk5HDbirh5eWlmJiY25YnJyfr0KFDqlq1qlxcXExIBsCe+DsOAED2dLfjc4mREQAAAAAmoYwAAAAAMAVlBAAAAIApKCMAAAAATEEZAQAAAGAKyggAAACQw1y4cEGOMGkuZQQAAADIQf766y95e3tr6NChZke5J8oIAAAAkEMcOXJEdevW1dGjR1WlShWz49yTq9kBAAAAAGTcwYMH5ePjo1OnTmnevHnq2LGj2ZHuiTICAAAAOLj9+/fLx8dHZ8+e1aJFi9SuXTuzI6ULp2k5iM6dO8vJyUlOTk5ydXVV0aJFVbt2bX3wwQc6f/58qnWTk5M1depUPffccypUqJAKFiyoJ554QiNGjNCZM2du27a3t7dcXFz0008/3fbcqFGjUvZ769exY8fumrdixYop6+XNm1elS5eWv7+/Zs2apaSkpNvWP3/+vIYMGaL//Oc/cnd3V4kSJfTiiy/qq6++Unx8/F33c3OefPnyqVy5cmrWrJmWL19+x/VjYmLUp08fVa5cWfny5VPp0qXl4+OjpUuXymq13vE1x44dS9nH7t27b3v+qaeekpOTk0aNGnXbc3v37pWLi4uqV69+15/hhrCwMDk5OWnPnj2plr/66qtycnLSDz/8kGr5G2+8oapVq6Za9ssvv+iVV16Rl5eX8ubNqzJlyqhu3br68ssvdfny5fvOd+P3GBwcnGp5RETEPf8M3PqzNW/eXCVLllTevHlVvnx5+fv7a+HChUpISEi17oP8jgAAyM12796t+vXr69y5c1q6dKnDFBGJMuJQateurVOnTun48ePatm2bunfvrm+++UY1atTQoUOHJElJSUlq2rSp3nvvPbVu3Vpbt27Vnj17NHbsWB04cEBffvllqm1GR0fr6NGj6tWrl2bMmHHH/Xp5eenUqVO3fZUrVy7NvAMHDtSpU6d05MgRrV27VhaLRYMGDVKDBg109erVlPVOnDihp59+WsuXL9ewYcMUHR2tH374QX369NHMmTNvOwi/1aRJk3Tq1CkdPnxYy5Yt02OPPaaOHTuqbdu2qQ5e9+zZoyeffFLbt2/XuHHj9Ntvvyk8PFzt2rXTiBEjdPz48TT3U758ec2cOTPVsh07dujQoUMqVqzYHV8zffp0vf766zp//ryioqLS3P4LL7ygfPnyaevWramWh4WFqXz58rctDw0Nla+vb8r3ixYt0vPPP6/r16/r66+/1v79+xUZGam33npLa9eu1Zo1ax4on7u7u959993bSkN6ffbZZ/Lz89NDDz2kxYsX68CBA9q8ebM6duyoGTNmaMeOHSnrZvR3BABAbvPrr7+qQYMGio2N1cqVK9W6dWuzI90fI4cpW7bsHZcnJSUZ+/fvN5KSkrI4Uebo1KmTUa9evduWx8bGGg8//LDRoEEDwzAMY8KECYaTk5Oxffv2O27n/Pnzqb5//fXXjd69ext79uwx8ufPb1y8eDHV8yNHjjQqVKhw33krVKhgjBw58rblO3fuNFxdXY0PPvggZVmzZs2MkiVL3rZvw7D93mJjY++6H0nGnDlzblu+du1aQ5Ixb948wzAMw2q1Gk8++aTx2GOPGYmJibetf/XqVePatWt33MfRo0cNScYHH3xgFC5c2Lh69WrKc927dze6du16x5/3ypUrhqenp/Hzzz8bAwcONNq3b3/Xn+MGX19fIzAwMOX7vXv3Gvny5TOmTJli1K1bN2X5sWPHDEnGihUrDMMwjJMnTxru7u5Gz54977ptq9V63/kqVKhg9OnTx/D09DTGjRuXsjw8PNyQZBw9ejTNn+fXX381nJycjDFjxtwzV0Z+R4bh+H/HAQC4Xz/99JNRuHBhI1++fMbGjRvNjnNXdzs+NwzDYGTkAVit0rJl0uDBtkczzxwpVKiQevXqpYiICJ09e1bz58+XxWJR7dq177h+kSJFUv47Li5O33zzjTp37qzHHntM1atX14IFC+ya98knn1RAQICWLVsmyTYH9rp169S3b195enretr6Li4sKFSp03/tp0qSJatSokbKf3bt3a9euXXr33Xfl6nr7pVLu7u7Kly9fmtusW7euSpYsmbLNy5cv65tvvlH37t3vuP4333wjLy8vPfPMM+rSpYtWrFihf//9N819+Pj4KCoqSomJiZJsox8vvPCCAgMD9eOPP6aMKIWGhsrZ2VkWi0WStGzZMl27dk3vv//+Xbft5OT0QPmKFy+uYcOG6ZNPPtG5c+fSzH+r+fPny93dXQMGDLhnrsz4HQEAkFt8//338vX1VXx8vNatW6eGDRuaHemBUEYeQHCw9MknUni47fGW0+mz3GOPPSbDMHT06FEdPHgwXdcnSNLChQtVsWJFPfPMM5Js16Xc6VSt48ePy8PDI9VX5cqVM5T3zz//lCQdPnxYVqs13ZkfdD8HDx6UpAzvp3v37vrqq68k2Q7mK1WqpOeff/6O686YMUOdOnWSJNWoUUM1a9bUnDlz0ty+r6+vLl++nHL9TlhYmHx8fFSpUiWVLl065VSqsLAwPf300ypcuHDKz1eoUCGVLVs2ZVsnT55M9Tvr2bPnA+fr16+fihYtesfrYtJy8OBBVa5cWXny5ElZ9sMPP6TKNXr06JR1pYz/jgAAyOkiIyMVEBAgq9WqjRs3ysfHx+xID4wy8gCioyU3N6lUKdtjdLS5eYz/v7vmrZ9838vNB6OS1L59ex0+fFjff/99qvXKlCmjXbt2pfoKDQ3NUN77zZpd9tOpUydFR0dr//79mjlz5l1HRX799Vf9+uuvqabU69Kli2bOnJnm3VCfeuopFSlSRFu3blVycrIiIiJSRj8sFkvKdSNhYWGprheRdNt2S5YsmfL7qlGjhq5fv/7A+fLmzasxY8ZoxowZOnDgwG3PN2rUKFXBSOvajlq1aqXkKly48ANfiwIAQG60detWNWrUSC4uLtq8ebPq1atndqQMoYw8AG9vKSFBOn3a9ujtbW6evXv3ysnJSQ8//LCqVaum/fv33/M127dv1+7duzVkyBC5urrK1dVVJUqUUHx8/G2jI66urqpSpUqqr4oVK2Yo742RlUceeUTOzs7pypyR/VSrVk2SMryf4sWLq0WLFurXr5/27dt31/m7p0+fruTkZHl5eaW8v/369dPhw4cVHh5+1+07OzurQYMGCg0N1S+//CLDMFJGrm4s379/v06dOpWqjFSrVk2XLl1STExMyjIXF5eU35e7u3uG87Vp00bPPfecBg0adNtzs2bNSlVWy5Qpk5Lrjz/+SFU48uXLl5Lr5tOxMut3BABATrVx40Y1adJEefPm1datW/XCCy+YHSnDKCMPIChIGjZMatDA9hgUZF6WuLg4ffnll/Lx8VGxYsXUsWNHhYWF3XUGqgsXLkiyjYpYLBb99ttvqQ4iv/rqKy1fvjxlvcy2a9cuhYSE6OWXX5Zku4alcePGmjJlimJjY29bPzk5WXFxcfe9n7Vr12r//v0p+3n88cf1+OOP67PPPrvj1MLXr19PNXKQlu7duys0NFRBQUEpp0nd7NKlS/rmm2/0xRdf3Dai1KRJk7vOWnaDr6+vfvrpJ61evVr16tWTi4uLJFsZ+e2337R06VK5u7vrxRdfTHlNUFCQ8ubNqw8++OCe+TOSb8KECdqwYcNtI2Nly5ZNVVZvlIxXX31V165d07hx4+6ZKzN/RwAA5DRr1qxRixYt5OHhobCwsJQPKx1eFlxAn6Vy8mxatWvXNk6dOmWcPHnS2Ldvn/H1118b1apVM8qUKWMcPnzYMAzDSEhIMPz9/Y2CBQsaY8eONX7++Wfj2LFjxpYtW4x27doZo0aNMs6fP2/ky5fPmD179m37SUhIMIoUKWJMnDjRMAzbbFpeXl7GqVOnbvuKj483DMMwVq5caVSrVs2IiYlJ2U6FChWMgQMHGqdOnTL+/vtvY8eOHcann35qFC5c2KhXr16qGan+/vtvo3z58sbDDz9sLFiwwNi7d6/xxx9/GEuWLDGeeeYZIzw83DAMw5g8ebJRrVq1VHklGZMmTTJOnTplHD9+3Ni+fbvx3nvvGfny5TPatWtnJCcnp6y7a9cuo0iRIkatWrWMFStWGAcPHjQOHjxozJ4926hWrVrKzFBDhgwxLBZLyutuzKZ1I4dhGMbZs2dTzex082xa06ZNM/Lnz29cvnz5tvd3+fLlRp48eYx//vnHMAzDqFatmjF58uRU6xw8eNCQZBQsWNCYNGlSquceeeQRo2DBgoafn99t2549e7bh4uJiNGvWzNi4caNx+PBhY9++fcbs2bONkiVLGl27dr3vfHeaJax9+/aGu7t7umbTMgzD+OCDDwwnJyeja9euRmhoqPHnn38au3fvNv773/8a+fPnNz788MOUddP7O7oTR/87DgDA3QQHBxuurq5GiRIljN27d5sd576lNZsWZcRBdOrUyZBkSDJcXFyMwoULG88995zxwQcf3DZdb2JiovHf//7XeOaZZ4wCBQoYBQoUMGrWrGmMHDnSOHv2rDFx4kQjT548xoULF+64r27duhmPPvqoYRi2MnJjv7d+3Tg4nzNnzm0HphUqVEhZL0+ePEbJkiUNPz8/46uvvrrj7+DcuXPGO++8Y1StWtXImzevUaxYMePFF180Zs2alVJ6bmS52c153NzcjLJlyxpNmzY1li1bdsef7a+//jJ69uxpVKxY0XBzczNKlixp+Pj4GMuXL08pLp06dUo1nfGdysitbj5of+KJJ4ygoKA7rnf16lWjYMGCxqeffpqS/05TIJcrV86QdNs/OD169DAkGZ999tkdt//jjz8abdq0MUqXLm24uroahQoVMmrXrm2MHTvWuHTp0n3nu1MZOX78+H2VEcMwjE2bNhmNGzc2ihcvbri6uhpFihQx6tevb0yfPj3l93tDen5Hd+Lof8cBALiTxYsXGy4uLkapUqWMffv2mR3ngaRVRpwMI42raR2Ql5dXqvPmb0hOTtahQ4dUtWrVlNNeAOQc/B0HAOQ08+bNU9euXVW6dGmFhYWpatWqZkd6IHc7Ppe4ZgQAAADIdmbNmqUuXbqoXLlyioqKctgici+UEQAAACAbmTp1qrp3765KlSopMjJSDz/8sNmR7IYyAgAAAGQTEydOVN++fVW1alVFRkaqQoUKZkeyK8oIAAAAkA189tlnGjBggKpXr66IiAh5eXmZHcnuck0ZuXEn7hx2vT6A/3fj7/aNv+sAADiSjz76SEOGDFHNmjUVHh6u0qVLmx0pS+SaMuLs7CwXFxdumgbkUNevX5eLi4ucnXPNP2sAgBzAMAy9//77GjFihJ566imFh4froYceMjtWlnE1O0BWKlGihE6cOKGyZcsqX758fIIK5ACGYej69es6ceJErvrHGwDg+AzD0Lvvvqtx48bp2WefVUhIiAoXLmx2rCyVq8pIkSJFJEknT55UcnKyyWkAZBYXFxc99NBDKX/HAQDI7gzDUP/+/fXFF1/ohRde0MaNG1WoUCGzY2W5XFVGJFshKVKkiKxWK9ePADmAk5MTp2YBAByK1WpVnz59NH36dNWrV0/r1q2Th4eH2bFMkevKyA0cvAAAACCrJScnq0ePHpo9e7Z8fX21evVq5c+f3+xYpsm1ZQQAAADISklJSerSpYsWLlyoRo0aaeXKlcqXL5/ZsUzF8AAAAABgZ4mJierQoYMWLlyoZs2aadWqVbm+iEiMjAAAAAB2lZCQoHbt2mnVqlVq3bq1Fi9eLDc3N7NjZQuMjAAAAAB2cv36dbVu3VqrVq3SK6+8oiVLllBEbkIZAQAAAOzg2rVrat68udatW6dOnTppwYIFcnXlxKSbUUYAAACATHblyhU1adJEmzdv1uuvv67Zs2fLxcXF7FjZDmUEAAAAyESXLl1So0aNFBYWpt69e2vGjBncVuIueFcAAACATBIbG6uAgABt27ZN/fv315QpUygiaeCdAQAAADLB+fPn5evrqx9++EFDhgzR+PHj5eTkZHasbI0yAgAAAGTQuXPn5OPjo+joaI0YMUKjR4+miKQDl/MDAAAAGfDPP//I19dXe/fu1ccff6xhw4aZHclhUEYAAACAB3Ty5En5+PjowIEDGjdunAYNGmR2JIdCGQEAAAAewN9//y2LxaI//vhDX3zxhfr162d2JIdDGQEAAADu07Fjx2SxWHT06FFNnz5db7zxhtmRHBJlBAAAALgPR44cUYMGDRQTE6Ovv/5aXbt2NTuSw6KMAAAAAOl08OBBWSwWnT59WvPnz1eHDh3MjuTQKCMAAABAOuzbt08+Pj46d+6cFi9erJdfftnsSA6PMgIAAADcw2+//SZfX1/FxsZq+fLlatmypdmRcgTKCAAAAJCGX375RX5+frpy5YpWrlypJk2amB0px6CMAAAAAHfx008/KSAgQPHx8VqzZo0CAgLMjpSjUEYAAACAO/juu+8UGBio5ORkrV+/XhaLxexIOQ5lBAAAALhFRESEmjRpIicnJ23atEkvvfSS2ZFyJOes2IlhGBo5cqTKlCmjAgUKqG7dutq7d+89XxcXF6eKFSvKyclJSUlJWZAUAAAAud2WLVsUGBgoFxcXbd68mSJiR1lSRj7//HPNnj1bISEhOnfunF588UUFBATo8uXLab7u7bffVrVq1bIiIgAAAKANGzaoadOmyps3r0JDQ1W7dm2zI+VoWVJGpk2bpkGDBqlmzZpyd3fXRx99pISEBK1atequr1m7dq327Nmjd955JysiAgAAIJdbvXq1WrRoIQ8PD4WHh8vb29vsSDme3ctIbGysjh07pmeffTZlmaurq2rVqqWdO3fe8TX//vuv+vbtqzlz5sjVNe3LWiZMmCAvL6+Ur3uNtgAAAAC3Wr58uYKCglSkSBFFREToySefNDtSrmD3MhIXFydJKly4cKrlRYoUSXnuVr169VL37t312GOP3XP7AwYMUExMTMqXh4dHhjMDAAAg91i8eLHatWunEiVKKDIyMl3HoMgcdp9Nq1ChQpKkixcvplp+4cIFlS1b9rb1lyxZoiNHjmjx4sX2jgYAAIBcbu7cueratavKli2rsLAwPfLII2ZHylXsPjLi6empihUraseOHSnLkpKStGvXLtWqVeu29Tdt2qQDBw6oVKlSKl68uJo3by5JKlWqlObNm2fvuAAAAMglZs6cqS5duqh8+fKKioqiiJjAyTAMw947GTdunCZPnqwNGzaocuXK+vjjjzV37lwdPHjwttOqLly4oCtXrqR8/8MPP6ht27Y6duyYihcvrgIFCqS5Ly8vL8XExNjl5wAAAEDOMHXqVPXt21eVK1dWWFiYypcvb3akHCut4/MsuenhoEGDdOnSJfn6+iouLk7e3t7atGmTPDw8dPz4cVWvXl0bN27USy+9pCJFiqhIkSIpry1RooQkqWzZsve8mB0AAAC4lwkTJmjgwIGqVq2aQkND73jpALJGloyMZCVGRgAAAHA3n376qYYOHarq1asrNDRUpUqVMjtSjpfW8XmW3GcEAAAAMJNhGPrggw80dOhQPf7444qIiKCIZAOc9wQAAIAczTAMvf/++xo9erSeeuopbd68WcWKFTM7FkQZAQAAQA5mGIbeeecdjR8/Xs8995w2bdp02/3vYB7KCAAAAHIkwzD01ltvafLkyapTp47Wr1+fcg88ZA+UEQAAAOQ4VqtVvXr10syZM9WgQQOtWbPmtltKwHyUEQAAAOQoycnJev311zV37lz5+fnp22+/Vf78+c2OhTugjAAAACDHSEpKUufOnbVo0SIFBgZqxYoVypcvn9mxcBeUEQAAAOQIiYmJevXVV7V8+XI1b95cS5cuVd68ec2OhTRwnxEAAAA4vPj4eLVt21bLly9XmzZttHz5coqIA2BkBAAAAA7t+vXrat26tTZs2KD27dtr3rx5cnXlMNcRMDICAAAAh3X16lU1a9ZMGzZsUOfOnTV//nyKiAOhjAAAAMAhXblyRU2aNNGWLVvUo0cPff3113JxcTE7Fu4DZQQAAAAOJy4uTg0bNlR4eLj69u2r6dOny9mZQ1tHw28MAAAADuXixYvy9/fXd999p4EDB+q///2vnJyczI6FB0AZAQAAgMM4f/68fH199dNPP+m9997TuHHjKCIOjDICAAAAh3D27FlZLBb98ssvGjVqlD755BOKiINjqgEAAABke6dPn5avr6/27dun0aNH67333jM7EjIBZQQAAADZ2okTJ+Tj46ODBw9q/PjxGjBggNmRkEkoIwAAABlgtUrBwVJ0tOTtLQUFSUzqlHmOHz8ui8WiI0eOaPLkyerbt6/ZkZCJKCMAAAAZEBwsffKJ5OYmhYTYlrVta26mnOLo0aOyWCw6duyYZsyYoR49epgdCZmM3g4AAJAB0dG2IlKqlO0xOtrsRDnDH3/8oXr16umvv/7S7NmzKSI5FGUEAAAgA7y9pYQE6fRp26O3t9mJHN+BAwdUt25dnThxQgsWLFCXLl3MjgQ74TQtAACADAgKsj3efM0IHtzevXvl4+Oj8+fPa8mSJWrTpo3ZkWBHToZhGGaHyExeXl6KiYkxOwYAAADu065du+Tr66u4uDgtW7ZMLVq0MDsSMkFax+eMjAAAAMB00dHR8vf319WrV7Vq1So1btzY7EjIApQRAAAAmOrHH39UQECAEhIStGbNGvn7+5sdCVmEMgIAAADTbNu2TYGBgbJardqwYYMaNGhgdiRkIWbTAgAAgCnCwsLUsGFDOTk5KSQkhCKSC1FGAAAAkOU2b96sxo0bK0+ePNq8ebPq1KljdiSYgDICAACALLV+/Xo1bdpU7u7uCg0N1fPPP292JJiEMgIAAIAss2rVKrVs2VKFChVSeHi4nn76abMjwUSUEQAAAGSJZcuWqU2bNipatKgiIiL0xBNPmB0JJqOMAAAAwO4WLlyoV155RSVLllRkZKRq1KhhdiRkA5QRAAAA2NWcOXP02muvqWzZsoqMjFS1atXMjoRsgjICAAAAu5kxY4a6du2qChUqKCoqSlWqVDE7ErIRyggAAADsYvLkyerZs6eqVKmiqKgoVaxY0exIyGYoIwAAAMh0n3/+ufr166dHH31UkZGRKleunNmRkA1RRgAAAJCpRo8erXfeeUc1atRQRESEypQpY3YkZFOUEQAAAGQKwzA0atQoDRs2TE888YTCw8NVsmRJs2MhG3M1OwAAAAAcn2EYGjp0qMaMGSNvb2+FhISoaNGiZsdCNkcZAQAAQIYYhqGBAwdq4sSJev7557Vp0yZ5enqaHQsOgDICAACAB2a1WtWvXz9NnTpVderU0YYNG1SwYEGzY8FBUEYAAADwQKxWq3r27KmvvvpKDRo00Nq1a1WgQAGzY8GBUEYAAABw35KTk9WtWzfNmzdP/v7+WrVqlfLnz292LDgYyggAAADuS1JSkjp16qTFixercePGCg4OVr58+cyOBQdEGQEAAEC6JSYmqn379goODlbLli21ZMkSubm5mR0LDor7jAAAACBd4uPj1aZNGwUHB6tt27ZaunQpRQQZQhkBAADAPV2/fl2tWrXS6tWr1aFDBy1atEh58uQxOxYcHGUEAAAAabp69aqaNm2qDRs2qEuXLpo7d65cXTnbHxlHGQEAAMBdXb58WY0bN9bWrVvVs2dPzZo1Sy4uLmbHQg5BGQEAAMAdxcXFqWHDhoqIiFC/fv00bdo0OTtz+IjMw58mAAAA3ObixYvy8/PT999/r0GDBmnSpElycnIyOxZyGMoIAAAAUvn333/l4+Ojn3/+WcOGDdPYsWMpIrALrjwCAABAijNnzsjPz0+7d+/Whx9+qOHDh5sdCTkYZQQAAACSpFOnTsnX11f79+/XmDFj9O6775odCTkcZQQAAAA6ceKELBaLDh06pAkTJqh///5mR0IuQBkBAADI5Y4fPy6LxaIjR45oypQp6tOnj9mRkEtQRgAAAHKxP//8UxaLRcePH9fMmTPVvXt3syMhF6GMAAAA5FKHDx+WxWLRyZMnNWfOHHXq1MnsSMhlKCMAAAC50O+//y6LxaKzZ89q4cKFeuWVV8yOhFyIMgIAAJDL7NmzRz4+Prpw4YKWLFmioKAgsyMhl6KMAAAA5CI7d+6Un5+f4uLiFBwcrObNm5sdCbkYZQQAACCX2LFjh/z9/XXt2jWtXr1ajRo1MjsScjnKCAAAQC6wfft2NWrUSImJiVq3bp18fX3NjgRQRgAAAHK6qKgoBQYGSpI2btyoevXqmZwIsHE2OwAAAADsJzQ0VA0bNpSzs7NCQkIoIshWKCMAAAA5VEhIiJo0aSI3Nzdt2bJFL774otmRgFQoIwAAADnQ2rVr1axZM+XPn19hYWF67rnnzI4E3IYyAgAAkMOsXLlSrVq1kqenp8LDw/XUU0+ZHQm4I8oIAABADrJ06VK1bdtWxYoVU0REhB5//HGzIwF3RRkBAADIIRYsWKD27durZMmSioyMVPXq1c2OBKSJMgIAAJADzJ49W506dZKXl5eioqJUrVo1syMB90QZAQAAcHBffvmlunXrpooVKyoqKkqVK1c2OxKQLpQRAAAAB/bFF1+od+/eeuSRRxQVFaUKFSqYHQlIN8oIAACAgxo3bpzefvttPfroo4qMjJSXl5fZkYD7QhkBAABwQB9//LEGDx6sxx57TBERESpdurTZkYD7RhkBAABwIIZhaMSIERo+fLiefPJJhYeHq2TJkmbHAh6Iq9kBAAAAkD6GYWjIkCEaO3asnnnmGYWEhKhIkSJmxwIeGGUEAADAARiGoQEDBmjSpEmqXbu2Nm7cKE9PT7NjARlCGQEAAMjmrFar3nzzTU2bNk1169bVunXrVLBgQbNjARlGGQEAAMjGrFar3njjDc2aNUsWi0Vr1qxRgQIFzI4FZArKCAAAQDaVnJysrl27av78+WrYsKFWrlwpd3d3s2MBmYYyAgAAkA0lJibqtdde05IlS9S0aVMtX75cefPmNTsWkKmY2hcAACCbSUhI0CuvvKIlS5aoVatWCg4OpoggR6KMAAAAZCPx8fEKCgrSihUr1K5dOy1ZskRubm5mxwLsgjICAACQTVy7dk0tWrTQ2rVr1bFjRy1cuFB58uQxOxZgN5QRAACAbODKlStq2rSpNm3apG7dumnOnDlycXExOxZgV5QRAAAAk126dEmBgYEKDQ1Vr169NHPmTIoIcgXKCAAAgIliY2PVsGFDRUVF6a233tLUqVPl7MwhGnIH/qQDAACY5MKFC/Lz89P27ds1ePBgTZw4UU5OTmbHArIMZQQAAMAE586dk4+Pj3bs2KHhw4drzJgxFBHkOtz0EAAAIIudOXNGvr6+2rNnjz766CO9//77ZkcCTEEZAQAAyEKnTp2Sj4+Pfv/9d3322WcaPHiw2ZEA01BGAAAAskhMTIwsFosOHz6siRMn6u233zY7EmAqyggAAEAW+Ouvv2SxWPTnn39q2rRp6tWrl9mRANNRRgAAAOzsyJEjslgs+vvvvzVr1ix169bN7EhAtkAZAQAAsKODBw/Kx8dHp06d0rx589SxY0ezIwHZBmUEAADATvbv3y8fHx+dPXtWixYtUrt27cyOBGQrlBEAAAA72L17t3x9fXXhwgUtXbpUrVu3NjsSkO1QRgAAADLZr7/+Kj8/P12+fFkrV65U06ZNzY4EZEuUEQAAgEz0888/KyAgQNevX9fq1avVsGFDsyMB2RZlBAAAIJN8//33atSokZKSkrRu3Tr5+PiYHQnI1igjAAAAmSAyMlKNGzeWJG3cuFH16tUzORGQ/TmbHQAAAMDRbd26VY0aNZKLi4s2b95MEQHSiTICAACQARs3blSTJk2UN29ebd26VS+88ILZkQCHQRkBAAB4QGvWrFGLFi1UoEABhYWF6ZlnnjE7EuBQKCMAAAAPYMWKFWrdurU8PT0VERGhWrVqmR0JcDiUEQAAgPv0zTff6OWXX1bx4sUVERGhmjVrmh0JcEiUEQAAgPswb948dejQQaVKlVJkZKSqV69udiTAYVFGAAAA0mnWrFnq0qWLypUrp6ioKFWtWtXsSIBDo4wAAACkw7Rp09S9e3dVqlRJkZGRevjhh82OBDg8yggAAMA9TJo0SX369FHVqlUVGRmpChUqmB0JyBEoIwAAAGn47LPP1L9/f1WvXl0RERHy8vIyOxKQY1BGAAAA7uKjjz7SkCFDVLNmTYWHh6t06dJmRwJyFFezAwAAAGQ3hmFo+PDh+uSTT1SrVi1t2bJFxYoVMzsWkONQRgAAAG5iGIbeffddjRs3Ts8++6w2bdqkIkWKmB0LyJEoIwAAAP/PMAz1799fX3zxhV544QVt3LhRhQoVMjsWkGNRRgAAACRZrVb16dNH06dPV7169bRu3Tp5eHiYHQvI0SgjAAAg10tOTlaPHj00e/Zs+fr6avXq1cqfP7/ZsYAcjzICAABytaSkJHXp0kULFy5Uo0aNtHLlSuXLl8/sWECuwNS+AAAg10pMTFSHDh20cOFCNWvWTKtWraKIAFmIkREAAJArJSQkqF27dlq1apVat26txYsXy83NzexYQK7CyAgAAMh1rl+/rtatW2vVqlV65ZVXtGTJEooIYALKCAAAyFWuXbum5s2ba926derUqZMWLFggV1dOFgHMQBkBAAC5xpUrV9SkSRNt3rxZr7/+umbPni0XFxezYwG5FmUEAADkCpcuXVKjRo0UFham3r17a8aMGXJ25lAIMBN/AwEAQI4XGxurgIAAbdu2Tf3799eUKVMoIkA2wN9CAACQo50/f16+vr764YcfNGTIEI0fP15OTk5mxwIgyggAAMjBzp07Jx8fH0VHR2vEiBEaPXo0RQTIRpg6AgAA5Ej//POPfH19tXfvXn388ccaNmyY2ZEA3IIyAgAAcpyTJ0/Kx8dHBw4c0Lhx4zRo0CCzIwG4A8oIAADIUf7++29ZLBb98ccf+uKLL9SvXz+zIwG4C8oIAADIMY4dOyaLxaKjR49q+vTpeuONN8yOBCANlBEAAJAjHDlyRA0aNFBMTIy+/vprde3a1exIAO6BMgIAABzewYMHZbFYdPr0ac2fP18dOnQwOxKAdKCMAAAAh7Zv3z75+Pjo3LlzWrx4sV5++WWzIwFIJ8oIAABwWL/99pt8fX0VGxur5cuXq2XLlmZHAnAfKCMAAMAh/fLLL/Lz89OVK1e0cuVKNWnSxOxIAO4TZQQAADicn376SQEBAYqPj9eaNWsUEBBgdiQAD4AyAgAAHMp3332nwMBAJScna/369bJYLGZHAvCAKCMAAMBhREREqEmTJnJyctKmTZv00ksvmR0JQAY4mx0AAAAgPbZs2aLAwEC5uLho8+bNFBEgB7B7GTEMQyNHjlSZMmVUoEAB1a1bV3v37r3r+s2aNVPZsmVVqFAhlS5dWl26dNG///5r75gAACAb27Bhg5o2baq8efMqNDRUtWvXNjsSgExg9zLy+eefa/bs2QoJCdG5c+f04osvKiAgQJcvX77j+h999JH++OMPxcXFaf/+/bp27Zp69Ohh75gAACCbWr16tVq0aCEPDw+Fh4fL29vb7EgAMondy8i0adM0aNAg1axZU+7u7vroo4+UkJCgVatW3XH9J554Qu7u7v8L6OysgwcP2jsmAADIhpYvX66goCAVKVJEERERevLJJ82OBCAT2bWMxMbG6tixY3r22WdTlrm6uqpWrVrauXPnXV/33nvvqWDBgipatKi+/fZbjRw50p4xAQBANrR48WK1a9dOJUqUUGRkpB577DGzIwHIZHYtI3FxcZKkwoULp1pepEiRlOfu5NNPP9WlS5d0+PBhDRgwQFWrVr3ruhMmTJCXl1fK191O/wIAAI5j7ty56tChg8qUKaPIyEg9+uijZkcCYAd2LSOFChWSJF28eDHV8gsXLqQ8l5YqVaqoWbNmCggIUGJi4h3XGTBggGJiYlK+PDw8MpwbAACYZ+bMmerSpYvKly+vqKgoPfLII2ZHAmAndi0jnp6eqlixonbs2JGyLCkpSbt27VKtWrXStY3ExET9888/io2NtVdMAACQTUydOlVvvPGGKleurKioKFWqVMnsSADsyO4XsPfu3Vuff/659u7dq2vXrmnkyJHKkyePWrZsedu6hw4d0sqVKxUXFyfDMHTw4EG98847euaZZ1S8eHF7RwUAACaaMGGC+vbtq2rVqikyMlLly5c3OxIAO7N7GRk0aJA6d+4sX19fFStWTNu2bdOmTZvk4eGh48ePy8PDQ9u2bZNkuyfJhAkTVL58eRUsWFABAQGqWbOm1qxZY++YAADARJ9++qkGDhyo6tWrKyIiQmXLljU7EoAs4GQYhmF2iMzk5eWlmJgYs2MAAIB0MAxDH374oUaNGqXHH39cW7duVYkSJcyOBSATpXV87prFWQAAACTZisj777+v0aNH66mnntLmzZtVrFgxs2MByEKUEQAAkOUMw9A777yj8ePH67nnntOmTZtuuxUAgJyPMgIAALKUYRh66623NHnyZNWpU0fr169P15T/AHIeyggAAMgyVqtVvXr10syZM9WgQQOtWbOGe4QBuRhlBAAAZInk5GS9/vrrmjt3rvz8/PTtt98qf/78ZscCYCLKCAAAsLukpCR17txZixYtUmBgoFasWKF8+fKZHQuAySgjAADArhITE/Xqq69q+fLlat68uZYuXaq8efOaHQtANmD3mx4CAIDcKz4+Xm3bttXy5cvVpk0bLV++nCICIAUjIwAAwC6uX7+u1q1ba8OGDWrfvr3mzZsnV1cOPQD8DyMjAAAg0129elXNmjXThg0b1LlzZ82fP58iAuA2lBEAAJCprly5oiZNmmjLli3q0aOHvv76a7m4uJgdC0A2RBkBAACZJi4uTg0bNlR4eLj69u2r6dOny9mZww0Ad8a/DgAAIFNcvHhR/v7++u677zRw4ED997//lZOTk9mxAGRjlBEAAJBh58+fl6+vr3766Se99957GjduHEUEwD1xJRkAANmE1SoFB0vR0ZK3txQUJDnCGU5nz56Vn5+ffvvtN40aNUojRoygiABIF8oIAADZRHCw9MknkpubFBJiW9a2rbmZ7uX06dPy9fXVvn37NHr0aL333ntmRwLgQBzg8xYAAHKH6GhbESlVyvYYHW12orSdOHFC9evX1759+zR+/HiKCID7RhkBACCb8PaWEhKk06dtj97eZie6u+PHj6tevXo6ePCgJk+erAEDBpgdCYAD4jQtAACyiaAg2+PN14xkR0ePHpXFYtGxY8c0Y8YM9ejRw+xIAByUk2EYhtkhMpOXl5diYmLMjgEAQI70xx9/yGKxKCYmRl9//bW6dOlidiQA2Vxax+eMjAAAgHQ5cOCALBaL/vnnHy1YsECvvvqq2ZEAODjKCAAAuKe9e/fKx8dH58+f15IlS9SmTRuzIwHIASgjAAAgTbt27ZKvr6/i4uK0fPlytWjRwuxIAHIIyggAALir6Oho+fv76+rVq1q1apUaN25sdiQAOQhlBAAA3NGPP/6ogIAAJSQkaM2aNfL39zc7EoAchjICAABus23bNgUGBspqtWrDhg1q0KCB2ZEA5EDc9BAAAKQSFhamhg0bSpJCQkIoIgDshjICAABSbN68WY0bN1aePHm0ZcsW1alTx+xIAHIwyggAAJAkrV+/Xk2bNpW7u7tCQ0P1/PPPmx0JQA5HGQEAAFq1apVatmypQoUKKTw8XE8//bTZkQDkApQRAAByuWXLlqlNmzYqWrSoIiIi9MQTT5gdCUAuQRkBACAXW7hwoV555RWVLFlSkZGRqlGjhtmRAOQilBEAAHKpOXPm6LXXXlPZsmUVGRmpatWqmR0JQC5DGQEAIBeaMWOGunbtqgoVKigqKkpVqlQxOxKAXIgyAgBALjN58mT17NlTVapUUVRUlCpWrGh2JAC5FGUEAIBc5PPPP1e/fv306KOPKjIyUuXKlTM7EoBcjDICAEAuMXr0aL3zzjuqUaOGIiIiVKZMGbMjAcjlKCMAAORwhmFo1KhRGjZsmJ544gmFh4erZMmSZscCALmaHQAAANiPYRgaOnSoxowZI29vb4WEhKho0aJmxwIASZQRAAByLMMwNHDgQE2cOFHPP/+8Nm3aJE9PT7NjAUAKyggAADmQ1WpVv379NHXqVNWpU0cbNmxQwYIFzY4FAKlQRgAAyGGsVqt69uypr776Sg0aNNDatWtVoEABs2MBwG0oIwAA5CDJycnq1q2b5s2bJ39/f61atUr58+c3OxYA3BFlBACAHCIpKUmdOnXS4sWL1bhxYwUHBytfvnxmxwKAu6KMAACQAyQmJqp9+/YKDg5Wy5YttWTJErm5uZkdCwDSxH1GAABwcPHx8WrTpo2Cg4PVtm1bLV26lCICwCFQRgAAcGDXr19Xq1attHr1anXo0EGLFi1Snjx5zI4FAOlCGQEAwEFdvXpVTZs21YYNG9SlSxfNnTtXrq6cgQ3AcVBGAABwQJcvX1bjxo21detW9ezZU7NmzZKLi4vZsQDgvlBGAABwMHFxcWrYsKEiIiLUr18/TZs2Tc7O/C8dgOPhXy4AABzIxYsX5efnp++//16DBg3SpEmT5OTkZHYsAHgglBEAABzEv//+Kx8fH/38888aNmyYxo4dSxEB4NC4yg0AAAdw5swZ+fn5affu3frwww81fPhwsyMBQIZRRgAAyOZOnTolX19f7d+/X2PGjNG7775rdiQAyBSUEQAAsrETJ07IYrHo0KFDmjBhgvr37292JADINJQRAACyqePHj8tisejIkSOaMmWK+vTpY3YkAMhUlBEAALKhP//8UxaLRcePH9fMmTPVvXt3syMBQKajjAAAkM0cPnxYFotFJ0+e1Jw5c9SpUyezIwGAXVBGAADIRn7//XdZLBadPXtWCxYsUPv27c2OBAB2QxkBACCb2LNnj3x8fHThwgUtWbJEQUFBZkcCALuijAAAkA3s3LlTfn5+iouLU3BwsJo3b252JACwO8oIAAAm27Fjh/z9/XXt2jWtXr1ajRo1MjsSAGQJyggAACbavn27GjVqpMTERK1bt06+vr5mRwKALEMZAQDAJFFRUWrcuLEMw9DGjRtVr149syMBQJZyNjsAAAC5UWhoqBo1aiQnJyeFhIRQRADkSpQRAACyWEhIiJo0aaI8efJoy5YtevHFF82OBACmoIwAAJCF1q5dq2bNmil//vwKCwvTc889Z3YkADANZQQAgCyycuVKtWrVSoUKFVJ4eLieeuopsyMBgKkoIwAAZIGlS5eqbdu2KlasmCIiIvT444+bHQkATEcZAQDAzhYsWKD27durZMmSioyMVI0aNcyOBADZAmUEAAA7mj17tjp16iQvLy9FRUWpWrVqZkcCgGyD+4wAAHAXVqsUHCxFR0ve3lJQkOR8Hx/jffnll+rdu7cqVaqk8PBwVahQwX5hAcABUUYAALiL4GDpk08kNzcpJMS2rG3b9L32iy++0Ntvv61HHnlEYWFh8vLysl9QAHBQnKYFAMg2rFZp2TJp8GDbo9Vqbp7oaFsRKVXK9hgdnb7XjRs3Tm+//bYeffRRRUZGUkQA4C4YGQEAZBsZGYmwB29vW47Tp6WEBNv39/Lxxx9r+PDheuyxx7R161aVLFnS/kEBwEFRRgAA2cbNIxGnT9u+N7OMBAX9L9eNa0buxjAMjRw5Uh999JGefPJJbdmyRcWLF8+aoADgoCgjAIBs40FGIuzJ2dlWhu5ViAzD0JAhQzR27Fg988wzCgkJUZEiRbImJAA4MMoIACDbuJ+RiOzCMAwNGDBAkyZNUu3atbVx40Z5enqaHQsAHIKTYRiG2SEyk5eXl2JiYsyOAQDIBaxWq958801NmzZNdevW1bp161SwYEGzYwFAtpLW8TkjIwAAPACr1ao33nhDs2bNksVi0Zo1a1SgQAGzYwGAQ6GMAABwn5KTk9W1a1fNnz9fDRs21MqVK+Xu7m52LABwOJQRAADuQ2Jiol577TUtWbJETZs21fLly5U3b16zYwGAQ+KmhwAApFNCQoJeeeUVLVmyRK1atVJwcDBFBAAyIF1l5PDhw2rUqJHKlCmjokWLpnwBAJBbxMfHKygoSCtWrFC7du20ZMkSubm5mR0LABxauspI9+7d1blzZxUpUkSRkZEKCgrSoEGD7J0NAIBs4dq1a2rRooXWrl2rjh07auHChcqTJ4/ZsQDA4aWrjMTFxenll1+Ws7OzatasqRkzZujbb7+1czQAwL1YrdKyZdLgwbZHq9XsRDnPlStX1LRpU23atEndunXTnDlz5OLiYnYsAMgR0nUB+41PfwoWLKhjx46pVKlSOnfunF2DAQDuLThY+uQTyc3Ndudy6d53C0f6Xbp0SU2aNFFUVJR69eqlKVOmyNmZyy0BILOk61/UunXr6t9//1Xfvn319NNPq1KlSmrWrJm9swEA7iE62lZESpWyPUZHm50o54iNjVXDhg0VFRWlt956S1OnTqWIAEAmS9fIyLhx4yRJ7du310svvaTY2Fg99thjdg0GALg3b2/biMjp01JCgu37nMZqtY0ARUfbfr6gIMneneDChQsKCAjQjh07NHjwYI0ZM0ZOTk723SkA5ELpKiMtWrRIuUakXLlyKleuXKplAABzBAXZHm8+UM9psvpUtHPnzsnf3187d+7U8OHD9cEHH1BEAMBO0lVGjh8/ftuyI0eOZHoYAMD9cXa2HZjn5OtEbj4V7fRp2/f2+nnPnDkjX19f7dmzRx9++KGGDx9unx0BACTdo4zMmDFD06dP16FDh/TUU0+lLI+NjVWNGjXsHg4AgKw6Fe3UqVPy8fHR77//rs8++0yDBw+2z44AACnSLCMNGzZUtWrV1KtXL02cODFleaFChfT444/bPRwAAFlxKlpMTIwsFosOHz6siRMn6u233878nQAAbuNkGIZhdojM5OXlpZiYGLNjAAAcxF9//SWLxaI///xT06ZNU69evcyOBAA5SlrH5+m6ZuTatWuaPHmydu3apevXr6csX7lyZeYkBADABEeOHJHFYtHff/+tWbNmqVu3bmZHAoBcJV2TI3bv3l3Hjh3T9u3b1aBBA/3111+qUKGCvbMBAGA3hw4dUr169RQTE6N58+ZRRADABOkqI7/99pumTZumQoUK6c0331RERIR++eUXe2cDAMAu9u/fr3r16un06dNatGiROnbsaHYkAMiV0nWalru7u21lV1dduXJFBQsW1NmzZ+0aDAAAe9i9e7d8fX114cIFLV26VK1btzY7EgDkWukqI0WLFtWFCxcUGBiogIAAFS9eXF5eXvbOBgBApvr111/l5+eny5cva+XKlWratKnZkQAgV0vXbFrJyclycXGRYRhatGiRLl68qNdee02FChXKioz3hdm0AAB38vPPPysgIEDXrl3Tt99+q4YNG5odCQByhQzPpnX16lUdPHhQktSiRQt5eHhkXjoAAOzs+++/V6NGjZSUlKT169fLx8fH7EgAAN3jAnar1aq33npLxYoVk6+vr3x8fFSsWDH1799fOez2JACAHCoyMlIBAQGyWq3auHEjRQQAspE0y8iUKVMUHR2tPXv26OLFi4qNjdXu3bsVHR2tKVOmZFVGAAAeyNatW9WoUSO5uLho8+bNqlevntmRAAA3SbOMLFq0SIsWLVK1atVSllWrVk0LFizQwoUL7R4OAIAHtXHjRjVp0kR58+bV1q1b9cILL5gdCQBwizTLyMWLF1WxYsXbllesWFGxsbH2ygQAQIasWbNGLVq0UIECBRQWFqZnnnnG7EgAgDtIs4ykdaF6gQIFMj0MAAAZtWLFCrVu3Vqenp6KiIhQrVq1zI4EALiLNGfT+vvvvzVgwIDblhuGwfS5AIBs55tvvlHHjh1VokQJhYaGqnr16mZHAgCkIc0y0qdPn7s+17t370wPAwDAg5o3b566du2q0qVLKywsTFWrVjU7EgDgHtJ100NHwk0PASD3mTVrlnr06KHy5csrLCxMDz/8sNmRAAD/L63j8zSvGQEAILubNm2aunfvrkqVKikyMpIiAgAOhDICAHBYkyZNUp8+fVS1alVFRkaqQoUKZkcCANwHyggAwCF99tln6t+/v6pXr66IiAh5eXmZHQkAcJ/SVUaOHz+u69evp3x/7do1/f3333YLBQBAWj766CMNGTJENWvWVHh4uEqXLm12JADAA0hXGQkKCkrXMgAA7MkwDL3//vsaMWKEatWqpfDwcD300ENmxwIAPKA0p/a9ISEhQfny5Uv53t3dXfHx8XYLBQDArQzD0Lvvvqtx48bp2Wef1aZNm1SkSBGzYwEAMiBdIyNOTk46c+ZMyvenT59WDpsRGACQjRmGof79+2vcuHF64YUXtGXLFooIAOQA6RoZ6devn2rXrq2OHTtKkhYuXKiRI0faNRgAAJJktVrVp08fTZ8+XfXq1dO6devk4eFhdiwAQCZIVxnp0qWLKlWqpA0bNkiS5syZo5deesmuwQAASE5OVo8ePTR79mz5+vpq9erVyp8/v9mxAACZhDuwAwCypaSkJHXp0kULFy5Uo0aNtHLlylTXLwIAHENax+dpjowMHDhQ48ePV8uWLeXk5HTb8ytXrsychAAA3CQxMVEdO3bU0qVL1axZMy1btkx58+Y1OxYAIJOlWUbq168vSWrRokUWRAEAwDaDY7t27bRq1Sq1bt1aixcvlpubm9mxAAB2kGYZadq0qSSpZMmSatiwYarnNm3aZL9UAIBc6fr162rTpo3WrVunV155RfPnz5era7oubwQAOKB0Te07dOjQdC0DAOBBXbt2Tc2bN9e6dev02muvacGCBRQRAMjh0vxX/tChQzpw4IBiY2O1Zs2alOWxsbG6evWq3cMBAHKHK1euqFmzZgoLC9Prr7+uGTNmyNk5XZ+XAQAcWJpl5IcfftDcuXN15swZTZw4MWV5oUKFNH78eLuHAwDkfJcuXVLjxo21bds29e7dW5MnT6aIAEAuka6pfb/++mt169YtK/JkGFP7AoDjiI2NVaNGjfTDDz+of//+Gj9+/B1nbwQAOK60js/T9dHTa6+9pvHjx6t3796SpCNHjigsLCzzEgIAcp3z58/L19dXP/zwg4YMGUIRAYBcKF1XBr755ptKTk7Wd999J0kqVqyYXn75ZUVHR9s1HAAgZzp37pz8/Py0a9cujRgxQqNGjaKIAEAulK4y8uOPP2rXrl2qVauWJKlw4cJKTEy0azAAQM70zz//yNfXV3v37tXHH3+sYcOGmR0JAGCSdJWRfPnypfo+OTlZVqvVLoEAADnXyZMn5ePjowMHDmjcuHEaNGiQ2ZEAACZK1zUjjz/+uBYuXCir1ao//vhDPXv2TLk7OwAA6fH333+rXr16OnDggL744guKCAAgfWVkwoQJ2rZtm06fPq0XX3xRzs7OGjNmjL2zAQByiGPHjqlevXr6448/9OWXX6pfv35mRwIAZAPpmtrXkTC1LwBkL0eOHFGDBg0UExOjWbNmqWvXrmZHAgBkobSOz9N1zYgk/fTTTzpy5IiSkpJSlr322msZTwcAsDurVQoOlqKjJW9vKShIyor7Ch48eFAWi0WnT5/W/Pnz1aFDB/vvFADgMNJVRnr16qWQkBA9+eSTcnFxkSQ5OTlRRgDAQQQHS598Irm5SSEhtmVt29p3n/v27ZOPj4/OnTunxYsX6+WXX7bvDgEADiddZWTr1q3av3//bbNqAQAcQ3S0rYiUKiWdPm373p5l5LfffpOvr69iY2O1fPlytWzZ8oG2Y9aIDgAga6SrjJQuXVp58+a1dxYAgJ14e9tGRE6flhISbN/byy+//CI/Pz9duXJFK1euVJMmTR54W2aM6AAAsk6aZWTNmjWSpOeee05BQUF6+eWXU42ONGvWzL7pAACZIijI9njzCIM9/PTTTwoICFB8fLzWrFmjgICADG0vq0d0AABZK83ZtBo0aHD3Fzo5KSwszC6hMoLZtADAHN99950CAwOVnJystWvXymKxZHiby5b9b2QkIUEaNowyAgCO5oFn0woPD7dLIABAzhIREaEmTZrIyclJmzZt0ksvvZQp282qER0AgDnSdRngs88+m65lAIDcZ8uWLQoMDJSLi4s2b96caUVEsl2s3ratNHas7ZGL1wEgZ0nXP+s331tEkhITE3Xp0iW7BAIAOI4NGzaoadOmyps3r0JDQ1W7dm2zIwEAHEiaZeSzzz5TkSJFtGfPHhUtWjTlq1ChQqpbt25WZQQAZEOrV69WixYt5OHhofDwcHnbc4ouAECOlGYZ6dmzp3bu3ClfX1/t3Lkz5evkyZOaMWNGunZgGIZGjhypMmXKqECBAqpbt6727t17x3XPnDmjTp06qVKlSvLw8FDFihX13nvvKT4+/v5/MgBwUFar7cLtwYNtj1ar2Ylut3z5cgUFBalIkSKKiIjQk08+aXYkAIADSvMCdk9PT3l6emrjxo0PvIPPP/9cs2fPVkhIiKpUqaIPP/xQAQEBOnjwoDw8PFKte/nyZVWrVk0jRoxQpUqV9Oeff6pVq1a6du2aJk2a9MAZAMCRZPd7ayxevFgdO3ZUyZIlFRYWpkcffdTsSAAAB5Wua0Z+/fVXNWzYUFWrVtXDDz+sSpUq6eGHH07XDqZNm6ZBgwapZs2acnd310cffaSEhAStWrXqtnUffvhhDR06VJUrV5azs7OqVKmirl27MqsXgFzl5ntruLnZvs8u5s6dqw4dOqhMmTKKjIykiAAAMiRdd2Dv1KmT+vbtq9q1a8vFxSXdG4+NjdWxY8dSzbzl6uqqWrVqaefOnerYseM9t7F582bVqlXrrs9PmDBBEyZMSPn+8uXL6c4HABlhtdpGMW6edjYzZnvKyrul34+ZM2fqjTfeUIUKFRQeHq5KlSqZHQkA4ODSVUZcXFz0xhtv3PfG4+LiJEmFCxdOtbxIkSIpz6Xlo48+0s6dO7Vjx467rjNgwAANGDAg5XsvL6/7zgkAD8Jep1Nlx3trTJ06VX379lXlypUVFham8uXLmx0JAJADpOszvBdffFHRD3CeQKFChSRJFy9eTLX8woULKc/dzfDhwzVz5kxFRERQMABkS/Y6nSq73VtjwoQJ6tu3r6pVq6bIyEiKCAAg06Trf3FRUVF64YUXVL16dT311FMpX/fi6empihUrphrZSEpK0q5du+566pVhGOrTp4+++eYbbdu2TdWqVUvnjwIAWcvb23YaVXY7nSozffrppxo4cKCqV6+uiIgIlS1b1uxIAIAcJF2naU2ZMuWBd9C7d299/vnnslgsqly5sj7++GPlyZNHLVu2vG3dpKQkderUSbt27dK2bdtUunTpB94vANhbdjydKrMYhqEPP/xQo0aN0uOPP66tW7eqRIkSZscCAOQw6SojJUuWfOAZUwYNGqRLly7J19dXcXFx8vb21qZNm+Th4aHjx4+revXq2rhxo1566SV9//33Wrx4sfLmzatHHnkk1Xa4MB1AdnPjdKrsNO1uZjAMQ++//75Gjx6tp556Sps3b1axYsXMjgUAyIGcDMMw7rVSxYoV9cgjj+jNN99U06ZN5eTklBXZHoiXl5diYmLMjgEADskwDL3zzjsaP368nnvuOW3atOm2SUgAALgfaR2fp+uakT///FO9e/fW5MmTVblyZY0dO1bnz5/P1JAAAHMZhqG33npL48ePV506dbR582aKCADArtJVRpydndWyZUtt2bJFy5cv15QpU+Tl5aXu3bvr5MmT9s4IALAzq9Wqnj17avLkyapfv742btx4z1kPAQDIqHRPGHn48GG9/fbbatasmRo3bqzvvvtO1apVU8OGDe2ZDwBgZ8nJyerWrZtmzpwpPz8/rV+/Xh4eHmbHAgDkAum6gD0gIECHDx9W7969tW/fvpRh+6eeekpz5861YzwAgD0lJSWpc+fOWrRokQIDA7VixQrly5fP7FgAgFwiXWWkR48eatmypZzvcOetvXv3ZnooAID9JSYm6tVXX9Xy5cvVvHlzLV26VHnz5jU7FgAgF0nXaVqtW7eWs7Oz/vzzT02aNElr1661dy4AgB3Fx8erbdu2Wr58udq0aaPly5dTRAAAWS7NMuLr66tdu3ZJkk6ePClvb2+FhITonXfe0WeffZYV+QAAmez69etq3bq1vv32W7Vv316LFy9Wnjx5zI4FAMiF0iwjJ06c0JNPPilJWrx4serVq6eNGzfqhx9+0KJFi7IiHwAgE129elXNmzfX+vXr1blzZ82fP1+uruk6YxcAgEyXZhlxd3dP+e/t27crMDBQklSkSBH+5wUADubKlStq0qSJNm/erB49eujrr7+Wi4uL2bEAALlYmmXE2dlZMTExunz5siIjI1WvXr2U565evWr3cACAzBEXF6eGDRsqPDxcffv21fTp0+84KQkAAFkpzeGNoUOHqlatWnJ1dVWDBg1UtWpVSbZRkooVK2ZFPgBABl28eFENGzbUTz/9pAEDBujzzz+Xk5OT2bEAAJCTYRhGWiucPn1a//zzjx5//PGU/3mdPHlSSUlJKl++fJaEvB9eXl6KiYkxOwYAZAvnz5+Xv7+/fvnlF7333nv65JNPKCIAgCyV1vH5PS/8KFWqlEqVKpVqWZkyZTInGQDAbs6ePSs/Pz/99ttvGjVqlEaMGEERAQBkK1yFDgA50OnTp+Xr66t9+/Zp9OjReu+998yOBADAbSgjAJDDnDhxQj4+Pjp48KDGjx+vAQMGmB0JAIA7oowAQA5y/PhxWSwWHTlyRJMnT1bfvn3NjgQAwF1RRgAghzh69KgsFouOHTumGTNmqEePHmZHAgAgTZQRAMgB/vjjD1ksFsXExGj27Nnq0qWL2ZEAALgnyggAOLgDBw7IYrHon3/+0YIFC/Tqq6+aHQkAgHShjACAA9u7d698fHx0/vx5LVmyRG3atDE7EgAA6UYZAQAHtWvXLvn6+iouLk7Lly9XixYtzI4EAMB9oYwAgAOKjo6Wv7+/rl69qlWrVqlx48ZmRwIA4L5RRgDAwfz4448KCAhQQkKC1qxZI39/f7MjAQDwQCgjAOBAtm3bpsDAQFmtVm3YsEENGjQwOxIAAA/M2ewAAID0CQsLU8OGDSVJISEhFBEAgMOjjACAA9i8ebMaN26sPHnyaMuWLapTp47ZkQAAyDDKCABkc+vXr1fTpk3l7u6u0NBQPf/882ZHAgAgU1BGACAbW7VqlVq2bKlChQopPDxcTz/9tNmRAADINJQRAMimli1bpjZt2qho0aKKiIjQE088YXYkAAAyFWUEALKhhQsX6pVXXlHJkiUVGRmpGjVqmB0JAIBMRxkBgGxmzpw5eu2111S2bFlFRkaqWrVqZkcCAMAuKCMAkI3MmDFDXbt2VYUKFRQVFaUqVaqYHQkAALuhjABANjF58mT17NlTVapUUVRUlCpWrGh2JAAA7IoyAgDZwOeff65+/fqpWrVqioyMVLly5cyOBACA3VFGAMBko0eP1jvvvKMaNWooMjJSZcqUMTsSAABZgjICACYxDEOjRo3SsGHD9MQTTyg8PFwlS5Y0OxYAAFnG1ewAAJAbGYahoUOHasyYMfL29lZISIiKFi1qdiwAALIUZQQAsphhGBo4cKAmTpyo559/Xps2bZKnp6fZsQAAyHKUEQDIQlarVf369dPUqVNVp04dbdiwQQULFjQ7FgAApqCMAEAWsVqt6tmzp7766is1aNBAa9euVYECBcyOBQCAaSgjAJAFkpOT1a1bN82bN0/+/v5atWqV8ufPb3YsAABMRRkBADtLSkpSp06dtHjxYjVu3FjBwcHKly+f2bEAADAdZQQA7CgxMVHt27dXcHCwWrZsqSVLlsjNzc3sWAAAZAvcZwQA7CQ+Pl5t2rRRcHCw2rZtq6VLl1JEAAC4CWUEAOzg+vXratWqlVavXq0OHTpo0aJFypMnj9mxAADIVigjAJDJrl69qqZNm2rDhg3q0qWL5s6dK1dXzooFAOBWlBEAyESXL19W48aNtXXrVvXs2VOzZs2Si4uL2bEAAMiWKCMAkEni4uLUsGFDRUREqF+/fpo2bZqcnflnFgCAu+H/kgCQCS5evCh/f399//33GjRokCZNmiQnJyezYwEAkK1RRgAgg/7991/5+Pjop59+0rBhwzR27FiKCAAA6cAVlQCQAWfOnJGfn592796tDz/8UMOHDzc7EgAADoMyAgAP6NSpU/L19dX+/fv16aefasiQIWZHAgDAoVBGAOABnDhxQhaLRYcOHdKECRPUv39/syMBAOBwKCMAcJ+OHz8ui8WiI0eOaMqUKerTp4/ZkQAAcEiUEQC4D3/++acsFouOHz+umTNnqnv37mZHAgDAYVFGACCdDh8+LIvFopMnT2rOnDnq1KmT2ZEAAHBolBEASIfff/9dFotFZ8+e1YIFC9S+fXuzI+U4VqsUHCxFR0ve3lJQkMQ9IwEgZ6OMAMA97NmzRz4+Prpw4YKWLFmioKAgsyPlSMHB0iefSG5uUkiIbVnbtuZmAgDYF585AUAadu7cqQYNGujixYsKDg6miNhRdLStiJQqZXuMjjY7EQDA3igjAHAXO3bskMVi0eXLl7V69Wo1b97c7Eg5mre3lJAgnT5te/T2NjsRAMDeOE0LAO5g+/btatSokRITE7Vu3Tr5+vqaHSnHuzHodPM1IwCAnM3JMAzD7BCZycvLSzExMWbHAODAoqKi1LhxYxmGofXr16tevXpmRwIAwGGldXzOaVoAcJPQ0FA1atRITk5OCgkJoYgAAGBHnKYF5DJMn3p3ISEhatGihfLmzauQkBA999xzZkcCACBHo4wAuQzTp97Z2rVrFRQUJA8PD23ZskVPPfWU2ZEAAMjx+DwUyGWYPvV2K1euVKtWrVSoUCGFh4dTRAAAyCKUESCXYfrU1JYuXaq2bduqWLFiioiI0OOPP252JAAAcg1O0wJyGaZP/Z8FCxaoc+fOKlWqlMLCwlStWjWzIwEAkKswtS+AXGn27Nl6/fXXVa5cOYWFhaly5cpmRwIAIEdial8AuMmXX36pbt26qWLFioqKiqKIAABgEsoIgFzliy++UO/evfXII48oKipKFSpUMDsSAAC5FmUEQK4xbtw4vf3223r00UcVGRkpLy8vsyMBAJCrUUYA5Aoff/yxBg8erMcee0wREREqXbq02ZEAAMj1KCMAcjTDMDRixAgNHz5cTz75pMLDw1WyZEmzYwEAADG1L4AczDAMDRkyRGPHjtUzzzyjkJAQFSlSxOxYDsFqlYKDU08B7ex87+cAALgflBEAOZJhGBowYIAmTZqk2rVra+PGjfL09DQ7lsMIDpY++URyc5NCQmzL2ra993MAANwPPssCkONYrVb17dtXkyZNUt26dRUSEkIRuU/R0bayUaqU7TE6On3PAQBwPygjAHIUq9WqN954Q9OmTZPFYtGGDRtUsGBBs2M5HG9vKSFBOn3a9ujtnb7nAAC4H5ymBSDHSE5OVteuXTV//nw1bNhQK1eulLu7u9mxHFJQkO3x5utC0vMcAAD3w8kwDMPsEJkprdvNA8i5kpKS1LFjRy1ZskRNmzbV8uXLlTdvXrNjAQCQ66V1fM5pWgAcXkJCgtq1a6clS5aoVatWCg4OpogAAOAAKCMAHFp8fLyCgoK0YsWKlELi5uZmdiwAAJAOlBEADuvatWtq0aKF1q5dq44dO2rhwoXKkyeP2bEAAEA6UUYAOKQrV66oadOm2rRpk7p166Y5c+bIxcXF7FgAAOA+UEYAOJxLly4pMDBQoaGh6tWrl2bOnEkRAQDAAVFGADiU2NhYNWzYUFFRUXrrrbc0depUOTvzTxkAAI6I/4MDcBgXLlyQn5+ftm/frsGDB2vixIlycnIyOxYAAHhA3PQQsBOrVQoOTn1jOD7Af3Dnzp2Tv7+/du7cqeHDh+uDDz6giAAA4OAoI4CdBAdLn3wiublJISG2ZW3bmpvJUZ05c0a+vr7as2ePPvzwQw0fPtzsSAAAIBPwOS1gJ9HRtiJSqpTtMTra7ESO6dSpU6pfv7727Nmjzz77jCICAEAOQhkB7MTbW0pIkE6ftj16e5udyPHExMSoXr16+v333zVx4kQNHjzY7EgAACATcZoWYCdBQbbHm68ZQfr99ddfslgs+vPPPzVt2jT16tXL7EgAACCTORmGYZgdIjN5eXkpJibG7BgAMuDIkSOyWCz6+++/9dVXX6lbt25mRwIAAA8oreNzRkYAZCuHDh2SxWLRqVOnNG/ePHXs2NHsSAAAwE4oIwCyjf3798vHx0dnz57VokWL1K5dO7MjAQAAO6KMAMgWdu/eLV9fX124cEFLly5V69atzY4EAADsjDICwHS//vqr/Pz8dPnyZa1cuVJNmzY1OxIAAMgClBEApvr5558VEBCga9euafXq1WrYsKHZkQAAQBahjAAwzffff69GjRopKSlJ69evl4+Pj9mRAABAFqKMADBFZGSkGjduLEnauHGj6tWrZ3IiAACQ1bgDO4Ast3XrVjVq1EguLi7avHkzRQQAgFyKMgIgS23cuFFNmjRR3rx5tXXrVr3wwgtmRwIAACahjADIMmvWrFGLFi1UoEABhYWF6ZlnnjE7EgAAMBFlBECWWLFihVq3bi1PT09FRESoVq1aZkcCAAAmo4wAsLtvvvlGL7/8sooXL66IiAjVrFnT7EgAACAboIwAsKt58+apQ4cOKlWqlCIjI1W9enWzIwEAgGyCMgLAbmbNmqUuXbrIy8tLUVFRqlq1qtmRAABANkIZAWAX06ZNU/fu3VWpUiVFRUXp4YcfNjsSAADIZigjADLdpEmT1KdPH1WtWlWRkZGqUKGC2ZEAAEA2RBkBkKnGjPlM/fv3V7Fi1TVgQITKlPEyOxIAAMimKCMAMs1HH32k994bonz5asrLK1zTppVWcLDZqQAAQHZFGQGQYYZhaPjw4RoxYoQeeqiWHn00XOXKPSQ3Nyk62ux0AAAgu6KMAMgQwzD07rvv6uOPP9azzz6rTz8NldVaTKdPSwkJkre32QkBAEB25Wp2AACOyzAM9e/fX1988YVeeOEFbdy4UR4eheThYRsR8faWgoLMTgkAALIrJ8MwDLNDZCYvLy/FxMSYHQPI8axWq/r06aPp06erXr16WrdunTw8PMyOBQAAspm0js8ZGQFw35KTk9WjRw/Nnj1bvr6+Wr16tfLnz292LAAA4GAoIwDuS1JSkrp06aKFCxeqYcOGWrlypdzd3c2OBQAAHBBlBLme1SoFB6e+xsH5Aad2yMxtZUeJiYnq2LGjli5dqmbNmmnZsmXKmzev2bEAAICDoowg1wsOlj75RHJzk0JCbMvatjV/W9lNQkKC2rVrp1WrVql169ZavHix3NzczI4FAAAcWA76zBZ4MNHRtvJQqpQyfF+MzNxWdnL9+nW1bt1aq1at0iuvvKIlS5ZQRAAAQIZRRpDreXvb7oeRGffFyMxtZRfXrl1TixYttG7dOr322mtasGCBXF0ZVAUAABnHEQVyvRv3wciM+2Jk5raygytXrqhZs2YKCwtTt26vy9d3ht57zzlHXg8DAACyHvcZAXBHly5dUuPGjbVt2zb17t1bL700WZ9+6iw3N9uoz7BhOed6GAAAYD9pHZ/zuSaA28TGxiogIEDbtm1T//79NWXKFP36q3OOvB4GAACYhzICIJXz58/L19dXP/zwg4YMGaLx48fLyckpR14PAwAAzMU1IwBSnDt3Tn5+ftq1a5dGjBihUaNGycnJSVLOux4GAACYj2tGAEiS/vnnH/n6+mrv3r36+OOPNWzYMLMjAQCAHCCt43NGRgDo5MmT8vHx0YEDBzRu3DgNGjTI7EgAACAXoIwAudzff/8ti8WiP/74Q1988YX69etndiQAAJBLUEaALGa1SsHBqa+9MOt+HceOHZPFYtHRo0f15ZdfqmfPnuYEAQAAuRJlBMhiwcHSJ5/YpscNCbEtM+N+HUeOHFGDBg0UExOjr7/+Wl27ds36EAAAIFdjal8gi0VHy/T7dRw8eFB169bViRMnNH/+fIoIAAAwBWUEyGJm369j3759qlevnv755x8tXrxYHTp0yNoAAAAA/4/TtIAsZub9On777Tf5+voqNjZWy5cvV8uWLbNu5wAAALfgPiNALvHLL7/Iz89PV65c0YoVK9SkSROzIwEAgFyA+4wAOcz9zsj1008/KSAgQPHx8VqzZo0CAgKyLiwAAMBdUEYAB3Q/M3J99913CgwMVHJystavXy+LxZJ1QQEAANLABeyAA0rvjFwRERFq2LChDMPQpk2bKCIAACBboYwADig9M3Jt2bJFgYGBcnFx0ebNm/XSSy9lfVAAAIA0cJoW4IDuNSPXhg0b1KpVK7m7u2vz5s165plnsj4kAADAPTCbFpDDrF69Wm3atFGhQoW0detWPfnkk2ZHAgAAuVhax+ecpgXkIMuXL1dQUJCKFCmiiIgIiggAAMjW7F5GDMPQyJEjVaZMGRUoUEB169bV3r1777r++++/r1q1asnNzU116tSxdzwgx1i8eLHatWunEiVKKDIyUo899pjZkQAAANJk9zLy+eefa/bs2QoJCdG5c+f04osvKiAgQJcvX77j+pUrV9aHH36oHj162DsakK1ZrdKyZdLgwbZHq/Xu686bN08dOnRQmTJlFBkZqUcffTTrggIAADwgu5eRadOmadCgQapZs6bc3d310UcfKSEhQatWrbrj+l26dFHTpk1VvHhxe0cDsrUb9xIJD7c9Bgffeb2vvvpKXbp0Ufny5RUVFaVHHnkka4MCAAA8ILuWkdjYWB07dkzPPvtsyjJXV1fVqlVLO3fuzJR9TJgwQV5eXilfdxtxARxNeu4lMnXqVPXo0UMPP/ywoqKiVKlSpawPCgAA8IDsWkbi4uIkSYULF061vEiRIinPZdSAAQMUExOT8uXh4ZEp24Xju5/TnLKje91LZMKECerbt6+qVaumyMhIlS9f3pygAAAAD8iu9xkpVKiQJOnixYupll+4cEFly5a1566BlNOc3NykkBDbsrZtzc10P9K6l8inn36qoUOHqnr16goNDVWpUqXMCQkAAJABdh0Z8fT0VMWKFbVjx46UZUlJSdq1a5dq1aplz10D6TrNKTtzdraVp7FjbY/OzrbZ6T744AMNHTpUjz/+uCIiIigiAADAYdn9AvbevXvr888/1969e3Xt2jWNHDlSefLkUcuWLe+4fmJioq5fv66kpCQZhqHr16/r+vXr9o6JHOhepzk5GsMw9P7772vUqFF66qmnFBYWphIlSpgdCwAA4IHZ9TQtSRo0aJAuXbokX19fxcXFydvbW5s2bZKHh4eOHz+u6tWra+PGjXrppZckSd27d9e8efNSXu/u7i7JdiAG3I+0TnNyNIZh6J133tH48eP13HPPadOmTbddiwUAAOBonIwcdpSf1u3mAUdkGIbeeustTZ48WXXq1NH69etTrscCAADI7tI6Prf7yAiAB2e1WtW7d2/NmDFD9evX19q1a5kxDgAA5BiUESCbSk5OVvfu3TVnzhz5+fnp22+/Vf78+c2OJck2TXJwcOpT4JztfgUaAADIaSgjQDaUlJSkzp07a9GiRQoMDNSKFSuUL18+s2OlcPRpkwEAQPbAZ5nA/8suN0lMTExU+/bttWjRIjVv3lwrV67MVkVEcvxpkwEAQPbAyAjw/7LDp/3x8fFq166dvv32W7Vp00aLFi1Snjx5sjZEOnh7296jnDJtMgAAMAdlBPh/N3/af/q07Xt7lpFbr7to0uS62rYN0vr169W+fXvNmzdPrq7Z869oTpo2GQAAmCd7HukAJsjqT/tvHonZuPGqPvmkpXbv3qzOnTtr1qxZcnFxsW+ADLhxd3iuEwEAABlBGQH+X1Z/2n9jJKZ48Sv6/vumunQpXD169NCXX34p52wyNRWzZgEAAHuijAD/L6s/7ff2ljZsiNN33zXW5cvfKSCgr6ZP/6+cnJyyJkA6ZIfraAAAQM7FZ5yASXx9Lyo+3l+XL3+nxo0HaP36Bysi9pwFjFmzAACAPVFGABOcP39e/v6++uOPn/Tee+9p7drP5eLyYCMiN0YvwsNtj8HBmZfT29t2/QyzZgEAAHvgNC0gi509e1Z+fn767bffNGrUKI0YMSJDp2bZcxYwZs0CAAD2RBlBjpOdL7o+ffq0fH19tW/fPo0ePVrvvfdehrdpz1nAmDULAADYE2UEOU52uuj65mL08MMnNGmSjw4ePKjx48drwIABmbIPRi8AAICjoowgx8nqmxem5UYxMozjOnjQooSEI5o8ebL69u17z9emd4SH0QsAAOCoKCPIcbL65oVpiY6WDOOo/vjDooSEY/L3n6G+fXuk67XZaYQHAADAHigjyHGy02lLXl5/6MABixITY+TlNVvdunVJ92uz0wgPAACAPVBGkONkl9OWDhw4oDFjLEpK+keNGy/Qa6+9el/FKDuN8AAAANgDZQRIw4POzLV37175+Pjo33//1dKlS9SmTZv73nd2GuEBAACwB8oIkIYHuW5j165d8vX1VVxcnIKDg9WiRYsH2nd2GeEBAACwl2xy9wUge7r5ug03N9v3aa8fLYvFosuXL2vVqlUPXEQAAAByA8oIkAZvb9v1Gum5buPHH3+Uj4+Prl27pjVr1qhx48ZZFxQAAMABcZoWcrSM3o09vddtbNu2TYGBgbJardqwYYMaNGiQ8fAAAAA5HGUEOVpG79WRnus2wsPD1aRJEzk7OyskJER16tTJWGgAAIBcgtO0kKPd7zUf92vz5s0KDAxUnjx5tGXLFooIAADAfaCMIEe7n2s+7tf69evVtGlTubu7KzQ0VM8//3zmbRwAACAX4DQt5Gj2ulfHqlWr9PLLL8vT01Nbt27VE088kTkbBgAAyEWcDMMwzA6Rmby8vBQTE2N2DORgy5YtU/v27VW8eHGFhoaqRo0aZkcCAADIttI6Puc0LeA+LFy4UK+88ooeeughRUREUEQAAAAygNO04BAyOkVvZpgzZ466desmLy8vhYWFqUqVKlkb4C6yw3sDAADwICgjcAgZnaI3o2bMmKGePXuqYsWKCg8PV8WKFe26v/spGGa/NwAAAA+Kz0/hEOw9RW9aJk+erJ49e6pKlSqKioqyexGR/lcwwsNtj8HBd1/XzPcGAAAgIygjcAj2nKI3LePHj1e/fv1UrVo1RUZGqly5clmy3/spGGa9NwAAABnFaVpwCOmdojczr58YPXq0hg0bpho1aig0NFQlS5Z8sA09AG9v2ylX6SkY9pq+GAAAwN6Y2hc5yrJl/7t+IiFBGjbs/q+fMAxDH3zwgT744AM98cQT2rJli0qUKGGfwHfBRekAACCnSOv4nJERmMJqtRWHb76RDENq395WGjJ6wH3z6U2nT9u+v58yYhiGhg4dqjFjxsjb21shISEqWrRoxkI9AGdnW24uRAcAADkZZQSmCA6WhgyRzpyxff/bb/87AM+I+zm96VaGYWjgwIGaOHGinn/+eW3atEmenp4ZCwQAAIC7oozAFNHRUny8bRRDshWH+x3FuJMHvX7CarWqX79+mjp1qurUqaMNGzaoYMGCGQsDAACANHEWOkzh7S3lzWsrIQkJtlKSGbNA3RhdGTs2/ad9Wa1W9ezZU1OnTlWDBg3UvfsmffRRQS1bZjudDAAAAPbByAhMERRkO9C/+ZoRM2aBSk5OVrdu3TRv3jz5+/urQ4dV+vzz/NxAEAAAIAswMgJTODtL7dpJq1dLa9bY/jurZ4tKSkrSa6+9pnnz5qlx48ZavXq19uzJzw0EAQAAsghlBLlSYmKiXnnlFS1evFgtW7bUypUrlS9fPm4gCAAAkIU4TQu5Tnx8vF5++WWtXr1abdu21cKFC5UnTx5J3EAQAAAgK3HTQ+Qq169fV+vWrbVhwwZ16NBBc+bMkasrnRwAAMBe0jo+5zQt5BpXr15V06ZNtWHDBnXp0kVz586liAAAAJiIIzFkCqvVdiPDm09vyuoL0tNy+fJlNW3aVBERESnT+Dpnp4AAAAC5EGUEmSI4WPrkE2XLKXHj4uIUGBio77//Xv369dOkSZPk5ORkdiwAAIBcj4+GkSmio5Utp8S9ePGi/P399f3332vQoEH3VUSsVmnZMmnwYHEDRAAAADtgZASZwtvbNiKSmVPiZvTUr3///Vf+/v769ddfNWzYMH300Uf3NSKSnUd7AAAAcgLKCDKFPabEzUgZOHPmjPz8/LR79259+OGHGj58+H3v/+bRntOnbd9TRgAAADIPp2khUzg72w7Ux461PWbGteEPeurXqVOn1KBBA+3evVuffvrpAxURSdwAEQAAwM4YGUG29SCnfp04cUIWi0WHDh3ShAkT1L9//wfePzdABAAAsC9ueohs636vGTl+/LgsFouOHDmiKVOmqE+fPlkXFgAAAHeU1vE5ZQQ5wp9//imLxaLjx49rxowZ6t69u9mRAAAAoLSPzzlNC+mSnW9qePjwYVksFp08eVJz5sxRp06dzI4EAACAdKCMIF2y6zS3v//+u3x8fHTmzBktWLBA7du3NzsSAAAA0imbfLaN7C473tRw7969ql+/vs6ePaslS5ZQRAAAABwMZQTpkt2mud25c6fq16+vCxcuKDg4WEFMdQUAAOBwOE0L6ZKdprndsWOH/P39de3aNa1evVqNGjUyLwwAAAAeGLNpwaFs375djRo1UmJiotasWSNfX1+zIwEAACANzKaFHCEqKkqNGzeWYRjasGGD6tevb3YkAAAAZABlBJnGntP/hoaGqlmzZnJxcdGmTZv04osvZs6GAQAAYBrKCDKNvab/DQkJUYsWLZQ3b16FhIToueeey/hGAQAAYDpm00K6WK3SsmXS4MG2R6v19nXsMf3v2rVr1axZM+XPn19hYWEUEQAAgByEkRGkS3pGPby9bc9l1vS/K1eu1Msvv6zChQsrNDRUjz/+eMY2CAAAgGyFMoJ0uXnU4/Rp2/e3lpHMnP536dKlevXVV1W8eHGFhoaqRo0aD74xAAAAZEuUEaRLekY9nJ1tBeVu14mk9wL3BQsWqHPnzipVqpTCwsJUrVq1zP1hAAAAkC1QRpAumTHqkZ5TvWbPnq3XX39d5cqVU1hYmCpXrpyx4AAAAMi2KCNIl3uNeqTHrad67djxv+Xe3tLZs1+qb9/eqlSpksLCwlSxYsVMyX4ze04/DAAAgPtDGUGWufVUr8RE6Z13bP/91Vdf6OLFt/XII48oNDRU5cqVs0sGe00/DAAAgPtHGUGWufVUrwULpLNnJcMYp+vXB8vD41FFRoapdOnSdsuQngvxAQAAkDU4QQVZ5sapXmPH2h6dnaXExI91/fpgOTk9phdeiLBrEZFsJSghIfOmHwYAAMCDY2QEKW7c2PCbbyTDkNq3/19pyGyGYcjVdaSSkj6Sq+uTKlVqi7p0KZ75O7pFZk4/DAAAgIyhjCBFcLA0ZIh05ozt+99++99oRmYyDENDhgzRypVjVbnyMwoMDFGdOkWypBhkxoX4AAAAyByUkVzqTrNK7dghXbxoe87ZWYqPz/xrKgzD0IABAzRp0iTVrl1bGzdulKenZ+btAAAAAA6DMpJL3WlWqaQk6epV26Mk5c+fuddUWK1Wvfnmm5o2bZrq1q2rdevWqWDBgpmwXabrBQAAcESUkRzobgfnNy8/cEDKkyf1rFKurlK5ctLly7ZRkRdeyLxrKqxWq9544w3NmjVLFotFa9asUYECBTJl20zXCwAA4JgoIznQ3Q7Ob15um1JXcnJKPavU5s1S0aK2ZR06ZM4IQ3Jysrp27ar58+erYcOGWrlypdzd3TO+4f/HdL0AAACOiTKSA93t4Pzm5ZJUpoxUrdrts0o96ExTdxqRsVqT1LFjRy1ZskRNmzbV8uXLlTdv3sz7YXX7zRSZrhcAAMAxUEZyoLsdnN+6/NVXbx9ByMhMU7eOyCQlJWjlyvZasWKFWrVqpW+++UZubm4Z++HugOl6AQAAHBNlJAe628G5vQ/abx55OXkyXiNGtNGRI2vVrl07zZ8/X3ny5MncHf4/pusFAABwTJSRHOhOB+dZMePUjZGXkyev6fDhVrp0aZM6duyoOXPmyMXFJXN3BgAAAIdHGcklsmLGqaAg6fr1Kxo+vLkuXQpV167dNHPmDIoIAAAA7oi7MeQSO3bYpuw9f972uGNH5u/jypVL+vrrQB0/HqpevXrpq69mUkQAAABwV4yM5BJJSdLJk/+738iNGxveyc2ndD31lG3Zr7+mfXpXbGysAgMDtX37dr311luaOHGinJyc0tw2NygEAADI3SgjuYSrq20qXycn2/1FXNP4zd98StfSpbbXlChx99O7Lly4oICAAO3YsUODBw/WmDFj7lhEbt02NygEAADI3fhMOhe4MRISF2crIgUKSM88c/f1b54VKyHBdjf2UqVsy6KjU6977tw5+fj4aMeOHRo+fLhGjx6j5cudNHiwtGyZbd932/adtgcAAIDcg5GRXCA4WAoLkwoVki5dkpo1u31a35tPn0pMtBWQ06dthcHJ6c43FDxz5ox8fX21Z88effjhhxo+fLiWLUt75IMbFAIAAOAGykgucGM0onp1WwnIk+f26zRuPn0qIUFq0EA6dsw2gvHww7blzzzzvxJz6tQp+fj46Pfff9dnn32mwYMHp9rXrXd/v+HWe520amUbQeEaEgAAgNyHMpIL3Gs0wmqVFi6UzpyxXVeSJ4+tiBw7ZisWx49Lw4b9r1TExMTIYrHo8OHDmjhxot5+++107+vWe6DcayQFAAAAORdlJBcICrIVjm++sV0zYrXavm6MQAQHS7t3SxcvSv/+K+XLZ1svT57bRzj++usvWSwW/fnnn5o2bZp69ep1x30tXmw7vevWfd3qXiMpAAAAyLk4ISaHsFptowx3unDc2dn2deyYdOqUNGSI1KLF/9aLjrbNllWqlK2EODtL585JZ8+mHuE4cuSI6tatq6NHj2rWrFm3FZGb9/XXX7aphD/91FZ27sbb27Z9riEBAADIfRgZcSBp3aPjXlPm3hiBsFptp2Pt2GErDNL/Tq26ft02GlK5sm27ZcpI1arZnn/88UOqV8+iU6dOae7cuXrttdfumvN+RjtuvYbk1gvrAQAAkHNRRhxIWoXjXgXgRuE4c8b2fZkytsIRHS2NGWNbtnCh7XQtZ2fbKMWrr9q2sX//fjVo4KOzZ89q0aJFateuXZo572fGrFuvIQEAAEDuQRlxIHcrHFarbTrev/6Szp+XPDxuLwA3RhwWLZJ27bJdz3H2rHTggK3kBAXZvm4dedm9e7d8fX114cIFLV26VK1bt75nTkY7AAAAkB6UEQdytxGH4GApNFQqWNB2Y8M73UfkxgjEjcKxaJGtjJw8aRttkf43QnFjlOLXX3+Vn5+fLl++rJUrV6pp06bpysloBwAAANKDMuJA7jbiEB0t5c0rVahw9/uI3HCjKERH24rIjWtIFi1KfQ3Kzz//rICAAF27dk2rV69Ww4YN7f8DAgAAIFehjDiQu404pOcajRsXv+/YISUlSX/8YZtd68oV2/O7dtmeb9tW+u677fL3b6jExCQNGbJe/v4+9v7RAAAAkAtRRhzYzQXDYpFcXf93l/RbZ96yWm3T7F6+bBsRKV1aio+3XYNSubLtGpLoaKlkyUgFBDRWYqL0yCMbtWZNPdWsySlXAAAAyHyUkWwqrWl8b7h5dq2EhNR3SV+2TPr4Y9vIx5w5UvnyttO3nJxs23FykooX/991I25uUp48W9WoUTMZRh5VrbpRVaq8cM+pedOTEwAAALgTykg2da/7hki3z661Y8f/lh84YBsFOXdOSk62nZZVuLBt9OTGDRGTk213W5ek69c3aty4lipQ4P/au/fgKKs8jeNPh1zIhVyEIIRIgiA4wkKCkREz6lxEWFZRGXQMASHWSq2XEaSYVUYcpsSRUhllxtpxl10D6oIIOiqlLggqis7MChRthmFQiJVwNYRcOgRC0qHP/nE2nYQkQJN0v7l8P1VdTb/v6c5J1anYj+f8zonWL36xSW+8MU7ffWdnT7xee5hia2HjQvoJAAAAtIYw0kldyMGBZ9eK1Nc3BoOiIsnjsTMgkZF2FmTUKOmKK6Q9e2xI8fnsfWmDdu68U1FRcfroo83KyBirYcPsz/R6pY8/Pv9hihdywCEAAADQFAtqOqmsLBswzlWUPm2aXZr1ox/Z5/DwxlPWT560r8+ckWJi7Nkjubn2c/bskQ4etOeSFBW9pZ07f6qwsAQtWbJVY8eO9RfKP/usXdrVEDYiI23YCLSfAAAAQGuYGemkLubgwKuvlj78sPGU9SuvtLMjfftKCxbYz7jjDns/MlI6dep1eb0zFRubrCef/Ejz5l3V4jPPt1MXBxwCAADgYrmMMcbpTnSk1NRUHTp0yOluhMS6dc0L2BcutNeXLZO++aaxHiQ3V/rtb22tx5Qp0pYtkjGv6PTpe9Wr10AtW/axHn54eKuF5xSoAwAAoD3O9f2cr5Vd2I4ddilWaaktWJ87V/rTn2zReXS0VF5ua0I++sgGCkmaPl2Kjv4vnT6dJylVKSmfaeXK4f77Z2u6ZOuuuwgiAAAA6Dh8tezCsrJs3UdxsZ0ZOXZM+sMf7HNMjNSrlw0mJ0827rRVVvYHlZffp6ioIbrsss80evTlrdaCAAAAAMFGGOnCpk2z2/W6XA27YtmC9dJS6cABG1BOnrTniNTXSy+8sFwPPfSgkpKGa8aMT5WUlKaSEgrPAQAA4AwK2LuwsDBp8mTpxRcbr7lckjH2Idnn+Hhp585ntHz5Y4qKukqXXbZFX345UD/5id0ti8JzAAAAOIEw0gX5fNLatbYofc+e5veMsYGkYVtfl0uqrl6ibdt+pejof1By8hb16tVfR49KhYXSO+9QBwIAAABnEEa6iIZdrb780hakFxQ0nqR+tvBwWy9ijFFY2K906tRT6t07U/37b9bhw3119KhtU1BgP5NDCgEAAOAEwkgX4PNJjzwirVolnT5tazzOpU8fKS3NqKrqURUWPqfExHHy+TaqpiZJERF2tuTKK+2MCCemAwAAwCmEkU6q6fketbXSihU2iJxP795SfLxRWNgjKiz8nYYPv07Hj/+PPJ54nThhg8gll9ggQuE6AAAAnEQY6WQaQsjq1ZLbLSUnS/v2nTuIxMfbU9aPHpVqa306cOBBFRX9u2688UZlZLynN96IU+/e9rOjoqRrr5W+9z0K1wEAAOAswkgn8+ab9lT1Y8ckj0fq169x696GHbIahIXZcBERIZ04IdXVnZExc2RMvsLDb1Je3ruKjo7R2283tk9KkmbOZGkWAAAAnEcY6UR8PjsjcuyYXW5VVmZPVo+OtocY1tTYNmlpUmWl5PVKI0ZIFRVSeXm9jMmT9N+SJunMmT/qzTej9e679j1r1thAk5PDbAgAAAA6B8KIQ5rWhDQsl3rzTbs0y+OxQcTns4/KysYte8PCGrfuNUY6fFgqL/fKmJky5g1JUyStkzFROnLEtr/7bvsAAAAAOhPCiEMalmNFRkqbNtlrO3bYGpF+/eyMiDE2jJw5Y+83hJFTp6TYWBtIDh6sU3393ZLelvRTSWskRTrzSwEAAAAB4Lg7h+zYYYPIgAH2uWGGxOu1gSM5ufHgwgYN4cTlkvr3l0aMOC1jfirpbUVE5MjlWiuXK1JRUfYzBw1y7NcDAAAAzosw4pCsLLu17nffNW6xO3Wq9OMf27Bx223Sdde1fJ/LZQNLSUmNvvjidtXXv6eoqHt0ySWvKSkpXHFx9sDD+HhbHwIAAAB0VizTckhDEfn27VJ9vX3+85/t6epRUfIXnkdHy38+iMslDR4sJSSc1OHDU1RV9bFGjvxnpaf/h3r1ClNamn1fXZ39zDVrbDCZNs3OtgAAAACdCWHEIWFhjdvrNtSOFBU1hoayssa2LpcNFS6XdOrUCZWW/pNOntymm29+QEePvqiSkjD/qez9+9sQ8/e/26VfBw7Y62zlCwAAgM6GMOKw7dul6mr78HjsEqzWuFxS794eeb3/qJMn/6x58x5RePhvVVbmks9ntwMOD7fvLy2170lJseFmxw7CCAAAADofwkiInb2lb12ddPBg8xBy9gGHLpcUGVmumJiJKinZoUcffVRLly7V+vUurVvXGD4iI23dybff2i2CXa7GehQAAACgsyGMhNjZW/qmpdkZjfr6xgDSNIjYc0WOq6Zmgk6edOvaa3+lzMxfyxiXpk2zhyR++WXjLEhEhPT22y3PMAEAAAA6G8JIiDVs6Xvppbau429/s7MiZweQsDAbUHy+Ekk3Sdot6Sl9++3jevppO+tx111Sbm5jrUnDLEhDPQpLswAAANCZEUaC7OxlWRkZ0htvSPv2SSdPSklJzc8SkWxYOX1ako5I+omkvZKek8u1QLW1jeeS3HVX46wHsyAAAADoaggjQXb2sqwf/tDOgpw4YYNKQ71HUzaIHJT0Y0n7Jf1O0sMyxm7727QOhFkQAAAAdFWcPhFkZ5+0/t570uHDNoi0rUjSjbJB5CVJD/vvxMXZQDN1ahA7DQAAAIQAYSTImp60fuyYPffj3EGkUDaIFEl6WdK/NLtbXGwPM5w6VVq37nyfBQAAAHReLNMKsmnTbGBYvVravdsWpbfta9mlWd+pV69XlZIyQx6PVFXV2MLnkyoq7PkkxcX2Gku0AAAA0BUxMxJEDcXrq1dLW7Y01IK05W+yMyIliohYo6ioGerfX5o1y27921RYmN3Kt6GQHQAAAOiKmBkJoobi9eLi8wWRr2S37/VIWi+v9w6dOSMVFEjJydL999taE8nuvlVayoGGAAAA6PoII0HUULweFXWuVjslTZB0UtIfJd0iyc6q+HzS5s3SlVfaU9UbrnOgIQAAALoDwkgQjR1ri8zbnhX5X0kTJdVK2vD//27Uq5d9fPFF4zW28gUAAEB3QRgJsoazQVr6XNJkSWckvS9buN6SyyVlZwetewAAAIBjCCNB4PPZGZFFiySPp7WZka2yy7FckjZKur7Z3fBwKSbGPu6+W3ruuVD0GgAAAAgtwkgQrFsnPfSQVFbW2t3Nkm6TFCEbRMb770RE2GVZAwZIffrYMMNyLAAAAHRXhJEgWL26rSDygaSpkqIlfSjpGv+duDhpxQobRihOBwAAQE9AGAmCQ4dau/qupDslxUvaIinDfycmxgaRn/2ssUAdAAAA6O449DAI9u8/+8p6SdMkJcnWi2T477hc0pw5Uk6ODSIAAABAT8HX3w7k80kvvSRVVze9ukbS3ZKSJX0qaVSz94wZQ4E6AAAAeibCSAdau1Z64IGmV16RNENSimwQubJZ+1GjpO3b7e5ZAAAAQE8T9DBijNHixYuVkpKi2NhY3XDDDdq9e3eb7SsqKpSbm6uEhAQlJiYqNzdXlZWVwe5mh/j5z5u++k9JeZIGS/pM0hXN2sbFSZMmEUQAAADQcwU9jCxbtkz5+fnatGmTjh8/ruzsbE2cOFHVzdcy+c2YMUMlJSUqLCzU/v37VVJSolmzZgW7mx2ivLzhX/8maY6ky2WDyJAWbdPTpWuuaXEZCFjDuTb/+q/22edzukcAAAAXxmWMMcH8AUOGDNG8efM0d+5cSVJ9fb0GDhyo559/XjNnzmzWtri4WOnp6XK73RozZowk6auvvlJGRoaKi4s1ePDg8/681NRUHWp9O6ugc7kk6SVJD0gaIekjSYNatOvfX3rxRbt1L0XraK9166Tf/EaKjJTq6qTHH2dHNgAA0Hmc6/t5UL8KezweFRUVady4cf5r4eHhyszM1K5du1q0d7vdioqK8gcRSRozZowiIyPldrtb/RnPP/+8UlNT/Y+2ZlxCJ1vSDbK7ZjUPIuHhUt++0gsv2C+LBBF0hB07bBAZMMA+79jhdI8AAAAuTFArFqqqqiRJiYmJza4nJSX5753dPiEhocX1xMTEVttL0vz58zV//nz/69TU1Hb0uCOMlg0irmZXb75ZGj3aLs3iMEN0pKwsadMm6bvv7MxIVpbTPQIAALgwQQ0j8fHxktSiAL2iokKDBrVcvhQfHy+Px9PiemVlpf+zuobmQeTll6XZs5kJQXA0hNsdO2wQIewCAICuIqhhJCEhQenp6dq+fbvGjx8vydaMuN3uFvUikpSRkaHa2loVFBRo9OjRkqSCggLV1dUpIyMjmF3tEMGtvgFaFxZml/1RJwIAALqaoP+/+gceeEDLli3T7t27VVNTo8WLFysiIkJ33HFHi7ZpaWmaPHmyFixYoOPHj+v48eNasGCBbr311gsqXgcAAADQdQQ9jCxYsECzZ8/WTTfdpL59+2rbtm3auHGj4uLidODAAcXFxWnbtm3+9q+99pr69eunoUOHaujQoUpOTtarr74a7G4CAAAACLGgb+0bak5u7QsAAACgOce29gUAAACAthBGAAAAADiCMAIAAADAEYQRAAAAAI4gjAAAAABwBGEEAAAAgCMIIwAAAAAcQRgBAAAA4AjCCAAAAABHEEYAAAAAOIIwAgAAAMARhBEAAAAAjiCMAAAAAHAEYQQAAACAIwgjAAAAABxBGAEAAADgCMIIAAAAAEcQRgAAAAA4gjACAAAAwBGEEQAAAACOIIwAAAAAcARhBAAAAIAjCCMAAAAAHEEYAQAAAOAIwggAAAAARxBGAAAAADjCZYwxTneiI0VFRSk5OdnRPlRXVysuLs7RPqBnYcwhlBhvCDXGHEKJ8dbxSktLVVtb2+q9bhdGOoPU1FQdOnTI6W6gB2HMIZQYbwg1xhxCifEWWizTAgAAAOAIwggAAAAARxBGgmD+/PlOdwE9DGMOocR4Q6gx5hBKjLfQomYEAAAAgCOYGQEAAADgCMIIAAAAAEcQRgAAAAA4gjByEYwxWrx4sVJSUhQbG6sbbrhBu3fvbrN9RUWFcnNzlZCQoMTEROXm5qqysjJ0HUaXFuh4W7RokTIzMxUZGakf/OAHIewpuoNAxtuxY8c0a9YsDRkyRHFxcUpPT9fChQvbPNgKaE2gf+OmTJmiQYMGKT4+XgMHDlReXp7KyspC2GN0ZYGOtwZVVVVKT0+Xy+VSfX19CHracxBGLsKyZcuUn5+vTZs26fjx48rOztbEiRNVXV3davsZM2aopKREhYWF2r9/v0pKSjRr1qwQ9xpdVaDjbejQoXryySc1Z86cEPcU3UEg4626ulojRozQli1bVFVVpS1btuj999/Xo48+6kDP0VUF+jduyZIl2r9/v6qqqrRnzx7V1NTw9w4XLNDx1mDevHkaMWJEiHrZwxgELD093Sxfvtz/2uv1mn79+plXX321RduioiIjybjdbv81t9ttJJni4uKQ9BddWyDjranFixeb7OzsYHcP3czFjrcGL7zwghk9enSwuoduqD1jrry83OTk5JiRI0cGs4voRi5mvG3YsMFkZWWZzZs3G0nG6/WGoqs9BjMjAfJ4PCoqKtK4ceP818LDw5WZmaldu3a1aO92uxUVFaUxY8b4r40ZM0aRkZFyu92h6DK6sEDHG9AeHTHePvzwQ2VmZgari+hmLnbMLVy4UH369NEll1yid955R4sXLw5Fd9HFXcx4Kysr00MPPaSVK1cqPDw8VF3tUQgjAaqqqpIkJSYmNruelJTkv3d2+4SEhBbXExMTW20PNBXoeAPao73jbcmSJdq1a5eeeuqpYHQP3dDFjrmlS5fqxIkT2rdvn+bPn6/hw4cHs5voJi5mvN1///267777NGrUqGB3r8cijAQoPj5ekloUoFdUVPjvnd3e4/G0uF5ZWdlqe6CpQMcb0B7tGW9PPPGEVqxYoa1btyo1NTVYXUQ3096/ccOGDdOUKVM0ceJEeb3eYHQR3Uig423t2rUqLCzUY489Foru9ViEkQAlJCQoPT1d27dv91+rr6+X2+1udWlCRkaGamtrVVBQ4L9WUFCguro6ZWRkhKLL6MICHW9Ae1zMeDPG6MEHH9Trr7+ubdu2UeCJgHTE3ziv16uSkpJW/8cf0FSg423jxo3au3evBgwYoH79+um2226TJA0YMECvvPJKyPrd7TldtNIVPfvss+ayyy4zf/3rX82pU6fML3/5S5OSkmJOnDjRavvJkyebCRMmmNLSUlNaWmomTJhgbr311hD3Gl1VoOOtrq7O1NTUmMcff9xcd911pqamxtTU1IS41+iqAhlvXq/XTJ8+3Vx11VXmyJEjDvQW3UEgY+7rr782b731lvF4PMbn85m9e/ea8ePHm2uuucaBnqMrCmS8lZeXm4MHD/of69atM5JMUVGRqa6udqD33RNh5CL4fD7zxBNPmEsvvdRER0eb66+/3hQUFBhjjCkuLjaxsbHms88+87cvKyszOTk5Jj4+3sTHx5vp06ebiooKh3qPribQ8TZr1iwjqcUDuBCBjLetW7caSSYqKsrExsY2ewAXKpAxt3fvXpOdnW0SEhJMbGysSUtLM3PmzDFHjx518ldAFxLof1Ob+uSTT9hNKwhcxhjj3LwMAAAAgJ6KmhEAAAAAjiCMAAAAAHAEYQQAAACAIwgjAAAAABxBGAEAAADgCMIIAAAAAEcQRgAAAAA4gjACALho6enp6t+/v7xer//aJ598IpfLpXnz5kmStm7dqoyMDP99l8vV7LUkrVy5Ui6XS8uXL5ckrVq1Srfffrv//rFjx5SXl6fLL79cmZmZGjt2rJ5++uk2++R2uyVJs2fPbvMzAQDOI4wAANpl8ODB2rBhg//1yy+/rKysrHO+Jzw8XDt37vS/zs/Pb/M9NTU1uvHGG5WWlqZ9+/Zp165d+vzzzxUbG9sxvwAAwDGEEQBAu+Tl5Sk/P1+S5PF49Je//EWTJk264Pd888038nq9GjlyZKtt16xZoz59+ujXv/61evXqJUmKiYnR3LlzO/C3AAA4gTACAGiX7OxsFRUV6ciRI3r99dd15513+kNDW6ZOnaoPPvhAp0+fVn5+vvLy8tpsu3PnTo0fP76juw0A6AQIIwCAdps5c6ZWrVql/Px83XvvvedtHx0drYkTJ2r9+vVav369cnJyQtBLAEBnE+50BwAAXd8999yjsWPHavjw4briiisu6D15eXm65ZZbNGnSJMXHx7fZ7uqrr9aKFSs6qqsAgE6EmREAQLulpKRo6dKleuaZZy74Pd///ve1aNEiLVy48JztcnJyVFlZqSVLlujMmTOSbFH773//+3b1GQDgPGZGAAAd4lx1H225kCL0mJgYffrpp3rsscc0bNgwxcXFyeVyafr06RfTTQBAJ+IyxhinOwEAAACg52GZFgAAAABHEEYAAAAAOIIwAgAAAMARhBEAAAAAjiCMAAAAAHAEYQQAAACAIwgjAAAAABxBGAEAAADgiP8DkuoNwdHXMD8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}